{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12 # or 54\n",
    "lookback = 3\n",
    "chosen_stocks = [\"COST\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 4.8505 - acc: 0.4568 - val_loss: 3.4456 - val_acc: 0.2778\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 2.5857 - acc: 0.4568 - val_loss: 3.0682 - val_acc: 0.2778\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 585us/step - loss: 2.2971 - acc: 0.4568 - val_loss: 2.8638 - val_acc: 0.2778\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 572us/step - loss: 2.1756 - acc: 0.4568 - val_loss: 2.7266 - val_acc: 0.2778\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 581us/step - loss: 2.0652 - acc: 0.4568 - val_loss: 2.6165 - val_acc: 0.2778\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 594us/step - loss: 1.9797 - acc: 0.4568 - val_loss: 2.5235 - val_acc: 0.2778\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 1.9101 - acc: 0.4568 - val_loss: 2.4400 - val_acc: 0.2778\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 557us/step - loss: 1.8420 - acc: 0.4568 - val_loss: 2.3639 - val_acc: 0.2778\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 1.7948 - acc: 0.4568 - val_loss: 2.2933 - val_acc: 0.2778\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 543us/step - loss: 1.7422 - acc: 0.4568 - val_loss: 2.2276 - val_acc: 0.2778\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 1.6931 - acc: 0.4568 - val_loss: 2.1655 - val_acc: 0.2778\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 554us/step - loss: 1.6502 - acc: 0.4568 - val_loss: 2.1063 - val_acc: 0.2778\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 548us/step - loss: 1.6055 - acc: 0.4568 - val_loss: 2.0494 - val_acc: 0.2778\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 601us/step - loss: 1.5641 - acc: 0.4568 - val_loss: 1.9925 - val_acc: 0.2778\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 590us/step - loss: 1.5279 - acc: 0.4568 - val_loss: 1.9379 - val_acc: 0.2778\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 579us/step - loss: 1.4763 - acc: 0.4568 - val_loss: 1.8854 - val_acc: 0.2778\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 582us/step - loss: 1.4456 - acc: 0.4568 - val_loss: 1.8342 - val_acc: 0.2778\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 1.4094 - acc: 0.4568 - val_loss: 1.7846 - val_acc: 0.2778\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 1.3738 - acc: 0.4568 - val_loss: 1.7363 - val_acc: 0.2778\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 581us/step - loss: 1.3443 - acc: 0.4568 - val_loss: 1.6890 - val_acc: 0.2778\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 1.3066 - acc: 0.4568 - val_loss: 1.6443 - val_acc: 0.2778\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 598us/step - loss: 1.2766 - acc: 0.4568 - val_loss: 1.5993 - val_acc: 0.2778\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 582us/step - loss: 1.2448 - acc: 0.4568 - val_loss: 1.5551 - val_acc: 0.2778\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 1.2036 - acc: 0.4568 - val_loss: 1.5121 - val_acc: 0.2778\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 1.1847 - acc: 0.4568 - val_loss: 1.4700 - val_acc: 0.2778\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 1.1632 - acc: 0.4568 - val_loss: 1.4290 - val_acc: 0.2778\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 1.1344 - acc: 0.4568 - val_loss: 1.3884 - val_acc: 0.2778\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 563us/step - loss: 1.0989 - acc: 0.4568 - val_loss: 1.3488 - val_acc: 0.2778\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 1.0785 - acc: 0.4568 - val_loss: 1.3094 - val_acc: 0.2778\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 1.0407 - acc: 0.4568 - val_loss: 1.2712 - val_acc: 0.2778\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 543us/step - loss: 1.0168 - acc: 0.4568 - val_loss: 1.2336 - val_acc: 0.2778\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.9997 - acc: 0.4568 - val_loss: 1.1959 - val_acc: 0.2778\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.9680 - acc: 0.4568 - val_loss: 1.1596 - val_acc: 0.2778\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.9469 - acc: 0.4568 - val_loss: 1.1248 - val_acc: 0.2778\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 0.9205 - acc: 0.4568 - val_loss: 1.0908 - val_acc: 0.2778\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 0.9009 - acc: 0.4568 - val_loss: 1.0567 - val_acc: 0.2778\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.8725 - acc: 0.4568 - val_loss: 1.0236 - val_acc: 0.2778\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.8551 - acc: 0.4568 - val_loss: 0.9909 - val_acc: 0.2778\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 0.8445 - acc: 0.4568 - val_loss: 0.9594 - val_acc: 0.2778\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.8231 - acc: 0.4568 - val_loss: 0.9296 - val_acc: 0.2778\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.8108 - acc: 0.4568 - val_loss: 0.9010 - val_acc: 0.2778\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 616us/step - loss: 0.7899 - acc: 0.4568 - val_loss: 0.8736 - val_acc: 0.2778\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.7717 - acc: 0.4568 - val_loss: 0.8470 - val_acc: 0.2778\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.7580 - acc: 0.4568 - val_loss: 0.8218 - val_acc: 0.2778\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.7449 - acc: 0.4568 - val_loss: 0.7975 - val_acc: 0.2778\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 543us/step - loss: 0.7403 - acc: 0.4568 - val_loss: 0.7744 - val_acc: 0.2778\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 546us/step - loss: 0.7342 - acc: 0.4568 - val_loss: 0.7528 - val_acc: 0.2778\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 548us/step - loss: 0.7129 - acc: 0.4815 - val_loss: 0.7344 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 576us/step - loss: 0.7109 - acc: 0.4815 - val_loss: 0.7178 - val_acc: 0.4167\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.7112 - acc: 0.4691 - val_loss: 0.7028 - val_acc: 0.5278\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 0.6947 - acc: 0.4568 - val_loss: 0.6899 - val_acc: 0.5556\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 580us/step - loss: 0.6905 - acc: 0.5185 - val_loss: 0.6773 - val_acc: 0.5556\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.6978 - acc: 0.5062 - val_loss: 0.6666 - val_acc: 0.5833\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6845 - acc: 0.5432 - val_loss: 0.6586 - val_acc: 0.6111\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6837 - acc: 0.6049 - val_loss: 0.6518 - val_acc: 0.6389\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6894 - acc: 0.5556 - val_loss: 0.6464 - val_acc: 0.6667\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 0.6983 - acc: 0.5062 - val_loss: 0.6434 - val_acc: 0.6944\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6963 - acc: 0.5309 - val_loss: 0.6416 - val_acc: 0.7222\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 531us/step - loss: 0.6936 - acc: 0.5062 - val_loss: 0.6410 - val_acc: 0.7222\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.6873 - acc: 0.5679 - val_loss: 0.6410 - val_acc: 0.7222\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 548us/step - loss: 0.6854 - acc: 0.5432 - val_loss: 0.6406 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6889 - acc: 0.5062 - val_loss: 0.6412 - val_acc: 0.7222\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 0.6936 - acc: 0.5556 - val_loss: 0.6423 - val_acc: 0.6944\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.6791 - acc: 0.5802 - val_loss: 0.6426 - val_acc: 0.6944\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6952 - acc: 0.4938 - val_loss: 0.6426 - val_acc: 0.6944\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 0.6855 - acc: 0.5432 - val_loss: 0.6445 - val_acc: 0.6667\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 565us/step - loss: 0.6915 - acc: 0.5309 - val_loss: 0.6467 - val_acc: 0.6667\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.6832 - acc: 0.5556 - val_loss: 0.6472 - val_acc: 0.6667\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 0.6838 - acc: 0.5926 - val_loss: 0.6479 - val_acc: 0.6667\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 0.6917 - acc: 0.5679 - val_loss: 0.6483 - val_acc: 0.6667\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 580us/step - loss: 0.6855 - acc: 0.5309 - val_loss: 0.6488 - val_acc: 0.6667\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 0.6965 - acc: 0.4938 - val_loss: 0.6491 - val_acc: 0.6389\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 584us/step - loss: 0.6790 - acc: 0.5556 - val_loss: 0.6477 - val_acc: 0.6667\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 580us/step - loss: 0.6893 - acc: 0.5556 - val_loss: 0.6472 - val_acc: 0.6667\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6866 - acc: 0.4815 - val_loss: 0.6471 - val_acc: 0.6667\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6871 - acc: 0.5185 - val_loss: 0.6466 - val_acc: 0.6667\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 0.6943 - acc: 0.5432 - val_loss: 0.6459 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.6903 - acc: 0.5679 - val_loss: 0.6455 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6860 - acc: 0.5679 - val_loss: 0.6457 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.6929 - acc: 0.5679 - val_loss: 0.6454 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6973 - acc: 0.5309 - val_loss: 0.6454 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 576us/step - loss: 0.6856 - acc: 0.5185 - val_loss: 0.6458 - val_acc: 0.6667\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 0.6940 - acc: 0.5309 - val_loss: 0.6468 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.7013 - acc: 0.5062 - val_loss: 0.6485 - val_acc: 0.6389\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 573us/step - loss: 0.6928 - acc: 0.4691 - val_loss: 0.6495 - val_acc: 0.6389\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6939 - acc: 0.5062 - val_loss: 0.6497 - val_acc: 0.6389\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.7019 - acc: 0.4691 - val_loss: 0.6508 - val_acc: 0.6389\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6927 - acc: 0.4938 - val_loss: 0.6513 - val_acc: 0.6389\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 0.6881 - acc: 0.5062 - val_loss: 0.6544 - val_acc: 0.6111\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 565us/step - loss: 0.6933 - acc: 0.5062 - val_loss: 0.6559 - val_acc: 0.6111\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 0.6888 - acc: 0.5679 - val_loss: 0.6568 - val_acc: 0.6111\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6925 - acc: 0.5432 - val_loss: 0.6566 - val_acc: 0.6111\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 547us/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.6560 - val_acc: 0.6111\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 0.6875 - acc: 0.5432 - val_loss: 0.6548 - val_acc: 0.6111\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.6914 - acc: 0.5062 - val_loss: 0.6536 - val_acc: 0.6111\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6829 - acc: 0.5556 - val_loss: 0.6522 - val_acc: 0.6111\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 0.6883 - acc: 0.5679 - val_loss: 0.6516 - val_acc: 0.6111\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6897 - acc: 0.5185 - val_loss: 0.6522 - val_acc: 0.6111\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 543us/step - loss: 0.6830 - acc: 0.5185 - val_loss: 0.6517 - val_acc: 0.6111\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6823 - acc: 0.5309 - val_loss: 0.6506 - val_acc: 0.6389\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.6806 - acc: 0.6049 - val_loss: 0.6513 - val_acc: 0.6111\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6972 - acc: 0.4691 - val_loss: 0.6505 - val_acc: 0.6389\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 0.6812 - acc: 0.4938 - val_loss: 0.6495 - val_acc: 0.6389\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 0.7001 - acc: 0.4568 - val_loss: 0.6500 - val_acc: 0.6389\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6923 - acc: 0.5802 - val_loss: 0.6514 - val_acc: 0.6111\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 0.6946 - acc: 0.4815 - val_loss: 0.6534 - val_acc: 0.6111\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 536us/step - loss: 0.6760 - acc: 0.5432 - val_loss: 0.6540 - val_acc: 0.6111\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6863 - acc: 0.5556 - val_loss: 0.6552 - val_acc: 0.6111\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.6853 - acc: 0.5556 - val_loss: 0.6553 - val_acc: 0.6111\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.6824 - acc: 0.5309 - val_loss: 0.6562 - val_acc: 0.6111\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.6963 - acc: 0.5556 - val_loss: 0.6567 - val_acc: 0.6111\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 703us/step - loss: 0.6755 - acc: 0.6296 - val_loss: 0.6554 - val_acc: 0.6111\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.6885 - acc: 0.5309 - val_loss: 0.6536 - val_acc: 0.6111\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6836 - acc: 0.5679 - val_loss: 0.6522 - val_acc: 0.6111\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 0.6966 - acc: 0.5185 - val_loss: 0.6523 - val_acc: 0.6111\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6917 - acc: 0.5556 - val_loss: 0.6523 - val_acc: 0.6111\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6880 - acc: 0.4691 - val_loss: 0.6534 - val_acc: 0.6111\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 554us/step - loss: 0.7015 - acc: 0.4815 - val_loss: 0.6541 - val_acc: 0.6111\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 554us/step - loss: 0.6854 - acc: 0.5185 - val_loss: 0.6543 - val_acc: 0.6111\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 0.6799 - acc: 0.5556 - val_loss: 0.6526 - val_acc: 0.6111\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 586us/step - loss: 0.6804 - acc: 0.5062 - val_loss: 0.6520 - val_acc: 0.6111\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 611us/step - loss: 0.6812 - acc: 0.5309 - val_loss: 0.6496 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 600us/step - loss: 0.6766 - acc: 0.5679 - val_loss: 0.6496 - val_acc: 0.6389\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.6918 - acc: 0.5432 - val_loss: 0.6490 - val_acc: 0.6389\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 591us/step - loss: 0.6827 - acc: 0.5309 - val_loss: 0.6486 - val_acc: 0.6389\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 0.6861 - acc: 0.5309 - val_loss: 0.6476 - val_acc: 0.6389\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6960 - acc: 0.5062 - val_loss: 0.6492 - val_acc: 0.6389\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.6933 - acc: 0.5062 - val_loss: 0.6501 - val_acc: 0.6111\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 0.6843 - acc: 0.5432 - val_loss: 0.6487 - val_acc: 0.6389\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 0.6811 - acc: 0.5679 - val_loss: 0.6481 - val_acc: 0.6389\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6935 - acc: 0.5062 - val_loss: 0.6485 - val_acc: 0.6389\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 572us/step - loss: 0.6842 - acc: 0.5679 - val_loss: 0.6484 - val_acc: 0.6389\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 0.6795 - acc: 0.6173 - val_loss: 0.6493 - val_acc: 0.6389\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.6827 - acc: 0.5432 - val_loss: 0.6485 - val_acc: 0.6389\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6886 - acc: 0.5309 - val_loss: 0.6490 - val_acc: 0.6389\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 563us/step - loss: 0.6788 - acc: 0.5432 - val_loss: 0.6514 - val_acc: 0.6111\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.6817 - acc: 0.5556 - val_loss: 0.6533 - val_acc: 0.6111\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 609us/step - loss: 0.6780 - acc: 0.5679 - val_loss: 0.6552 - val_acc: 0.6389\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.6854 - acc: 0.5309 - val_loss: 0.6560 - val_acc: 0.6389\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 580us/step - loss: 0.6894 - acc: 0.4815 - val_loss: 0.6564 - val_acc: 0.6389\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 587us/step - loss: 0.6834 - acc: 0.5556 - val_loss: 0.6547 - val_acc: 0.6389\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 610us/step - loss: 0.6953 - acc: 0.4938 - val_loss: 0.6537 - val_acc: 0.6389\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 610us/step - loss: 0.6867 - acc: 0.4938 - val_loss: 0.6535 - val_acc: 0.6389\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 586us/step - loss: 0.6853 - acc: 0.5062 - val_loss: 0.6530 - val_acc: 0.6389\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 590us/step - loss: 0.6832 - acc: 0.5062 - val_loss: 0.6536 - val_acc: 0.6389\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 0.6807 - acc: 0.5802 - val_loss: 0.6525 - val_acc: 0.6389\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 582us/step - loss: 0.6826 - acc: 0.5062 - val_loss: 0.6532 - val_acc: 0.6389\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 589us/step - loss: 0.6813 - acc: 0.5556 - val_loss: 0.6546 - val_acc: 0.6667\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.6933 - acc: 0.5309 - val_loss: 0.6547 - val_acc: 0.6667\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 563us/step - loss: 0.6945 - acc: 0.4444 - val_loss: 0.6549 - val_acc: 0.6667\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 0.6808 - acc: 0.5926 - val_loss: 0.6547 - val_acc: 0.6667\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 565us/step - loss: 0.6792 - acc: 0.5556 - val_loss: 0.6526 - val_acc: 0.6389\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 587us/step - loss: 0.6776 - acc: 0.5432 - val_loss: 0.6522 - val_acc: 0.6389\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 577us/step - loss: 0.6883 - acc: 0.5432 - val_loss: 0.6526 - val_acc: 0.6667\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 0.6932 - acc: 0.5556 - val_loss: 0.6527 - val_acc: 0.6667\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 586us/step - loss: 0.6842 - acc: 0.5679 - val_loss: 0.6539 - val_acc: 0.6667\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 563us/step - loss: 0.6734 - acc: 0.5556 - val_loss: 0.6545 - val_acc: 0.6667\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 585us/step - loss: 0.6896 - acc: 0.4691 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 587us/step - loss: 0.6780 - acc: 0.5926 - val_loss: 0.6573 - val_acc: 0.6667\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 0.6887 - acc: 0.5309 - val_loss: 0.6570 - val_acc: 0.6667\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6954 - acc: 0.4815 - val_loss: 0.6573 - val_acc: 0.6667\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 574us/step - loss: 0.6848 - acc: 0.5926 - val_loss: 0.6597 - val_acc: 0.6389\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6853 - acc: 0.5185 - val_loss: 0.6619 - val_acc: 0.6389\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 585us/step - loss: 0.6756 - acc: 0.5802 - val_loss: 0.6601 - val_acc: 0.6389\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6831 - acc: 0.5802 - val_loss: 0.6589 - val_acc: 0.6389\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 597us/step - loss: 0.6880 - acc: 0.5185 - val_loss: 0.6567 - val_acc: 0.6667\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 0.6834 - acc: 0.5432 - val_loss: 0.6546 - val_acc: 0.6667\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 592us/step - loss: 0.6851 - acc: 0.5062 - val_loss: 0.6537 - val_acc: 0.6667\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 572us/step - loss: 0.6785 - acc: 0.5679 - val_loss: 0.6551 - val_acc: 0.6667\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 0.6907 - acc: 0.5432 - val_loss: 0.6559 - val_acc: 0.6667\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 591us/step - loss: 0.6850 - acc: 0.5185 - val_loss: 0.6552 - val_acc: 0.6667\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 602us/step - loss: 0.6903 - acc: 0.5185 - val_loss: 0.6544 - val_acc: 0.6667\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6864 - acc: 0.5432 - val_loss: 0.6526 - val_acc: 0.6667\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6795 - acc: 0.5556 - val_loss: 0.6527 - val_acc: 0.6667\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 0.6887 - acc: 0.5309 - val_loss: 0.6517 - val_acc: 0.6667\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 0.6877 - acc: 0.5802 - val_loss: 0.6502 - val_acc: 0.6667\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6878 - acc: 0.5432 - val_loss: 0.6522 - val_acc: 0.6667\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 532us/step - loss: 0.6831 - acc: 0.5432 - val_loss: 0.6538 - val_acc: 0.6667\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 548us/step - loss: 0.6730 - acc: 0.5556 - val_loss: 0.6541 - val_acc: 0.6667\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 534us/step - loss: 0.6801 - acc: 0.5309 - val_loss: 0.6541 - val_acc: 0.6389\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 531us/step - loss: 0.6906 - acc: 0.5185 - val_loss: 0.6546 - val_acc: 0.6389\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 527us/step - loss: 0.6898 - acc: 0.5185 - val_loss: 0.6556 - val_acc: 0.6389\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6927 - acc: 0.4815 - val_loss: 0.6591 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6912 - acc: 0.5309 - val_loss: 0.6602 - val_acc: 0.6389\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 592us/step - loss: 0.6811 - acc: 0.5309 - val_loss: 0.6595 - val_acc: 0.6389\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 0.6910 - acc: 0.5309 - val_loss: 0.6601 - val_acc: 0.6111\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 589us/step - loss: 0.6805 - acc: 0.5679 - val_loss: 0.6587 - val_acc: 0.6389\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 579us/step - loss: 0.6788 - acc: 0.5556 - val_loss: 0.6580 - val_acc: 0.6389\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 595us/step - loss: 0.6800 - acc: 0.5062 - val_loss: 0.6571 - val_acc: 0.6389\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 635us/step - loss: 0.6840 - acc: 0.5432 - val_loss: 0.6554 - val_acc: 0.6389\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 621us/step - loss: 0.6860 - acc: 0.5062 - val_loss: 0.6559 - val_acc: 0.6389\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 625us/step - loss: 0.6812 - acc: 0.5432 - val_loss: 0.6544 - val_acc: 0.6389\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 651us/step - loss: 0.6795 - acc: 0.5679 - val_loss: 0.6542 - val_acc: 0.6389\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 609us/step - loss: 0.6864 - acc: 0.5556 - val_loss: 0.6554 - val_acc: 0.6389\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 615us/step - loss: 0.6796 - acc: 0.5432 - val_loss: 0.6560 - val_acc: 0.6389\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 0.6828 - acc: 0.5926 - val_loss: 0.6579 - val_acc: 0.6389\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 618us/step - loss: 0.6859 - acc: 0.5432 - val_loss: 0.6583 - val_acc: 0.6389\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.6869 - acc: 0.5185 - val_loss: 0.6571 - val_acc: 0.6389\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 607us/step - loss: 0.6962 - acc: 0.4691 - val_loss: 0.6572 - val_acc: 0.6389\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 618us/step - loss: 0.6796 - acc: 0.5802 - val_loss: 0.6576 - val_acc: 0.6389\n",
      "<keras.callbacks.History object at 0x1a3076aa58>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 202us/step\n",
      "loss: 0.7061431407928467\n",
      "acc: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a35b2a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44851884]\n",
      " [0.4470679 ]\n",
      " [0.44380125]\n",
      " [0.4711763 ]\n",
      " [0.44005868]\n",
      " [0.4604307 ]\n",
      " [0.4651965 ]\n",
      " [0.4881841 ]\n",
      " [0.5123998 ]\n",
      " [0.53906685]\n",
      " [0.56609386]\n",
      " [0.61974865]\n",
      " [0.5829518 ]\n",
      " [0.5453064 ]\n",
      " [0.49532506]\n",
      " [0.4975081 ]\n",
      " [0.4957299 ]\n",
      " [0.5349066 ]\n",
      " [0.54466325]\n",
      " [0.537885  ]\n",
      " [0.54404587]\n",
      " [0.5206021 ]\n",
      " [0.49285966]\n",
      " [0.464291  ]\n",
      " [0.5096214 ]\n",
      " [0.48943505]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.18      0.27        11\n",
      "        1.0       0.59      0.87      0.70        15\n",
      "\n",
      "avg / total       0.55      0.58      0.52        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.43      0.55      0.48        11\n",
      "        1.0       0.58      0.47      0.52        15\n",
      "\n",
      "avg / total       0.52      0.50      0.50        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.39      0.82      0.53        11\n",
      "        1.0       0.33      0.07      0.11        15\n",
      "\n",
      "avg / total       0.36      0.38      0.29        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.91      0.56        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.17      0.38      0.24        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COST\n",
      "Target\tPredict\tConsequence\n",
      "1.0\t-1\tLoss\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "0.0\t1\tLoss\n",
      "1.0\t1\tGain\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "0.0\t1\tLoss\n",
      "0.0\t0\tNothing\n",
      "0.0\t1\tLoss\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t-1\tLoss\n",
      "1.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "\n",
      "\n",
      "[{'month_id': 232, 'QAId': 'COST'}, {'month_id': 233, 'QAId': 'COST'}, {'month_id': 234, 'QAId': 'COST'}, {'month_id': 235, 'QAId': 'COST'}, {'month_id': 236, 'QAId': 'COST'}, {'month_id': 241, 'QAId': 'COST'}, {'month_id': 243, 'QAId': 'COST'}]\n",
      "[{'month_id': 223, 'QAId': 'COST'}, {'month_id': 224, 'QAId': 'COST'}, {'month_id': 225, 'QAId': 'COST'}, {'month_id': 226, 'QAId': 'COST'}, {'month_id': 227, 'QAId': 'COST'}, {'month_id': 228, 'QAId': 'COST'}, {'month_id': 229, 'QAId': 'COST'}, {'month_id': 246, 'QAId': 'COST'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "for j, stock in enumerate(chosen_stocks):\n",
    "  print(stock)\n",
    "  sorted_result = sorted(map(lambda x: x[j], result))\n",
    "  midpt = (sorted_result[-2] + sorted_result[1]) / 2\n",
    "  upper_threshold = midpt * 1.05\n",
    "  lower_threshold = midpt * 0.95\n",
    "  \n",
    "  print(\"Target\\tPredict\\tConsequence\")\n",
    "  for i, r in enumerate(result):\n",
    "    prediction = r[j].item()\n",
    "    target = y_test[i][j].item()\n",
    "    buy_or_sell = 1 if prediction > upper_threshold else (-1 if prediction < lower_threshold else 0)\n",
    "    if prediction > upper_threshold:\n",
    "      buy_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    if prediction < lower_threshold:\n",
    "      sell_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    \n",
    "    to_print = str(target) + \"\\t\" + str(buy_or_sell)\n",
    "    if (buy_or_sell == -1 and target == 0) or (buy_or_sell == 1 and target == 1):\n",
    "      print(to_print + \"\\tGain\")\n",
    "    elif (buy_or_sell == -1 and target == 1) or (buy_or_sell == 1 and target == 0):\n",
    "      print(to_print + \"\\tLoss\")\n",
    "    else:\n",
    "      print(to_print + \"\\tNothing\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       232  COST\n",
       "1       233  COST\n",
       "2       234  COST\n",
       "3       235  COST\n",
       "4       236  COST"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       223  COST\n",
       "1       224  COST\n",
       "2       225  COST\n",
       "3       226  COST\n",
       "4       227  COST"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
