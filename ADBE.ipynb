{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"ADBE\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 3s 36ms/step - loss: 7.8722 - acc: 0.3827 - val_loss: 3.4019 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 3.8124 - acc: 0.3827 - val_loss: 3.0420 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 523us/step - loss: 2.9642 - acc: 0.3827 - val_loss: 2.8515 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 531us/step - loss: 2.6759 - acc: 0.3827 - val_loss: 2.7053 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 2.5205 - acc: 0.3827 - val_loss: 2.5894 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 527us/step - loss: 2.4227 - acc: 0.3827 - val_loss: 2.4953 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 2.3229 - acc: 0.3827 - val_loss: 2.4161 - val_acc: 0.3333\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 472us/step - loss: 2.2444 - acc: 0.3827 - val_loss: 2.3471 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 2.1848 - acc: 0.3827 - val_loss: 2.2866 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 2.1367 - acc: 0.3827 - val_loss: 2.2321 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 483us/step - loss: 2.0794 - acc: 0.3827 - val_loss: 2.1825 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 2.0354 - acc: 0.3827 - val_loss: 2.1376 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 1.9803 - acc: 0.3827 - val_loss: 2.0959 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 1.9659 - acc: 0.3827 - val_loss: 2.0576 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 1.9175 - acc: 0.3827 - val_loss: 2.0214 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 1.8851 - acc: 0.3827 - val_loss: 1.9875 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 1.8524 - acc: 0.3827 - val_loss: 1.9548 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 1.8218 - acc: 0.3827 - val_loss: 1.9236 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 1.7850 - acc: 0.3827 - val_loss: 1.8938 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 1.7538 - acc: 0.3827 - val_loss: 1.8648 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 1.7297 - acc: 0.3827 - val_loss: 1.8370 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 486us/step - loss: 1.7163 - acc: 0.3827 - val_loss: 1.8095 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 484us/step - loss: 1.6957 - acc: 0.3827 - val_loss: 1.7826 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 475us/step - loss: 1.6639 - acc: 0.3827 - val_loss: 1.7563 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 462us/step - loss: 1.6366 - acc: 0.3827 - val_loss: 1.7307 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 1.6092 - acc: 0.3827 - val_loss: 1.7055 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 476us/step - loss: 1.5818 - acc: 0.3827 - val_loss: 1.6811 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 1.5678 - acc: 0.3827 - val_loss: 1.6572 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 1.5491 - acc: 0.3827 - val_loss: 1.6336 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 512us/step - loss: 1.5246 - acc: 0.3827 - val_loss: 1.6103 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 1.4974 - acc: 0.3827 - val_loss: 1.5871 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 1.4866 - acc: 0.3827 - val_loss: 1.5641 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 557us/step - loss: 1.4659 - acc: 0.3827 - val_loss: 1.5415 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 1.4330 - acc: 0.3827 - val_loss: 1.5193 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 1.4141 - acc: 0.3827 - val_loss: 1.4970 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 462us/step - loss: 1.4008 - acc: 0.3827 - val_loss: 1.4746 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 463us/step - loss: 1.3800 - acc: 0.3827 - val_loss: 1.4524 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 1.3603 - acc: 0.3827 - val_loss: 1.4307 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 1.3383 - acc: 0.3827 - val_loss: 1.4088 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 1.3185 - acc: 0.3827 - val_loss: 1.3870 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 1.2957 - acc: 0.3827 - val_loss: 1.3652 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 1.2700 - acc: 0.3827 - val_loss: 1.3429 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 476us/step - loss: 1.2513 - acc: 0.3827 - val_loss: 1.3208 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 478us/step - loss: 1.2344 - acc: 0.3827 - val_loss: 1.2989 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 478us/step - loss: 1.2136 - acc: 0.3827 - val_loss: 1.2773 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 1.1989 - acc: 0.3827 - val_loss: 1.2556 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 1.1668 - acc: 0.3827 - val_loss: 1.2339 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 462us/step - loss: 1.1546 - acc: 0.3827 - val_loss: 1.2126 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 474us/step - loss: 1.1387 - acc: 0.3827 - val_loss: 1.1912 - val_acc: 0.3333\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 1.1225 - acc: 0.3827 - val_loss: 1.1702 - val_acc: 0.3333\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 462us/step - loss: 1.1054 - acc: 0.3827 - val_loss: 1.1493 - val_acc: 0.3333\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 1.0766 - acc: 0.3827 - val_loss: 1.1285 - val_acc: 0.3333\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 1.0692 - acc: 0.3827 - val_loss: 1.1083 - val_acc: 0.3333\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 1.0500 - acc: 0.3827 - val_loss: 1.0883 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 1.0208 - acc: 0.3827 - val_loss: 1.0684 - val_acc: 0.3333\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 522us/step - loss: 1.0042 - acc: 0.3827 - val_loss: 1.0487 - val_acc: 0.3333\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 1.0014 - acc: 0.3827 - val_loss: 1.0292 - val_acc: 0.3333\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.9655 - acc: 0.3827 - val_loss: 1.0101 - val_acc: 0.3333\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 0.9569 - acc: 0.3827 - val_loss: 0.9913 - val_acc: 0.3333\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 0.9191 - acc: 0.3827 - val_loss: 0.9727 - val_acc: 0.3333\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 0.9265 - acc: 0.3827 - val_loss: 0.9543 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 481us/step - loss: 0.8959 - acc: 0.3827 - val_loss: 0.9360 - val_acc: 0.3333\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 0.8854 - acc: 0.3827 - val_loss: 0.9176 - val_acc: 0.3333\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.8841 - acc: 0.3827 - val_loss: 0.8996 - val_acc: 0.3333\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.8583 - acc: 0.3827 - val_loss: 0.8823 - val_acc: 0.3333\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.8373 - acc: 0.3827 - val_loss: 0.8654 - val_acc: 0.3333\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.8290 - acc: 0.3827 - val_loss: 0.8490 - val_acc: 0.3333\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 0.8062 - acc: 0.3827 - val_loss: 0.8332 - val_acc: 0.3333\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 0.8028 - acc: 0.3827 - val_loss: 0.8174 - val_acc: 0.3333\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 508us/step - loss: 0.7872 - acc: 0.3951 - val_loss: 0.8024 - val_acc: 0.3333\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 0.7717 - acc: 0.3827 - val_loss: 0.7877 - val_acc: 0.3333\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 504us/step - loss: 0.7608 - acc: 0.3827 - val_loss: 0.7740 - val_acc: 0.3333\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 0.7494 - acc: 0.4074 - val_loss: 0.7608 - val_acc: 0.3333\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 491us/step - loss: 0.7390 - acc: 0.4074 - val_loss: 0.7481 - val_acc: 0.3333\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.7231 - acc: 0.4074 - val_loss: 0.7357 - val_acc: 0.3333\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 0.7139 - acc: 0.4444 - val_loss: 0.7241 - val_acc: 0.3333\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.7099 - acc: 0.4444 - val_loss: 0.7135 - val_acc: 0.3611\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 0.6917 - acc: 0.4691 - val_loss: 0.7035 - val_acc: 0.5556\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 506us/step - loss: 0.6912 - acc: 0.4938 - val_loss: 0.6950 - val_acc: 0.5000\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.6970 - acc: 0.5062 - val_loss: 0.6875 - val_acc: 0.5833\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 0.6754 - acc: 0.5679 - val_loss: 0.6805 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.6888 - acc: 0.5185 - val_loss: 0.6739 - val_acc: 0.6667\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6693 - acc: 0.5432 - val_loss: 0.6681 - val_acc: 0.6389\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 501us/step - loss: 0.6794 - acc: 0.5802 - val_loss: 0.6627 - val_acc: 0.6667\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.6673 - acc: 0.5556 - val_loss: 0.6581 - val_acc: 0.6389\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.6760 - acc: 0.5556 - val_loss: 0.6541 - val_acc: 0.6111\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6765 - acc: 0.5802 - val_loss: 0.6511 - val_acc: 0.6111\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 499us/step - loss: 0.6827 - acc: 0.6296 - val_loss: 0.6486 - val_acc: 0.6111\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.6782 - acc: 0.6049 - val_loss: 0.6472 - val_acc: 0.6389\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 0.6770 - acc: 0.5802 - val_loss: 0.6460 - val_acc: 0.6389\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 536us/step - loss: 0.7038 - acc: 0.5185 - val_loss: 0.6451 - val_acc: 0.6389\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.6638 - acc: 0.5926 - val_loss: 0.6445 - val_acc: 0.6389\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6737 - acc: 0.6049 - val_loss: 0.6445 - val_acc: 0.6389\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 484us/step - loss: 0.6567 - acc: 0.6420 - val_loss: 0.6441 - val_acc: 0.6389\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6641 - acc: 0.6049 - val_loss: 0.6438 - val_acc: 0.6667\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.6825 - acc: 0.5926 - val_loss: 0.6437 - val_acc: 0.6667\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 488us/step - loss: 0.6747 - acc: 0.5926 - val_loss: 0.6437 - val_acc: 0.6667\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6733 - acc: 0.5309 - val_loss: 0.6438 - val_acc: 0.6667\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6615 - acc: 0.6173 - val_loss: 0.6435 - val_acc: 0.6667\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 470us/step - loss: 0.6664 - acc: 0.5926 - val_loss: 0.6434 - val_acc: 0.6667\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.6727 - acc: 0.6049 - val_loss: 0.6438 - val_acc: 0.6667\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6692 - acc: 0.6173 - val_loss: 0.6440 - val_acc: 0.6667\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 0.6651 - acc: 0.6173 - val_loss: 0.6440 - val_acc: 0.6667\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 502us/step - loss: 0.6699 - acc: 0.5802 - val_loss: 0.6448 - val_acc: 0.6389\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 0.6746 - acc: 0.5679 - val_loss: 0.6450 - val_acc: 0.6389\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 458us/step - loss: 0.6861 - acc: 0.5556 - val_loss: 0.6456 - val_acc: 0.6389\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 0.6577 - acc: 0.6173 - val_loss: 0.6460 - val_acc: 0.6389\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 0.6718 - acc: 0.6049 - val_loss: 0.6465 - val_acc: 0.6389\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 486us/step - loss: 0.6665 - acc: 0.6296 - val_loss: 0.6462 - val_acc: 0.6389\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 469us/step - loss: 0.6755 - acc: 0.5802 - val_loss: 0.6462 - val_acc: 0.6389\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 475us/step - loss: 0.6726 - acc: 0.6296 - val_loss: 0.6466 - val_acc: 0.6389\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.6608 - acc: 0.6296 - val_loss: 0.6466 - val_acc: 0.6389\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.6496 - acc: 0.6049 - val_loss: 0.6460 - val_acc: 0.6389\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.6790 - acc: 0.5926 - val_loss: 0.6456 - val_acc: 0.6389\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 473us/step - loss: 0.6555 - acc: 0.6049 - val_loss: 0.6454 - val_acc: 0.6389\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 0.6545 - acc: 0.6543 - val_loss: 0.6450 - val_acc: 0.6389\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.6607 - acc: 0.6049 - val_loss: 0.6452 - val_acc: 0.6389\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 473us/step - loss: 0.6630 - acc: 0.5926 - val_loss: 0.6452 - val_acc: 0.6389\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.6611 - acc: 0.5926 - val_loss: 0.6450 - val_acc: 0.6389\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 491us/step - loss: 0.6497 - acc: 0.5926 - val_loss: 0.6450 - val_acc: 0.6389\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 0.6410 - acc: 0.6667 - val_loss: 0.6449 - val_acc: 0.6389\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 501us/step - loss: 0.6678 - acc: 0.6420 - val_loss: 0.6446 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 468us/step - loss: 0.6677 - acc: 0.6420 - val_loss: 0.6447 - val_acc: 0.6667\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 499us/step - loss: 0.6653 - acc: 0.6173 - val_loss: 0.6451 - val_acc: 0.6389\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.6481 - acc: 0.6296 - val_loss: 0.6458 - val_acc: 0.6389\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6713 - acc: 0.6296 - val_loss: 0.6464 - val_acc: 0.6389\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6821 - acc: 0.5802 - val_loss: 0.6468 - val_acc: 0.6389\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 519us/step - loss: 0.6771 - acc: 0.5926 - val_loss: 0.6471 - val_acc: 0.6389\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 502us/step - loss: 0.6620 - acc: 0.6173 - val_loss: 0.6472 - val_acc: 0.6389\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6450 - acc: 0.6296 - val_loss: 0.6474 - val_acc: 0.6389\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6660 - acc: 0.6173 - val_loss: 0.6472 - val_acc: 0.6389\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 524us/step - loss: 0.6718 - acc: 0.6049 - val_loss: 0.6475 - val_acc: 0.6111\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 523us/step - loss: 0.6623 - acc: 0.5926 - val_loss: 0.6477 - val_acc: 0.6111\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.6830 - acc: 0.5926 - val_loss: 0.6480 - val_acc: 0.6111\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.6773 - acc: 0.5679 - val_loss: 0.6480 - val_acc: 0.6111\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.6622 - acc: 0.6049 - val_loss: 0.6477 - val_acc: 0.6111\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.6532 - acc: 0.6173 - val_loss: 0.6467 - val_acc: 0.6389\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.6818 - acc: 0.5802 - val_loss: 0.6472 - val_acc: 0.6389\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 0.6787 - acc: 0.6296 - val_loss: 0.6469 - val_acc: 0.6389\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.6655 - acc: 0.6420 - val_loss: 0.6466 - val_acc: 0.6389\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.6561 - acc: 0.6173 - val_loss: 0.6461 - val_acc: 0.6389\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6665 - acc: 0.6296 - val_loss: 0.6455 - val_acc: 0.6667\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6554 - acc: 0.6049 - val_loss: 0.6452 - val_acc: 0.6667\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.6584 - acc: 0.6173 - val_loss: 0.6450 - val_acc: 0.6667\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.6697 - acc: 0.5926 - val_loss: 0.6446 - val_acc: 0.6667\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 0.6666 - acc: 0.5926 - val_loss: 0.6450 - val_acc: 0.6667\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 476us/step - loss: 0.6810 - acc: 0.5802 - val_loss: 0.6456 - val_acc: 0.6667\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 481us/step - loss: 0.6523 - acc: 0.6543 - val_loss: 0.6458 - val_acc: 0.6667\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 505us/step - loss: 0.6651 - acc: 0.6049 - val_loss: 0.6460 - val_acc: 0.6389\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 0.6845 - acc: 0.6049 - val_loss: 0.6462 - val_acc: 0.6389\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 512us/step - loss: 0.6706 - acc: 0.6173 - val_loss: 0.6465 - val_acc: 0.6389\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 499us/step - loss: 0.6700 - acc: 0.6296 - val_loss: 0.6476 - val_acc: 0.6111\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6715 - acc: 0.6049 - val_loss: 0.6487 - val_acc: 0.6111\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 504us/step - loss: 0.6708 - acc: 0.5926 - val_loss: 0.6498 - val_acc: 0.6111\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 502us/step - loss: 0.6683 - acc: 0.5802 - val_loss: 0.6511 - val_acc: 0.6111\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.6641 - acc: 0.5802 - val_loss: 0.6518 - val_acc: 0.5833\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.6584 - acc: 0.6296 - val_loss: 0.6518 - val_acc: 0.5833\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6670 - acc: 0.6543 - val_loss: 0.6519 - val_acc: 0.5833\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6573 - acc: 0.6173 - val_loss: 0.6513 - val_acc: 0.6111\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.6649 - acc: 0.5926 - val_loss: 0.6513 - val_acc: 0.6111\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 475us/step - loss: 0.6691 - acc: 0.5926 - val_loss: 0.6511 - val_acc: 0.6111\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6532 - acc: 0.6420 - val_loss: 0.6509 - val_acc: 0.6111\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 504us/step - loss: 0.6510 - acc: 0.5926 - val_loss: 0.6503 - val_acc: 0.6111\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 506us/step - loss: 0.6591 - acc: 0.6173 - val_loss: 0.6494 - val_acc: 0.6111\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.6791 - acc: 0.5926 - val_loss: 0.6489 - val_acc: 0.6111\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 488us/step - loss: 0.6410 - acc: 0.6296 - val_loss: 0.6485 - val_acc: 0.6111\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 0.6619 - acc: 0.5802 - val_loss: 0.6484 - val_acc: 0.6111\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6794 - acc: 0.6049 - val_loss: 0.6488 - val_acc: 0.6111\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 476us/step - loss: 0.6510 - acc: 0.6420 - val_loss: 0.6486 - val_acc: 0.6111\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6430 - acc: 0.6420 - val_loss: 0.6488 - val_acc: 0.6111\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.6556 - acc: 0.6049 - val_loss: 0.6488 - val_acc: 0.6111\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.6539 - acc: 0.6296 - val_loss: 0.6484 - val_acc: 0.6111\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 481us/step - loss: 0.6668 - acc: 0.5926 - val_loss: 0.6484 - val_acc: 0.6111\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6403 - acc: 0.6543 - val_loss: 0.6484 - val_acc: 0.6111\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 0.6699 - acc: 0.6049 - val_loss: 0.6482 - val_acc: 0.6111\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 0.6694 - acc: 0.6296 - val_loss: 0.6485 - val_acc: 0.6111\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 510us/step - loss: 0.6514 - acc: 0.6049 - val_loss: 0.6484 - val_acc: 0.6111\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.6623 - acc: 0.5926 - val_loss: 0.6478 - val_acc: 0.6111\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 501us/step - loss: 0.6604 - acc: 0.5926 - val_loss: 0.6472 - val_acc: 0.6111\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.6693 - acc: 0.5802 - val_loss: 0.6478 - val_acc: 0.6111\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.6714 - acc: 0.6173 - val_loss: 0.6488 - val_acc: 0.6111\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6645 - acc: 0.6173 - val_loss: 0.6488 - val_acc: 0.6111\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 452us/step - loss: 0.6491 - acc: 0.5926 - val_loss: 0.6497 - val_acc: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 0.6661 - acc: 0.6173 - val_loss: 0.6503 - val_acc: 0.6111\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.6749 - acc: 0.5926 - val_loss: 0.6508 - val_acc: 0.6111\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 472us/step - loss: 0.6583 - acc: 0.6049 - val_loss: 0.6520 - val_acc: 0.5833\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.6671 - acc: 0.5926 - val_loss: 0.6524 - val_acc: 0.5833\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 0.6448 - acc: 0.6296 - val_loss: 0.6517 - val_acc: 0.5833\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 481us/step - loss: 0.6655 - acc: 0.5926 - val_loss: 0.6514 - val_acc: 0.5833\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 0.6407 - acc: 0.6420 - val_loss: 0.6505 - val_acc: 0.6111\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 508us/step - loss: 0.6496 - acc: 0.6296 - val_loss: 0.6500 - val_acc: 0.6111\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6521 - acc: 0.6296 - val_loss: 0.6494 - val_acc: 0.6111\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6672 - acc: 0.6543 - val_loss: 0.6497 - val_acc: 0.6111\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 491us/step - loss: 0.6769 - acc: 0.6173 - val_loss: 0.6503 - val_acc: 0.6111\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 0.6601 - acc: 0.6173 - val_loss: 0.6503 - val_acc: 0.6111\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 486us/step - loss: 0.6630 - acc: 0.6420 - val_loss: 0.6510 - val_acc: 0.5833\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 0.6925 - acc: 0.6173 - val_loss: 0.6512 - val_acc: 0.5833\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6721 - acc: 0.6296 - val_loss: 0.6517 - val_acc: 0.5833\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.6483 - acc: 0.6049 - val_loss: 0.6521 - val_acc: 0.5833\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.6464 - acc: 0.6173 - val_loss: 0.6525 - val_acc: 0.5833\n",
      "<keras.callbacks.History object at 0x1a3e836470>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 155us/step\n",
      "loss: 0.6992578506469727\n",
      "acc: 0.3461538553237915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a478a2c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5186666 ]\n",
      " [0.50272137]\n",
      " [0.49509692]\n",
      " [0.50783515]\n",
      " [0.49503946]\n",
      " [0.49134734]\n",
      " [0.50436056]\n",
      " [0.47616613]\n",
      " [0.46926677]\n",
      " [0.48115957]\n",
      " [0.49921754]\n",
      " [0.47565764]\n",
      " [0.49731094]\n",
      " [0.47529972]\n",
      " [0.43182454]\n",
      " [0.46100533]\n",
      " [0.50745785]\n",
      " [0.52050674]\n",
      " [0.5243592 ]\n",
      " [0.5046872 ]\n",
      " [0.5344757 ]\n",
      " [0.5241608 ]\n",
      " [0.5058798 ]\n",
      " [0.4679069 ]\n",
      " [0.4805373 ]\n",
      " [0.71058255]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.72      0.95      0.82        19\n",
      "\n",
      "avg / total       0.53      0.69      0.60        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.14      0.29      0.19         7\n",
      "        1.0       0.58      0.37      0.45        19\n",
      "\n",
      "avg / total       0.46      0.35      0.38        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 1\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "[{'month_id': 223, 'QAId': 'ADBE'}, {'month_id': 226, 'QAId': 'ADBE'}, {'month_id': 239, 'QAId': 'ADBE'}, {'month_id': 240, 'QAId': 'ADBE'}, {'month_id': 241, 'QAId': 'ADBE'}, {'month_id': 243, 'QAId': 'ADBE'}, {'month_id': 244, 'QAId': 'ADBE'}, {'month_id': 248, 'QAId': 'ADBE'}]\n",
      "[{'month_id': 237, 'QAId': 'ADBE'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "def second_largest(numbers):\n",
    "    count = 0\n",
    "    m1 = m2 = float('-inf')\n",
    "    for x in numbers:\n",
    "        count += 1\n",
    "        if x > m2:\n",
    "            if x >= m1:\n",
    "                m1, m2 = x, m1            \n",
    "            else:\n",
    "                m2 = x\n",
    "    return m2 if count >= 2 else None\n",
    "\n",
    "midpt = (second_largest(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1.05 else (-1 if r.item() < midpt * 0.95 else 0)\n",
    "  if r.item() > midpt * 1.05:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.95:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       237  ADBE"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
