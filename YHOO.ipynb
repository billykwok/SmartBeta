{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12 # or 54\n",
    "lookback = 3\n",
    "chosen_stocks = [\"YHOO\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 4.7696 - acc: 0.5062 - val_loss: 3.5938 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 565us/step - loss: 2.5442 - acc: 0.5062 - val_loss: 3.0827 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 587us/step - loss: 2.1665 - acc: 0.5062 - val_loss: 2.8565 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 606us/step - loss: 2.0551 - acc: 0.5062 - val_loss: 2.7192 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 1.9853 - acc: 0.5062 - val_loss: 2.6236 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 589us/step - loss: 1.9188 - acc: 0.5062 - val_loss: 2.5533 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 602us/step - loss: 1.8556 - acc: 0.5062 - val_loss: 2.4976 - val_acc: 0.3333\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 1.8215 - acc: 0.5062 - val_loss: 2.4496 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 1.7854 - acc: 0.5062 - val_loss: 2.4077 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 592us/step - loss: 1.7609 - acc: 0.5062 - val_loss: 2.3701 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 572us/step - loss: 1.7231 - acc: 0.5062 - val_loss: 2.3347 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 594us/step - loss: 1.7064 - acc: 0.5062 - val_loss: 2.3023 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 587us/step - loss: 1.6708 - acc: 0.5062 - val_loss: 2.2715 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 575us/step - loss: 1.6567 - acc: 0.5062 - val_loss: 2.2418 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 1.6412 - acc: 0.5062 - val_loss: 2.2126 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 1.6091 - acc: 0.5062 - val_loss: 2.1837 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 580us/step - loss: 1.5950 - acc: 0.5062 - val_loss: 2.1553 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 1.5636 - acc: 0.5062 - val_loss: 2.1266 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 1.5533 - acc: 0.5062 - val_loss: 2.0979 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 1.5355 - acc: 0.5062 - val_loss: 2.0689 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 576us/step - loss: 1.5100 - acc: 0.5062 - val_loss: 2.0407 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 1.4916 - acc: 0.5062 - val_loss: 2.0129 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 1.4711 - acc: 0.5062 - val_loss: 1.9850 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 1.4491 - acc: 0.5062 - val_loss: 1.9578 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 554us/step - loss: 1.4323 - acc: 0.5062 - val_loss: 1.9313 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 1.4114 - acc: 0.5062 - val_loss: 1.9052 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 588us/step - loss: 1.3964 - acc: 0.5062 - val_loss: 1.8792 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 603us/step - loss: 1.3880 - acc: 0.5062 - val_loss: 1.8532 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 1.3608 - acc: 0.5062 - val_loss: 1.8276 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 578us/step - loss: 1.3455 - acc: 0.5062 - val_loss: 1.8032 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 1.3268 - acc: 0.5062 - val_loss: 1.7786 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 596us/step - loss: 1.3111 - acc: 0.5062 - val_loss: 1.7547 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 577us/step - loss: 1.2973 - acc: 0.5062 - val_loss: 1.7315 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 588us/step - loss: 1.2796 - acc: 0.5062 - val_loss: 1.7089 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 565us/step - loss: 1.2644 - acc: 0.5062 - val_loss: 1.6872 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 1.2482 - acc: 0.5062 - val_loss: 1.6655 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 1.2315 - acc: 0.5062 - val_loss: 1.6447 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 1.2137 - acc: 0.5062 - val_loss: 1.6238 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 1.2087 - acc: 0.5062 - val_loss: 1.6038 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 1.1972 - acc: 0.5062 - val_loss: 1.5839 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 1.1764 - acc: 0.5062 - val_loss: 1.5644 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 1.1559 - acc: 0.5062 - val_loss: 1.5448 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 1.1501 - acc: 0.5062 - val_loss: 1.5259 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 1.1345 - acc: 0.5062 - val_loss: 1.5069 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 1.1254 - acc: 0.5062 - val_loss: 1.4881 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 1.1065 - acc: 0.5062 - val_loss: 1.4692 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 1.0970 - acc: 0.5062 - val_loss: 1.4505 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 1.0889 - acc: 0.5062 - val_loss: 1.4325 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 551us/step - loss: 1.0720 - acc: 0.5062 - val_loss: 1.4142 - val_acc: 0.3333\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 586us/step - loss: 1.0667 - acc: 0.5062 - val_loss: 1.3962 - val_acc: 0.3333\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 1.0407 - acc: 0.5062 - val_loss: 1.3780 - val_acc: 0.3333\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 547us/step - loss: 1.0379 - acc: 0.5062 - val_loss: 1.3597 - val_acc: 0.3333\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 649us/step - loss: 1.0258 - acc: 0.5062 - val_loss: 1.3417 - val_acc: 0.3333\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 620us/step - loss: 1.0107 - acc: 0.5062 - val_loss: 1.3242 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 584us/step - loss: 0.9973 - acc: 0.5062 - val_loss: 1.3060 - val_acc: 0.3333\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.9861 - acc: 0.5062 - val_loss: 1.2884 - val_acc: 0.3333\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.9730 - acc: 0.5062 - val_loss: 1.2711 - val_acc: 0.3333\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.9677 - acc: 0.5062 - val_loss: 1.2536 - val_acc: 0.3333\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 609us/step - loss: 0.9532 - acc: 0.5062 - val_loss: 1.2361 - val_acc: 0.3333\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 609us/step - loss: 0.9433 - acc: 0.5062 - val_loss: 1.2192 - val_acc: 0.3333\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.9434 - acc: 0.5062 - val_loss: 1.2021 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 598us/step - loss: 0.9243 - acc: 0.5062 - val_loss: 1.1856 - val_acc: 0.3333\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 582us/step - loss: 0.9080 - acc: 0.5062 - val_loss: 1.1691 - val_acc: 0.3333\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.9057 - acc: 0.5062 - val_loss: 1.1524 - val_acc: 0.3333\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 531us/step - loss: 0.8996 - acc: 0.5062 - val_loss: 1.1359 - val_acc: 0.3333\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 0.8733 - acc: 0.5062 - val_loss: 1.1198 - val_acc: 0.3333\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.8712 - acc: 0.5062 - val_loss: 1.1041 - val_acc: 0.3333\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 0.8630 - acc: 0.5062 - val_loss: 1.0881 - val_acc: 0.3333\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 0.8519 - acc: 0.5062 - val_loss: 1.0728 - val_acc: 0.3333\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 573us/step - loss: 0.8418 - acc: 0.5062 - val_loss: 1.0574 - val_acc: 0.3333\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.8319 - acc: 0.5062 - val_loss: 1.0426 - val_acc: 0.3333\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.8195 - acc: 0.5062 - val_loss: 1.0274 - val_acc: 0.3333\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 565us/step - loss: 0.8165 - acc: 0.5062 - val_loss: 1.0130 - val_acc: 0.3333\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.8027 - acc: 0.5062 - val_loss: 0.9984 - val_acc: 0.3333\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 536us/step - loss: 0.8037 - acc: 0.5062 - val_loss: 0.9841 - val_acc: 0.3333\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 0.7908 - acc: 0.5062 - val_loss: 0.9706 - val_acc: 0.3333\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.7763 - acc: 0.5062 - val_loss: 0.9577 - val_acc: 0.3333\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.7739 - acc: 0.5062 - val_loss: 0.9446 - val_acc: 0.3333\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 0.7732 - acc: 0.5062 - val_loss: 0.9318 - val_acc: 0.3333\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.7593 - acc: 0.5062 - val_loss: 0.9188 - val_acc: 0.3333\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.7547 - acc: 0.5062 - val_loss: 0.9067 - val_acc: 0.3333\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 575us/step - loss: 0.7500 - acc: 0.5062 - val_loss: 0.8948 - val_acc: 0.3333\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 0.7507 - acc: 0.5062 - val_loss: 0.8836 - val_acc: 0.3333\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 583us/step - loss: 0.7366 - acc: 0.5062 - val_loss: 0.8729 - val_acc: 0.3333\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 579us/step - loss: 0.7331 - acc: 0.5062 - val_loss: 0.8622 - val_acc: 0.3333\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.7286 - acc: 0.5062 - val_loss: 0.8515 - val_acc: 0.3333\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.7184 - acc: 0.5062 - val_loss: 0.8409 - val_acc: 0.3333\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.7088 - acc: 0.5062 - val_loss: 0.8309 - val_acc: 0.3333\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.7043 - acc: 0.4938 - val_loss: 0.8217 - val_acc: 0.3333\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.7062 - acc: 0.5062 - val_loss: 0.8129 - val_acc: 0.3333\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.7125 - acc: 0.4938 - val_loss: 0.8043 - val_acc: 0.3333\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 0.7066 - acc: 0.5309 - val_loss: 0.7965 - val_acc: 0.3333\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.7076 - acc: 0.4938 - val_loss: 0.7894 - val_acc: 0.3333\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 0.6929 - acc: 0.5185 - val_loss: 0.7822 - val_acc: 0.3333\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 0.6990 - acc: 0.5185 - val_loss: 0.7756 - val_acc: 0.3333\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 576us/step - loss: 0.6912 - acc: 0.5062 - val_loss: 0.7691 - val_acc: 0.3333\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 0.7030 - acc: 0.5556 - val_loss: 0.7630 - val_acc: 0.3333\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.7005 - acc: 0.4815 - val_loss: 0.7573 - val_acc: 0.3333\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 546us/step - loss: 0.6831 - acc: 0.5802 - val_loss: 0.7519 - val_acc: 0.3333\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6839 - acc: 0.4815 - val_loss: 0.7470 - val_acc: 0.3333\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.6910 - acc: 0.5432 - val_loss: 0.7428 - val_acc: 0.3333\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 563us/step - loss: 0.6818 - acc: 0.5185 - val_loss: 0.7388 - val_acc: 0.3333\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6812 - acc: 0.5556 - val_loss: 0.7361 - val_acc: 0.3333\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 557us/step - loss: 0.6870 - acc: 0.4938 - val_loss: 0.7332 - val_acc: 0.3056\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 551us/step - loss: 0.6788 - acc: 0.5679 - val_loss: 0.7307 - val_acc: 0.3056\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 534us/step - loss: 0.6934 - acc: 0.4691 - val_loss: 0.7284 - val_acc: 0.3333\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 519us/step - loss: 0.6854 - acc: 0.5309 - val_loss: 0.7266 - val_acc: 0.3333\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6870 - acc: 0.5309 - val_loss: 0.7250 - val_acc: 0.3611\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 523us/step - loss: 0.6914 - acc: 0.5185 - val_loss: 0.7230 - val_acc: 0.3611\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 534us/step - loss: 0.6899 - acc: 0.5309 - val_loss: 0.7215 - val_acc: 0.3611\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.6874 - acc: 0.5185 - val_loss: 0.7199 - val_acc: 0.3611\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 529us/step - loss: 0.6842 - acc: 0.5556 - val_loss: 0.7185 - val_acc: 0.3611\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.6826 - acc: 0.5309 - val_loss: 0.7165 - val_acc: 0.3611\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.6814 - acc: 0.5802 - val_loss: 0.7146 - val_acc: 0.4167\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6792 - acc: 0.5432 - val_loss: 0.7136 - val_acc: 0.4167\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.6825 - acc: 0.5432 - val_loss: 0.7124 - val_acc: 0.4167\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 532us/step - loss: 0.6863 - acc: 0.5309 - val_loss: 0.7111 - val_acc: 0.4444\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.6886 - acc: 0.5185 - val_loss: 0.7098 - val_acc: 0.4444\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.6736 - acc: 0.5679 - val_loss: 0.7090 - val_acc: 0.4444\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6822 - acc: 0.5802 - val_loss: 0.7077 - val_acc: 0.4444\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6807 - acc: 0.5432 - val_loss: 0.7070 - val_acc: 0.4722\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 557us/step - loss: 0.6816 - acc: 0.5802 - val_loss: 0.7062 - val_acc: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 564us/step - loss: 0.6834 - acc: 0.5062 - val_loss: 0.7065 - val_acc: 0.4444\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 594us/step - loss: 0.6727 - acc: 0.5556 - val_loss: 0.7061 - val_acc: 0.4167\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 0.6750 - acc: 0.5556 - val_loss: 0.7067 - val_acc: 0.4444\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 593us/step - loss: 0.6715 - acc: 0.5802 - val_loss: 0.7063 - val_acc: 0.4444\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 0.6762 - acc: 0.5432 - val_loss: 0.7069 - val_acc: 0.4444\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 584us/step - loss: 0.6840 - acc: 0.5309 - val_loss: 0.7074 - val_acc: 0.4444\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6862 - acc: 0.4938 - val_loss: 0.7078 - val_acc: 0.4722\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 585us/step - loss: 0.6744 - acc: 0.5802 - val_loss: 0.7082 - val_acc: 0.4722\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 584us/step - loss: 0.6763 - acc: 0.5556 - val_loss: 0.7081 - val_acc: 0.4722\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 603us/step - loss: 0.6818 - acc: 0.5432 - val_loss: 0.7072 - val_acc: 0.4722\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 603us/step - loss: 0.6747 - acc: 0.5556 - val_loss: 0.7070 - val_acc: 0.4722\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 0.6819 - acc: 0.5926 - val_loss: 0.7069 - val_acc: 0.4722\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6778 - acc: 0.5432 - val_loss: 0.7069 - val_acc: 0.4722\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 522us/step - loss: 0.6876 - acc: 0.4815 - val_loss: 0.7066 - val_acc: 0.4722\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.6744 - acc: 0.5926 - val_loss: 0.7071 - val_acc: 0.4722\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6729 - acc: 0.5679 - val_loss: 0.7070 - val_acc: 0.4722\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 520us/step - loss: 0.6824 - acc: 0.5185 - val_loss: 0.7066 - val_acc: 0.4722\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 532us/step - loss: 0.6786 - acc: 0.5309 - val_loss: 0.7060 - val_acc: 0.4722\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 524us/step - loss: 0.6934 - acc: 0.4691 - val_loss: 0.7053 - val_acc: 0.4722\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 524us/step - loss: 0.6730 - acc: 0.5802 - val_loss: 0.7043 - val_acc: 0.3889\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 534us/step - loss: 0.6851 - acc: 0.5309 - val_loss: 0.7040 - val_acc: 0.3889\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 522us/step - loss: 0.6787 - acc: 0.5309 - val_loss: 0.7032 - val_acc: 0.3611\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6763 - acc: 0.5432 - val_loss: 0.7030 - val_acc: 0.3611\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 520us/step - loss: 0.6759 - acc: 0.5432 - val_loss: 0.7028 - val_acc: 0.3611\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 543us/step - loss: 0.6669 - acc: 0.5926 - val_loss: 0.7023 - val_acc: 0.3611\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6760 - acc: 0.5802 - val_loss: 0.7024 - val_acc: 0.3611\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.6751 - acc: 0.5556 - val_loss: 0.7021 - val_acc: 0.3611\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6794 - acc: 0.5679 - val_loss: 0.7007 - val_acc: 0.3889\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 551us/step - loss: 0.6602 - acc: 0.6049 - val_loss: 0.7010 - val_acc: 0.3611\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6813 - acc: 0.4938 - val_loss: 0.7005 - val_acc: 0.3889\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 588us/step - loss: 0.6820 - acc: 0.5062 - val_loss: 0.7001 - val_acc: 0.3889\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.6755 - acc: 0.5926 - val_loss: 0.7004 - val_acc: 0.3611\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6751 - acc: 0.5309 - val_loss: 0.7008 - val_acc: 0.3611\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.6699 - acc: 0.5679 - val_loss: 0.7008 - val_acc: 0.3611\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6702 - acc: 0.5556 - val_loss: 0.7008 - val_acc: 0.3611\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 529us/step - loss: 0.6769 - acc: 0.5432 - val_loss: 0.7010 - val_acc: 0.3333\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 0.6694 - acc: 0.5926 - val_loss: 0.7009 - val_acc: 0.3333\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6711 - acc: 0.5679 - val_loss: 0.7007 - val_acc: 0.3333\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 0.6824 - acc: 0.5432 - val_loss: 0.6998 - val_acc: 0.3611\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 0.6698 - acc: 0.5679 - val_loss: 0.6997 - val_acc: 0.3611\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6782 - acc: 0.5432 - val_loss: 0.6988 - val_acc: 0.3611\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 0.6648 - acc: 0.5432 - val_loss: 0.6985 - val_acc: 0.3611\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 531us/step - loss: 0.6790 - acc: 0.5556 - val_loss: 0.6983 - val_acc: 0.3611\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 524us/step - loss: 0.6776 - acc: 0.5185 - val_loss: 0.6980 - val_acc: 0.3611\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6779 - acc: 0.5802 - val_loss: 0.6982 - val_acc: 0.3611\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.6664 - acc: 0.6296 - val_loss: 0.6979 - val_acc: 0.3611\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6787 - acc: 0.5556 - val_loss: 0.6973 - val_acc: 0.3611\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 0.6749 - acc: 0.5679 - val_loss: 0.6975 - val_acc: 0.3611\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 537us/step - loss: 0.6649 - acc: 0.5556 - val_loss: 0.6973 - val_acc: 0.3611\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.6781 - acc: 0.5556 - val_loss: 0.6972 - val_acc: 0.3611\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 0.6814 - acc: 0.5185 - val_loss: 0.6962 - val_acc: 0.4167\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 576us/step - loss: 0.6779 - acc: 0.5185 - val_loss: 0.6965 - val_acc: 0.3889\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6744 - acc: 0.5556 - val_loss: 0.6965 - val_acc: 0.3889\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 0.6729 - acc: 0.6049 - val_loss: 0.6962 - val_acc: 0.3889\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 0.6798 - acc: 0.5185 - val_loss: 0.6971 - val_acc: 0.3611\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.6686 - acc: 0.5309 - val_loss: 0.6969 - val_acc: 0.3611\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6760 - acc: 0.5679 - val_loss: 0.6968 - val_acc: 0.3889\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 527us/step - loss: 0.6733 - acc: 0.5062 - val_loss: 0.6967 - val_acc: 0.3889\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 529us/step - loss: 0.6715 - acc: 0.5802 - val_loss: 0.6965 - val_acc: 0.3889\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 527us/step - loss: 0.6814 - acc: 0.5185 - val_loss: 0.6961 - val_acc: 0.3889\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6705 - acc: 0.5679 - val_loss: 0.6955 - val_acc: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 546us/step - loss: 0.6657 - acc: 0.5556 - val_loss: 0.6947 - val_acc: 0.4167\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 0.6845 - acc: 0.5062 - val_loss: 0.6945 - val_acc: 0.4167\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6758 - acc: 0.5679 - val_loss: 0.6940 - val_acc: 0.4444\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6762 - acc: 0.4938 - val_loss: 0.6945 - val_acc: 0.4167\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 633us/step - loss: 0.6742 - acc: 0.5432 - val_loss: 0.6949 - val_acc: 0.4167\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 599us/step - loss: 0.6595 - acc: 0.5802 - val_loss: 0.6945 - val_acc: 0.4167\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6747 - acc: 0.5556 - val_loss: 0.6932 - val_acc: 0.4722\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 610us/step - loss: 0.6717 - acc: 0.5556 - val_loss: 0.6924 - val_acc: 0.4722\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 643us/step - loss: 0.6808 - acc: 0.5926 - val_loss: 0.6922 - val_acc: 0.4722\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 554us/step - loss: 0.6745 - acc: 0.5802 - val_loss: 0.6931 - val_acc: 0.4722\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 0.6806 - acc: 0.5185 - val_loss: 0.6939 - val_acc: 0.4722\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 0.6741 - acc: 0.6049 - val_loss: 0.6947 - val_acc: 0.4722\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 596us/step - loss: 0.6708 - acc: 0.5802 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 532us/step - loss: 0.6680 - acc: 0.5432 - val_loss: 0.6951 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6645 - acc: 0.5926 - val_loss: 0.6948 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 0.6619 - acc: 0.5556 - val_loss: 0.6946 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.6648 - acc: 0.5926 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "<keras.callbacks.History object at 0x1a2ba82748>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 200us/step\n",
      "loss: 0.6873190402984619\n",
      "acc: 0.5384615659713745\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8XHW9//HXZ2ayr03SfUtpy9KWtqSlFNkpgoBQRAQqiBQBQdwu6hX1Ksr96UUvFxFFEGRRRBBBlF22somltLUtXehCaWmaNE3SNvs2M9/fH2daQ9tsbWbJzPv5eMwjkzNn5nxyMnnPN9/zPd9jzjlERCT5+eJdgIiIxIYCX0QkRSjwRURShAJfRCRFKPBFRFKEAl9EJEUo8EVEUoQCX1KSmW0ys9PiXYdILCnwRURShAJfpBMzu8rMNpjZDjN70sxGRJabmf3czLabWZ2ZrTCzKZHHzjKz1WbWYGZbzeyb8f0pRPZPgS8SYWanAv8DXAgMBzYDj0QePh04ETgUKAQuAmojj90LfNE5lwdMAV6JYdkivRaIdwEiCeQS4D7n3FIAM/sOsNPMSoEOIA84HFjknFvT6XkdwCQzW+6c2wnsjGnVIr2kFr7Iv43Aa9UD4JxrxGvFj3TOvQL8CrgDqDKzu80sP7Lqp4GzgM1m9pqZHRvjukV6RYEv8m8VwNjd35hZDlAMbAVwzt3unJsBTMbr2vlWZPk7zrm5wBDgr8CjMa5bpFcU+JLK0swsc/cNL6jnm9l0M8sAfgK87ZzbZGZHm9kxZpYGNAGtQMjM0s3sEjMrcM51APVAKG4/kUg3FPiSyp4FWjrdTgC+DzwOVALjgYsj6+YD9+D1z2/G6+q5JfLY54BNZlYPXANcGqP6RfrEdAEUEZHUoBa+iEiKUOCLiKQIBb6ISIpQ4IuIpIiEOtO2pKTElZaWxrsMEZEBY8mSJTXOucG9WTehAr+0tJTFixfHuwwRkQHDzDb3vJZHXToiIilCgS8ikiIU+CIiKSKh+vD3p6Ojg/LyclpbW+NdStLIzMxk1KhRpKWlxbsUEYmhhA/88vJy8vLyKC0txcziXc6A55yjtraW8vJyxo0bF+9yRCSGEr5Lp7W1leLiYoV9PzEziouL9R+TSApK+MAHFPb9TPtTJDUNiMDvSVV9Kw2tHfEuQ0QkoSVF4Fc3tNHYFuz3162trWX69OlMnz6dYcOGMXLkyD3ft7e39+o15s+fz9q1a7td54477uChhx7qj5JFRLqU8Adte8OAaEzrX1xczLJlywD44Q9/SG5uLt/85jc/so5zDuccPt/+Pzvvv//+Hrdz3XXXHXyxIiI9SIoWPgaxvIzLhg0bmDJlCtdccw1lZWVUVlZy9dVXM3PmTCZPnsxNN920Z93jjz+eZcuWEQwGKSws5IYbbmDatGkce+yxbN++HYD/+q//4rbbbtuz/g033MCsWbM47LDDeOuttwBoamri05/+NNOmTWPevHnMnDlzz4eRiEhvDKgW/o+eWsXqivp9lje3hwj4jPRA3z+/Jo3I58ZzJvf5eatXr+b+++/nrrvuAuDmm2+mqKiIYDDIKaecwgUXXMCkSZM+8py6ujpOOukkbr75Zq6//nruu+8+brjhhn1e2znHokWLePLJJ7npppt4/vnn+eUvf8mwYcN4/PHHWb58OWVlZX2uWURSW3K08IltCx9g/PjxHH300Xu+f/jhhykrK6OsrIw1a9awevXqfZ6TlZXFmWeeCcCMGTPYtGnTfl/7/PPP32edN998k4sv9i6vOm3aNCZP7vuHlIiktgHVwu+qJb6msp7cjACji7JjVktOTs6e++vXr+cXv/gFixYtorCwkEsvvXS/49zT09P33Pf7/QSD+z/QnJGRsc86uvawiByspGjhx3tUeX19PXl5eeTn51NZWcnf//73ft/G8ccfz6OPPgrAu+++u9//IEREujOgWvhdsRgftN1bWVkZkyZNYsqUKRxyyCEcd9xx/b6Nr3zlK1x22WVMnTqVsrIypkyZQkFBQb9vR0SSlyVSV8HMmTPd3hdAWbNmDUcccUS3z1u7rYHMNB9ji3O6XW8gCwaDBINBMjMzWb9+Paeffjrr168nEDiwz+ze7FcRSXxmtsQ5N7M36yZNCz/ZNTY2MmfOHILBIM45fvOb3xxw2ItIakqaxEigf1SiorCwkCVLlsS7DBEZwHTQVkQkRSRH4JvF9aCtiMhAkBSBDxqnLiLSk6QIfCO+wzJFRAaC5Aj8KCb+ySefvM+JVLfddhtf+tKXunxObm4uABUVFVxwwQVdvu7eQ1D3dtttt9Hc3Lzn+7POOotdu3b1tnQRkY9IisCH6LXw582bxyOPPPKRZY888gjz5s3r8bkjRozgscceO+Bt7x34zz77LIWFhQf8eiKS2pIi8C2KTfwLLriAp59+mra2NgA2bdpERUUF06dPZ86cOZSVlXHkkUfyt7/9bZ/nbtq0iSlTpgDQ0tLCxRdfzNSpU7noootoaWnZs9611167Z2rlG2+8EYDbb7+diooKTjnlFE455RQASktLqampAeDWW29lypQpTJkyZc/Uyps2beKII47gqquuYvLkyZx++ukf2Y6IpLaBNQ7/uRtg27v7LB7eESKMg7QD+HGGHQln3tzlw8XFxcyaNYvnn3+euXPn8sgjj3DRRReRlZXFE088QX5+PjU1NcyePZtzzz23y+vF3nnnnWRnZ7NixQpWrFjxkemNf/zjH1NUVEQoFGLOnDmsWLGCr371q9x6660sWLCAkpKSj7zWkiVLuP/++3n77bdxznHMMcdw0kknMWjQINavX8/DDz/MPffcw4UXXsjjjz/OpZde2vf9IiJJJyla+NHWuVtnd3eOc47vfve7TJ06ldNOO42tW7dSVVXV5Wu8/vrre4J36tSpTJ06dc9jjz76KGVlZRx11FGsWrWqx4nR3nzzTT71qU+Rk5NDbm4u559/Pm+88QYA48aNY/r06UD3UzCLSOoZWC38LlriVbVNtHWEOXRYXlQ2e95553H99dezdOlSWlpaKCsr44EHHqC6upolS5aQlpZGaWnpfqdE7mx/rf8PPviAW265hXfeeYdBgwZx+eWX9/g63Q1B3T21MnjTK6tLR0R2S4oWfrSHZebm5nLyySdzxRVX7DlYW1dXx5AhQ0hLS2PBggVs3ry529c48cQT91yofOXKlaxYsQLwplbOycmhoKCAqqoqnnvuuT3PycvLo6GhYb+v9de//pXm5maampp44oknOOGEE/rrxxWRJDWwWvhdMcNFeST+vHnzOP/88/d07VxyySWcc845zJw5k+nTp3P44Yd3+/xrr72W+fPnM3XqVKZPn86sWbMA7+pVRx11FJMnT95nauWrr76aM888k+HDh7NgwYI9y8vKyrj88sv3vMaVV17JUUcdpe4bEelWUkyPvGVHM01tQQ4fnh/N8pKKpkcWSQ59mR5ZXToiIikiKQKfOF/xSkRkIBgQgd9Tt5OBEr8PEqkbT0RiJ+EDPzMzk9ra2m5DymJw0DZZOOeora0lMzMz3qWISIwl/CidUaNGUV5eTnV1dZfr7GrpoLktiK8uK4aVDVyZmZmMGjUq3mWISIwlfOCnpaUxbty4btf5ybNrePCfFaz570/EqCoRkYEn4bt0esPvM0JhdemIiHQnKQI/4DOC4XC8yxARSWhJEfg+M8JOo09ERLqTFIEf8HmTkqlbR0Ska1EPfDPzm9m/zOzpaG3D7/cCP6jAFxHpUixa+F8D1kRzA/7ItMNhdemIiHQpqoFvZqOAs4HfRnM7fp9a+CIiPYl2C/824D+BLofQmNnVZrbYzBZ3d3JVd/b04YcU+CIiXYla4JvZJ4Htzrkl3a3nnLvbOTfTOTdz8ODBB7St3S38kLp0RES6FM0W/nHAuWa2CXgEONXM/hCNDfl93o+hUToiIl2LWuA7577jnBvlnCsFLgZecc5dGo1tBdSHLyLSo6QYh++LBH5YgS8i0qWYTJ7mnHsVeDVar68WvohIz5Kihb/noK3m0xER6VKSBX6cCxERSWBJFfiaMVNEpGtJEfiaPE1EpGdJEfg+Bb6ISI+SIvDVwhcR6VlSBL4mTxMR6VlyBL7pxCsRkZ4kReAHdAEUEZEeJUXga/I0EZGeJUfgmw7aioj0JDkCXwdtRUR6lBSBv7sPX9e0FRHpWlIE/vj7p/LNwJ/UwhcR6UZSBD5mFNCk2TJFRLqRFIEfzigg35o1W6aISDeSIvBdRj75auGLiHQrKQKfTK+Frz58EZGuJUXgey38Zk2tICLSjaQIfK+F36QWvohIN5Ii8C2zgHyadaatiEg3kiLwySogy9pxwbZ4VyIikrCSIvAtqxAAf3tDnCsREUlcSRH4/kjgB9rr41yJiEjiSorAt8wCAAIdauGLiHQlOQI/0sJP61ALX0SkK0kR+ERa+Glq4YuIdCk5Aj8jH4D0oAJfRKQryRH4auGLiPQoOQI/PYcgPjLUwhcR6VJyBL4ZjeSQHlLgi4h0JTkCH2ggh8xgY7zLEBFJWEkT+I2Woy4dEZFuJE3gN1kOmSG18EVEuqLAFxFJEckT+L4cshT4IiJdSprAb7YcssIKfBGRriRP4PtyyXCtEGyPdykiIgkpaQK/ye9Nr0BzbXwLERFJUFELfDPLNLNFZrbczFaZ2Y+itS2AqsBw787OD6K5GRGRASuaLfw24FTn3DRgOvAJM5sdrY1VB0Z6d3ZsjNYmREQGtF4Fvpl9zczyzXOvmS01s9O7e47z7D6Kmha5Re0q4zvShhLCp8AXEelCb1v4Vzjn6oHTgcHAfODmnp5kZn4zWwZsB150zr29n3WuNrPFZra4urq6D6XvxZdGtX+oAl9EpAu9DXyLfD0LuN85t7zTsi4550LOuenAKGCWmU3Zzzp3O+dmOudmDh48uLd17yPgNyr9IxT4IiJd6G3gLzGzF/AC/+9mlgeEe7sR59wu4FXgE32usJf8PqPCNxx2bAIXtZ4jEZEBq7eB/wXgBuBo51wzkI7XrdMlMxtsZoWR+1nAacB7B1Frt/xmbPUNh7Y6aN4Rrc2IiAxYvQ38ucD7kZY6QAg4pIfnDAcWmNkK4B28PvynD6zMnvl9RrkN875Rt46IyD56G/g3Oufqdn8TCf4bu3uCc26Fc+4o59xU59wU59xNB1NoTwJ+Y6tFxuIr8EVE9tHbwN/feoH+LORg+cwoZwhgCnwRkf3obeAvNrNbzWy8mR1iZj8HlkSzsL4K+IxWF4CicVC1Mt7liIgknN4G/leAduBPwJ+BVuC6aBV1IPw+H6Gwg1GzYMvbGqkjIrKXXnXLOOea8EbpJCy/Dy/wxxwDKx7xunWKx8e7LBGRhNFt4JvZbc65r5vZU+xnWgTn3LlRq6yP/D4fwbCDMcd6Cz5cqMAXEemkpxb+g5Gvt0S7kIMV8BnhsIOSwyCzALYshKMuiXdZIiIJo9vAd84tMTM/cJVz7tIY1XRA/D7zWvg+H4yeDR/uM22PiEhK6/GgrXMuBAw2s/QY1HPA/D7z+vDB68evWQtNNfEtSkQkgfR2lM4m4B9m9n0zu373LYp19Vmgc+CPn+N9Xfts/AoSEUkwvQ38CuDpyPp5kVtutIo6EL7OgT98GgwqhVV/jWtNIiKJpLdny652zv258wIz+0wU6jlgAZ8RDEcm8DSDSefBP3/lTaSWXRTf4kREEkBvW/jf6eWyuPH7jLADt/uEq8nnQTgI7z0T38JERBJET+Pwz8SbA3+kmd3e6aF8IBjNwvrKb971WEJhR8BvMHw6DBoHy/4IZZ+Lc3UiIvHXUwu/AliMN5XCkk63J4Ezolta3/j9XuAHd/fjm8Gsq+DDt6A8oab9ERGJi24D3zm33Dn3O2AC8Ciw0Dn3O+fcX5xzO2NSYS8FfF7ghzvPoVN2GWQUwD9/GaeqREQSR2/78D8BLAOeBzCz6Wb2ZNSqOgA+26uFD5CRBzMvh9V/g9r341OYiEiC6G3g/xCYBewCcM4tA0qjU9KByUjzA9DaHvroA7Ovg0AWvPiDOFQlIpI4ehv4wc5XvEpExTneicA7mts/+kDeUDjhenjvadj4WhwqExFJDL0N/JVm9lnAb2YTzeyXwFtRrKvPiiKBX9vYvu+Dx34ZCsfAs9+CjtYYVyYikhj6cgGUyUAb8DBQD3w9WkUdiJLcSOA37Sfw0zLh7J978+u89tMYVyYikhh6ewGUZuB7kVtCKs7JAKC2sW3/K0w8DaZfCv+4DQ47E0bPimF1IiLx19OJV92OxEmkC6AUZKXh9xk79tfC3+2MH8OmN+DP8+GaNzTlgoiklJ5a+McCW/C6cd4GLOoVHSCfzxiUnU7N/vrwd8sqhM88APedAY9/AT77KPjTYlajiEg89dSHPwz4LjAF+AXwcaDGOfeacy7hhrwU56R33aWz28gyOOsWeP8VeOYbuti5iKSMns60DTnnnnfOfR6YDWwAXjWzr8Skuj4qzk3vvktntxmfh+Ovh6W/gzdvjX5hIiIJoMeDtmaWAZwNzMM72ep24C/RLevAFOWks6qivncrn/p9qNsCL98EBaNh6oXRLU5EJM56Omj7O7zunOeAHznnVsakqgNUkpvRc5fObj4fzL0D6ivhiWvAn+5NqSwikqR66sP/HHAo8DXgLTOrj9wazKyXTenYKcpJp741SHsw3LsnBDLgs4/AqJnw2BWw6onoFigiEkc99eH7nHN5kVt+p1uecy4/VkX2VnHk5Kude0+v0J2MPLj0cRh1NDz2BViZkL1VIiIHrbdn2g4Iu0++qultt85uGXlw6WPeyViPfwGW/C4K1YmIxFdyBX5uN/Pp9GR3S3/8HHjqq/D6LRqyKSJJJbkCf/eMmb0Zmrk/6Tkw72GYehG88t/w/Hcg3MvjASIiCa5Xc+kMFAfcpdOZPw3OuwuyS2DhHdBcA3N/DYH0fqpSRCQ+kirw87MCBHqaT6c3fD5v3p3cwfDSD6F5B1z0oPcfgIjIAJVUXTpmxtD8TDbvaO6PF4Pj/wPO/SVsXAC/Oweaag/+dUVE4iSpAh/gmEOK+MeGGkLhfjrgWnYZXPQHqFoF934cdm7qn9cVEYmxpAv8kw8bwq7mDpZt2dV/L3r42XDZ36C5Fn77cahY1n+vLSISI0kX+CdOLMFn8Nra7f37wmNmwxde8M7OfeBsb7ZNEZEBJOkCvzA7nemjC3l1XXX/v/jgw+ALL8KgUnjoM7D8T/2/DRGRKIla4JvZaDNbYGZrzGyVmX0tWtva2ymHDWFFeR3b6qJwwfL84TD/WRhzLDxxNbx5m07QEpEBIZot/CDwDefcEXhz6V9nZpOiuL095k4fic/g/n98EJ0NZBZ4Z+VOuQBeuhGe+zaEQ9HZlohIP4la4DvnKp1zSyP3G4A1wMhoba+zMcXZnD11BA+9/SF1LR3R2UggA86/B479Miz6DTw2Hzqi8B+FiEg/iUkfvpmVAkfhXRd378euNrPFZra4urr/+t2/eOIhNLYF+cPCzf32mvvYfYLWGT+B1X+DP5zvnaQlIpKAoh74ZpYLPA583Tm3zxz6zrm7nXMznXMzBw8e3G/bnTKygBMPHcz9/9hEa0eUu1uOvQ4uuA/K34HfzoHqddHdnojIAYhq4JtZGl7YP+Sci/lE89ecdAg1jW08tqQ8+hub8mm4/Bloa4DfngYbXor+NkVE+iCao3QMuBdY45yLy5XCjz2kmGmjC7n79Y0EQzGY9XL0LLhqARSO8YZtLrxTI3hEJGFEs4V/HN4lEk81s2WR21lR3N4+zIxrTxrPhzuaeXpFZWw2WjgarngeDjsLnr8Bnv46hKJ04FhEpA+iOUrnTeecOeemOuemR27PRmt7XTl90lAOH5bH7S+vj00rHyAjFy58EE74Bix5AB78lCZeE5G4S7ozbffm8xlfP20iG2uaeHJ5RSw3DHN+AOf/FrYsgrtP1hw8IhJXSR/4AKdPGsbkEfnc9PRqNmxviO3Gp37G6+JxYbjvDE3HICJxkxKB7/MZv76kjIDPx2X3LqKyriW2BYwsg6tfhVFHe9MxPHeD+vVFJOZSIvABxhbn8MD8o6lvDfL5+xaxq/kgr4rVV7mD4XN/hdnXwdt3wu/nQsO22NYgIiktZQIfvJOx7v7cDDbVNHPpvW9TvrMfrozVF/4AfOIn3pQMFf+Cu47XNMsiEjMpFfgAH5tQwl2fK2NzTTOf/OWbrCjvxwul9NbUC73x+tnF8OD58MqPNfmaiERdygU+wKmHD+WprxxPTnqAK3+3OPZ9+gBDDoerXoHpl8DrP/O6eOpjdK6AiKSklAx8gNKSHO67/Gia20Nc+Jt/8uTyClysz4pNz4Hz7oDz7oStS+DOY2FlzGegEJEUkbKBD3DYsDwemH80OekBvvrwv7jp6dWxD32A6Z+FL74ORYd40yw/fiW07Ix9HSKS1FI68AFmlhbx7FdPYP5xpdz/j038/KX1tAXj0J9eMhGueAFO/q7Xyv/1x+D9BbGvQ0SSVsoHPnjj9L9/9iTmTh/B7S+v58SfLeA3r71PQ2uMx8r7A3Dyt+HKl7zpGR48D578CrTE4cCyiCQdi0sXRhdmzpzpFi9eHLftO+d4c0MNd732Pv/YUMuQvAz+eNVsJgzJjX0xHS3w6v/AW7+CnBI46xaYdG7s6xCRhGZmS5xzM3uzrlr4nZgZJ0wczENXzubxaz9G2MG8exaycGNt7Pv207Lg4zd5I3lyh8Cjn4NHLtFIHhE5YAr8LswYO4iHrzoGAy6+eyGfueuf1DS2xb6QEdO9Mfun/ci7qModx8Di+yEco5k/RSRpKPC7MXFoHq996xT+e+5kVlbUMe/uhXxQ0xT7QvxpcPzX4dq3YPhUb479+86AyuWxr0VEBiwFfg+y0v187thS7rv8aMp3tnDKLa8y91dv8vq6/rvgeq8Vj4fPP+WN29/5gTfl8jPf1BBOEekVHbTtg4pdLTyzopIHF27mwx3NnDNtBD/99JFkpwdiX0zLLljwY3jnt5BVBB//EUz7rDcPv4ikjL4ctFXgH4C2YIjfvLaRn7+0jsOG5vG/F0zjyFEF8SmmcgU88w0oXwSjZsHZt8DwafGpRURiTqN0oiwj4OercybywPxZ1DS2M/eON7nxbyupj/W4ffD69K/4O8z9NezY6HXzPPstjd0XkX2ohX+Q6lo6uPWFtfx+4WZKcjP4n08dyWmThsanmJad3sybi+/1unlOu9GbnM3nj089IhJ16tKJg3fL6/jWY8t5b1sD500fwTdOP4zRRdnxKaZimdfKL18Ew6bCmT+FsR+LTy0iElUK/DhpC4b45csbuOeNjYSd47pTJvClkyeQHohDz5lzsPJxePEHUL8VJp3nncg1aGzsaxGRqFHgx9m2ulZ+8uwanlxewbiSHK456RA+MXk4BdlpsS+mvRneuh3evM27kPrHvgzHX+/N1SMiA54CP0G88l4V//fCOlZV1OMzOPXwIfzfZ6bHJ/jryuGlH8G7j0LuMK9/f+rFGsYpMsAp8BOIc44lm3fyynvbueeNjYwpyuZnF0xjxthB8Sloyzvw/Le9C66MOAo+cTOMmR2fWkTkoCnwE9TCjbVc99BSapvaOWFiCd//5CQOHZoX+0LCYXj3z/DSD6GhAo44F077oXcmr4gMKAr8BNbUFuSPb3/IrxZsoLEtyGdmjOK6UybEZ0RPexP88w6vfz/UBkdfBSf9J2QXxb4WETkgCvwBYGdTO794eT1/fPtDws5xQTyDv6EKXv0JLP09pOfBid+EWVdDWmbsaxGRPlHgDyDb6lq589UNPLxoS/yDf/sabxjn+hegcAzMuRGmfBrMYl+LiPSKAn8A2lbXyl2vvc8fF31IOOz4dNkovnxqnIL//QXwwveh6l0YOQNO/zGMPTb2dYhIjxT4A1jCBH84BMsfgVf+Gxoq4fBPwpwfwODDYluHiHRLgZ8EOgc/wCXHjGFWaREzxg5iSH4M+9bbm70Du/+4DTqaYdo8OOnbOmNXJEEo8JNIZV0L//v3tTzxr604Bz6DEyYO5jtnHc7hw/JjV0hTDbz5c1h0j3fG7sz5cMI3IS9OE8WJCKDAT0pNbUHer27kxdVVPPT2h9S3dPClUyZw3SnjyQjEcDbMuq3w+s9g6YPgT4djvgjHfU1DOUXiRIGf5HY0tXPTU6v467IKxg/OYc4RQzl+QgknTCzBYjWipvZ9ePVm7wSujDz42Fdh9jXefRGJGQV+iljw3nZue2kdayobaA+FOXJkAXOnj+CMycNid5C3apU3B//aZyC7BE74Bsy8QmP4RWJEgZ9i2oNhnvhXOfe++QHrqhpJ8xtfOP4QLp09hlGDYhT85Yu9ET0bX4W8EV43T9llkB6nawKIpAgFfgrbsqOZ215az+NLywE4pCSHEw8dzCXHjGFiLObt2fgavPZT2PwPr8X/sS/D0Veqq0ckShT4wvvVjby6tprX11WzcGMtHaEwZ0wextRRhZxfNpKh0R7aufkteP0WeP9lyCyE2dd6B3iz4jRLqEiSSojAN7P7gE8C251zU3rzHAV+dOxoaufXCzbwzLuVVNa1UpKbwc8vmsbUkYXRn5t/6xIv+Nc+683TM+tKmH0d5A6O7nZFUkSiBP6JQCPwewV+4lhX1cBVv1/M5tpmAA4flseFM0dzwcxR5GdGMfy3rYQ3/g9WPQGBTJhxudfq1wlcIgclIQI/Ukgp8LQCP7HUtXTw6trtVOxq5flV21i+ZRe5GQEuPno0lx9XGt0DvdXrvBO4VvwJcN6UDbO/5F2ERZO0ifSZAl/6ZEX5Ln77xgc8824lzjlOPHQwF84czZwjhkTvpK66rfDOPbD4fmjd5V19a/aXvIutB9Kjs02RJDSgAt/MrgauBhgzZsyMzZs3R60e6V7FrhYeenszjy/Zyrb6VvIyA0wans9xE0q4dPZYinKiEMTtTd4kbQvvhNr13vV2Z10JM+ZDTkn/b08kyQyowO9MLfzEEAo73lhfzd9XbWN1ZQPLt+wiI+DjxEMHM2VEARlpPj51VD+P9AmH4f1XYOEd3ld/unfpxZnzYexx6u4R6YICX/rVuqoGHlq4mRdWV1FZ1wpATrqfr8yZyOcq/NqvAAAPiUlEQVSPLSUrvZ+7fba/B4vv81r+bXVQPNE7yDv9s5qzR2QvCRH4ZvYwcDJQAlQBNzrn7u3uOQr8xOacIxR2bN3Vwk1Prebl97ZTkpvOEcPzGZqfyeQR+Zx/1Kj+G+rZ3gyr/+r185cvirT6z4GpF8H4U8Ef5SGlIgNAQgT+gVDgDyyLPtjBA299QMWuVsp3tlDT2MbY4mzu+GwZE4bkkpnWjy3/qlVe8K98DFp2QnYxTP4UHPkZGH2MunwkZSnwJS7e2bSDa/+whJrGdsCb1uG4CSWcPXU4R5cW4ff1QygH22HDS94snWufhWAr5I/0Wv5HnANjjgVfDKeLFokzBb7ETVV9Ky+tqWJHYzv/2rKLt96vobUjzJC8DM6eOpxzpo3gqNGF/TONc1sDvPcMrH7Sm8Ih2OrN33P42d4B33EnaoinJD0FviSMprYgL7+3naeWV/Da2mraQ2FGDcri9EnDGF2UxdGlRUwZWXDwG2prhA0vwpqnYN3fob0RMgrg0NO9/v5xJ0HByIPfjkiCUeBLQqpv7eCFVVU8tbyCt96voSPkvfcmDc8nNyPA+CE5XHZsKUcMP8hLN3a0etM0r3kK1j0HzbXe8pJDveAvPQ5GzoCC0er7lwFPgS8JLxx21DS18fTySv6+ahvOwYqtu2jtCDP7kCI+PmkYeRkBciIfBAd8/d5wGKpWwgeveR8Cm9/yLsYOkDPYC/6RM2BkGYwo07BPGXAU+DIg7Wpu50/vbOH3/9zM1l0tH3lsVmkRxxxSRGlxDqUl2QR8PgZlpzOmuI/z/gTbvQ+ArUtg61Lva806IPJ3MGgcDJ0MQ46AwYd7X4snQCCjf35IkX6mwJcBLRx21LV00NQepKktxBvrq/nTO1vYWNNEKPzR9+uJhw7m+AnFjBqUzahBWRw2LK/v8/+01kHFMi/8K5bC9jWwYyO4cGQFg9wh3miggpGQP8qb3jmryBseml0UuV8EmQXebKDqKpIYUeBLUmoPhinf2czm2mbCzrGmsp4/LPyQbfWte9bJSfdz0mGDOX3SMGaMHcTwgkya2kN8UNPE5tomxpXkUJSTjpkxsjCr640F26BmPVS/B7UboK4c6rd6X+u2QkdT1881H6TlQHqOd4nH9BxIz4W0Tvc7L0/PiTyW2+k5kfX96d4wU58fLPLVF/C248LeLRz69/393bDI833eB5Htvr+/W+d1u1lHEoYCX1JKXUsHW3e2sLm2idfX1/DSmiqqG9p6fN7MsYOYNrqQzbVNTByaR2tHiBdXV+Ez47BhefzHaYdyxPA8qhvaWFlRx+hB2UwYkouZ0drcQP2O7Qz2N7JtWyXrN33IuJw2CqyFtuYGmhrrsY4mMl0rma6F9HAraaFm/MFmrL3ZG0XU3gShnutMSHvCf38fDrb/Dwqfv+vH9nluVx863b12N4/v/XznvBvu3//JmR98nX6uPa/pLXf4MN++y/99PxC5+b3XDgch3AGhDu9Defd9F/LW82d4w4b9GZCZ710D+kB+FQp8SWXhsGPF1jrWVNZTVd9KTnqA0UVZjCnKYVNtEw2tHexq7uDBhZvZ3tDGmKJsNtU04TPjpMMGk5Xm57V11dS1dGAWyYWIQdlppAd8VDe0EXYwJC+D6sY2evtn5DPIz0ojNyNAbkYAnwvR2FBHW3MDOdZKFm0Mzwoxc3g6ldU1uFAH6X5HOBgkFAzi94U5Ykg2RTkZtIYgJzONjhBsa+hgY20zdS0hwvgYWpDNuCF5tLSHqapvIRQOMbowk11NrTS0tFOQ6aOqroVgKMSEwdmMGZRJe0eQD7Y34FwIFw7T2NqOD8eEwdmRdYMMzk0nK2Bk+CHDD8Pz00n3Q+WuZgiHCYdDNLd3UFqURXF2Gks319LS1kHA5yjKCpCVZgQM8jJ8pPkhFAxR39JGwKAg049zYeqaWqlrbqM4O0BmwGhq62BQlp+AQU1jK4RD+HD4zJGX4SfD56hvacdHmAy/kZPuo70jSHNbO+FwGB+OgM8RMAhYGMPREQYzIz0tQDAEYefwWxg/jnA4RCgUJM0H6T6Hz4XpCAWxcBi/hfHhvWZfOYywLwAWwOeCWLhjz2OhnCH4v7W+z68JCnyRXtk9N1DA76O5PUjYQW6G111S19zBI+98SGNbkMLsdCaPyOf96kZWVdQTDIUZVpBFYVYay7bsYmxxNudOG8HaqgYaW4PkZaYxuiiLrDQ/9a0d1LV4HzA7mzvY1dzOruYOmtqCNLYFcXgfGkPzMxmSl0FuZoC/LN3Ksi27mDl2EIOy02kPhclM85OV5qexrYOX1mxnV3M7WWl+mtpDmMGoQVnMGDOIw4fn4zN4buU2PqhpIj8zjXElOaT5jVUV9YwozGLUoCyq6luZMCSXktwM/rJ0K1t3tRDwGR8bX0x+Vhot7SHOLxvJ4k07+fOSco6bUMzwgizWbmugoS1IS3uQHU3te86qzssIkJXuJ83vIyfDz7qqRgBGFmZx4qElNLaFWFVRR31LkKa2IC0doT2/h/zMAG3BMG1Br6WdlxlgxthBLNxYS2tHmKH5GVTVe/8JjSnKZmRhFqGwo6EtyJrKegCG5WeSmxlgc23TnuG+U0bmU1qcQyjsqGlso6axnZqGNpragxw6NG/PsoDPKMxOo66lg46QIzPNR9mYQazcWkd9a3BPjWdMHsaK8jqa2oOEQ2HqWtpp7/A+zAiHSIt8GEwdno3f7+eDHR2MLs6jzflYua2Z5o6PZq0RJssXwh/uYFhegBe/96kDeh8r8EWSmHMO58DnM5rbg/jMDnreos6v2ZfnrKtqpKUjxJEjC/ZMneGc47mV21hTWc8XTxq/50O08/Mq61ppbg+REfAxalAW7aEwm2ubyQz4GVqQQUbAT2NbkI5gmMJs74O1sS3IceNLPlLjlh3NbKtvpWzMIPw+o761g7c21DCmKIdJI/Y/lDccdvh8RjAUZkN1I2OLcshK9+Oco7k9hN/n7c+2YIh12xrZuquFWeOK9rkeREcozDMrKlm2ZRcXzBjFEcPzaQuGyE4P7LNN5xz1rUGqG9rY3tBKdUMb1Q3eB05eZoCh+ZlcMGNUr/d9Zwp8EZEU0ZfA90W7GBERSQwKfBGRFKHAFxFJEQp8EZEUocAXEUkRCnwRkRShwBcRSREKfBGRFJFQJ16ZWTWw+QCfXgLU9GM5/UV19V2i1qa6+kZ19d2B1DbWOTe4NysmVOAfDDNb3NuzzWJJdfVdotamuvpGdfVdtGtTl46ISIpQ4IuIpIhkCvy7411AF1RX3yVqbaqrb1RX30W1tqTpwxcRke4lUwtfRES6ocAXEUkRAz7wzewTZrbWzDaY2Q1xrGO0mS0wszVmtsrMvhZZ/kMz22pmyyK3s+JU3yYzezdSw+LIsiIze9HM1ke+DopxTYd12i/LzKzezL4ej31mZveZ2XYzW9lp2X73j3luj7znVphZWRxq+18zey+y/SfMrDCyvNTMWjrtu7tiXFeXvzsz+05kn601szNiXNefOtW0ycyWRZbHcn91lRGxe595lzYbmDfAD7wPHAKkA8uBSXGqZThQFrmfB6wDJgE/BL6ZAPtqE1Cy17KfATdE7t8A/DTOv8ttwNh47DPgRKAMWNnT/gHOAp4DDJgNvB2H2k4HApH7P+1UW2nn9eJQ135/d5G/heVABjAu8nfrj1Vdez3+f8AP4rC/usqImL3PBnoLfxawwTm30TnXDjwCzI1HIc65Sufc0sj9BmANMDIetfTBXOB3kfu/A86LYy1zgPedcwd6pvVBcc69DuzYa3FX+2cu8HvnWQgUmtnwWNbmnHvBOReMfLsQOLALovZzXd2YCzzinGtzzn0AbMD7+41pXWZmwIXAw9HYdne6yYiYvc8GeuCPBLZ0+r6cBAhZMysFjgLejiz6cuRfsvti3W3SiQNeMLMlZnZ1ZNlQ51wleG9GYEicagO4mI/+ESbCPutq/yTa++4KvJbgbuPM7F9m9pqZnRCHevb3u0uUfXYCUOWcW99pWcz3114ZEbP32UAPfNvPsriOMzWzXOBx4OvOuXrgTmA8MB2oxPt3Mh6Oc86VAWcC15nZiXGqYx9mlg6cC/w5sihR9llXEuZ9Z2bfA4LAQ5FFlcAY59xRwPXAH80sP4YldfW7S5R9No+PNixivr/2kxFdrrqfZQe1zwZ64JcDozt9PwqoiFMtmFka3i/yIefcXwCcc1XOuZBzLgzcQ5T+je2Jc64i8nU78ESkjqrd/yJGvm6PR214H0JLnXNVkRoTYp/R9f5JiPedmX0e+CRwiYt0+ka6TGoj95fg9ZUfGquauvndxX2fmVkAOB/40+5lsd5f+8sIYvg+G+iB/w4w0czGRVqJFwNPxqOQSN/gvcAa59ytnZZ37nP7FLBy7+fGoLYcM8vbfR/vgN9KvH31+chqnwf+FuvaIj7S6kqEfRbR1f55ErgsMopiNlC3+1/yWDGzTwDfBs51zjV3Wj7YzPyR+4cAE4GNMayrq9/dk8DFZpZhZuMidS2KVV0RpwHvOefKdy+I5f7qKiOI5fssFkeno3nDO5K9Du+T+XtxrON4vH+3VgDLIrezgAeBdyPLnwSGx6G2Q/BGSCwHVu3eT0Ax8DKwPvK1KA61ZQO1QEGnZTHfZ3gfOJVAB17L6gtd7R+8f7XviLzn3gVmxqG2DXj9u7vfa3dF1v105He8HFgKnBPjurr83QHfi+yztcCZsawrsvwB4Jq91o3l/uoqI2L2PtPUCiIiKWKgd+mIiEgvKfBFRFKEAl9EJEUo8EVEUoQCX0QkRSjwJaWYWcg+OkNnv82wGpl5MV7nDIj0KBDvAkRirMU5Nz3eRYjEg1r4Iuy5XsBPzWxR5DYhsnysmb0cmQzsZTMbE1k+1Lx56JdHbh+LvJTfzO6JzHf+gpllxe2HEtmLAl9STdZeXToXdXqs3jk3C/gVcFtk2a/wpqidijdB2e2R5bcDrznnpuHNvb4qsnwicIdzbjKwC+9MTpGEoDNtJaWYWaNzLnc/yzcBpzrnNkYmuNrmnCs2sxq86QE6IssrnXMlZlYNjHLOtXV6jVLgRefcxMj33wbSnHP/L/o/mUjP1MIX+TfXxf2u1tmftk73Q+g4mSQQBb7Iv13U6es/I/ffwpuFFeAS4M3I/ZeBawHMzB/jOedFDohaH5JqsixyAeuI551zu4dmZpjZ23gNoXmRZV8F7jOzbwHVwPzI8q8Bd5vZF/Ba8tfizdAokrDUhy/Cnj78mc65mnjXIhIt6tIREUkRauGLiKQItfBFRFKEAl9EJEUo8EVEUoQCX0QkRSjwRURSxP8HnABlenmSlE0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a30fd7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3852933 ]\n",
      " [0.37359565]\n",
      " [0.37871283]\n",
      " [0.363247  ]\n",
      " [0.38505387]\n",
      " [0.3918266 ]\n",
      " [0.38323098]\n",
      " [0.38775283]\n",
      " [0.4325998 ]\n",
      " [0.40456897]\n",
      " [0.41546786]\n",
      " [0.39818195]\n",
      " [0.42246336]\n",
      " [0.41186374]\n",
      " [0.41061002]\n",
      " [0.4384904 ]\n",
      " [0.448525  ]\n",
      " [0.43448958]\n",
      " [0.41267353]\n",
      " [0.43720526]\n",
      " [0.44761363]\n",
      " [0.42615363]\n",
      " [0.43689466]\n",
      " [0.4218942 ]\n",
      " [0.45018983]\n",
      " [0.63285816]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        13\n",
      "        1.0       0.50      1.00      0.67        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        13\n",
      "        1.0       0.50      1.00      0.67        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        13\n",
      "        1.0       0.50      1.00      0.67        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        13\n",
      "        1.0       0.50      1.00      0.67        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        13\n",
      "        1.0       0.50      1.00      0.67        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        13\n",
      "        1.0       0.50      1.00      0.67        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.46      0.55        13\n",
      "        1.0       0.59      0.77      0.67        13\n",
      "\n",
      "avg / total       0.63      0.62      0.61        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.54      1.00      0.70        13\n",
      "        1.0       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.77      0.58      0.48        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      1.00      0.68        13\n",
      "        1.0       1.00      0.08      0.14        13\n",
      "\n",
      "avg / total       0.76      0.54      0.41        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      1.00      0.68        13\n",
      "        1.0       1.00      0.08      0.14        13\n",
      "\n",
      "avg / total       0.76      0.54      0.41        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      1.00      0.68        13\n",
      "        1.0       1.00      0.08      0.14        13\n",
      "\n",
      "avg / total       0.76      0.54      0.41        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        13\n",
      "        1.0       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        13\n",
      "        1.0       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        13\n",
      "        1.0       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        13\n",
      "        1.0       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        13\n",
      "        1.0       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        13\n",
      "        1.0       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.25      0.50      0.33        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YHOO\n",
      "Target\tPredict\tConsequence\n",
      "1.0\t-1\tLoss\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "0.0\t0\tNothing\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "1.0\t1\tGain\n",
      "0.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "1.0\t1\tGain\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "0.0\t0\tNothing\n",
      "0.0\t1\tLoss\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "1.0\t1\tGain\n",
      "\n",
      "\n",
      "[{'month_id': 231, 'QAId': 'YHOO'}, {'month_id': 238, 'QAId': 'YHOO'}, {'month_id': 239, 'QAId': 'YHOO'}, {'month_id': 240, 'QAId': 'YHOO'}, {'month_id': 242, 'QAId': 'YHOO'}, {'month_id': 243, 'QAId': 'YHOO'}, {'month_id': 245, 'QAId': 'YHOO'}, {'month_id': 247, 'QAId': 'YHOO'}, {'month_id': 248, 'QAId': 'YHOO'}]\n",
      "[{'month_id': 223, 'QAId': 'YHOO'}, {'month_id': 224, 'QAId': 'YHOO'}, {'month_id': 225, 'QAId': 'YHOO'}, {'month_id': 226, 'QAId': 'YHOO'}, {'month_id': 227, 'QAId': 'YHOO'}, {'month_id': 229, 'QAId': 'YHOO'}, {'month_id': 230, 'QAId': 'YHOO'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "for j, stock in enumerate(chosen_stocks):\n",
    "  print(stock)\n",
    "  sorted_result = sorted(map(lambda x: x[j], result))\n",
    "  midpt = (sorted_result[-2] + sorted_result[1]) / 2\n",
    "  upper_threshold = midpt * 1.05\n",
    "  lower_threshold = midpt * 0.95\n",
    "  \n",
    "  print(\"Target\\tPredict\\tConsequence\")\n",
    "  for i, r in enumerate(result):\n",
    "    prediction = r[j].item()\n",
    "    target = y_test[i][j].item()\n",
    "    buy_or_sell = 1 if prediction > upper_threshold else (-1 if prediction < lower_threshold else 0)\n",
    "    if prediction > upper_threshold:\n",
    "      buy_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    if prediction < lower_threshold:\n",
    "      sell_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    \n",
    "    to_print = str(target) + \"\\t\" + str(buy_or_sell)\n",
    "    if (buy_or_sell == -1 and target == 0) or (buy_or_sell == 1 and target == 1):\n",
    "      print(to_print + \"\\tGain\")\n",
    "    elif (buy_or_sell == -1 and target == 1) or (buy_or_sell == 1 and target == 0):\n",
    "      print(to_print + \"\\tLoss\")\n",
    "    else:\n",
    "      print(to_print + \"\\tNothing\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       231  YHOO\n",
       "1       238  YHOO\n",
       "2       239  YHOO\n",
       "3       240  YHOO\n",
       "4       242  YHOO"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       223  YHOO\n",
       "1       224  YHOO\n",
       "2       225  YHOO\n",
       "3       226  YHOO\n",
       "4       227  YHOO"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
