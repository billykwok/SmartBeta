{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12 # or 54\n",
    "lookback = 3\n",
    "chosen_stocks = [\"XRAY\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=256, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 2s 26ms/step - loss: 3.8549 - acc: 0.3580 - val_loss: 2.5304 - val_acc: 0.4722\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 743us/step - loss: 3.0021 - acc: 0.3580 - val_loss: 2.2871 - val_acc: 0.4722\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 2.7432 - acc: 0.3580 - val_loss: 2.1364 - val_acc: 0.4722\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 2.5605 - acc: 0.3580 - val_loss: 2.0182 - val_acc: 0.4722\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 2.4218 - acc: 0.3580 - val_loss: 1.9201 - val_acc: 0.4722\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 2.2938 - acc: 0.3580 - val_loss: 1.8385 - val_acc: 0.4722\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 2.2092 - acc: 0.3580 - val_loss: 1.7672 - val_acc: 0.4722\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 2.1203 - acc: 0.3580 - val_loss: 1.7027 - val_acc: 0.4722\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 2.0358 - acc: 0.3580 - val_loss: 1.6434 - val_acc: 0.4722\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 1.9674 - acc: 0.3580 - val_loss: 1.5888 - val_acc: 0.4722\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 1.8951 - acc: 0.3580 - val_loss: 1.5383 - val_acc: 0.4722\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 1.8417 - acc: 0.3580 - val_loss: 1.4912 - val_acc: 0.4722\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 1.7830 - acc: 0.3580 - val_loss: 1.4479 - val_acc: 0.4722\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 1.7320 - acc: 0.3580 - val_loss: 1.4068 - val_acc: 0.4722\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 1.6907 - acc: 0.3580 - val_loss: 1.3684 - val_acc: 0.4722\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 1.6354 - acc: 0.3580 - val_loss: 1.3322 - val_acc: 0.4722\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 1.5854 - acc: 0.3580 - val_loss: 1.2975 - val_acc: 0.4722\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 1.5387 - acc: 0.3580 - val_loss: 1.2641 - val_acc: 0.4722\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 1.4976 - acc: 0.3580 - val_loss: 1.2315 - val_acc: 0.4722\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 1.4579 - acc: 0.3580 - val_loss: 1.2002 - val_acc: 0.4722\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 1.4154 - acc: 0.3580 - val_loss: 1.1696 - val_acc: 0.4722\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 1.3787 - acc: 0.3580 - val_loss: 1.1400 - val_acc: 0.4722\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 1.3356 - acc: 0.3580 - val_loss: 1.1109 - val_acc: 0.4722\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 1.2995 - acc: 0.3580 - val_loss: 1.0823 - val_acc: 0.4722\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 1.2485 - acc: 0.3580 - val_loss: 1.0545 - val_acc: 0.4722\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 1.2189 - acc: 0.3580 - val_loss: 1.0269 - val_acc: 0.4722\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 777us/step - loss: 1.1849 - acc: 0.3580 - val_loss: 1.0005 - val_acc: 0.4722\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 1.1474 - acc: 0.3580 - val_loss: 0.9744 - val_acc: 0.4722\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 1.1163 - acc: 0.3580 - val_loss: 0.9491 - val_acc: 0.4722\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 1.0737 - acc: 0.3580 - val_loss: 0.9245 - val_acc: 0.4722\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 1.0415 - acc: 0.3580 - val_loss: 0.9009 - val_acc: 0.4722\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 1.0106 - acc: 0.3580 - val_loss: 0.8782 - val_acc: 0.4722\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.9803 - acc: 0.3580 - val_loss: 0.8563 - val_acc: 0.4722\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 866us/step - loss: 0.9379 - acc: 0.3580 - val_loss: 0.8358 - val_acc: 0.4722\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.9137 - acc: 0.3580 - val_loss: 0.8163 - val_acc: 0.4722\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.8917 - acc: 0.3580 - val_loss: 0.7980 - val_acc: 0.4722\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.8627 - acc: 0.3580 - val_loss: 0.7809 - val_acc: 0.4722\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 0.8186 - acc: 0.3580 - val_loss: 0.7656 - val_acc: 0.4722\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.8063 - acc: 0.3580 - val_loss: 0.7513 - val_acc: 0.4722\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 780us/step - loss: 0.7790 - acc: 0.3580 - val_loss: 0.7387 - val_acc: 0.4722\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.7639 - acc: 0.3457 - val_loss: 0.7281 - val_acc: 0.4722\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 744us/step - loss: 0.7413 - acc: 0.3951 - val_loss: 0.7196 - val_acc: 0.4722\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 758us/step - loss: 0.7089 - acc: 0.4568 - val_loss: 0.7132 - val_acc: 0.5000\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 733us/step - loss: 0.6961 - acc: 0.4691 - val_loss: 0.7088 - val_acc: 0.4444\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 757us/step - loss: 0.6742 - acc: 0.6049 - val_loss: 0.7067 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 858us/step - loss: 0.6711 - acc: 0.5926 - val_loss: 0.7066 - val_acc: 0.3889\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.6607 - acc: 0.5679 - val_loss: 0.7084 - val_acc: 0.5278\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 853us/step - loss: 0.6467 - acc: 0.6173 - val_loss: 0.7116 - val_acc: 0.5000\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6500 - acc: 0.6420 - val_loss: 0.7160 - val_acc: 0.5278\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6468 - acc: 0.6173 - val_loss: 0.7213 - val_acc: 0.5278\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6341 - acc: 0.6420 - val_loss: 0.7259 - val_acc: 0.5278\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.6556 - acc: 0.6420 - val_loss: 0.7304 - val_acc: 0.5278\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.6426 - acc: 0.6420 - val_loss: 0.7337 - val_acc: 0.5278\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 847us/step - loss: 0.6290 - acc: 0.6420 - val_loss: 0.7362 - val_acc: 0.5278\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 866us/step - loss: 0.6662 - acc: 0.6296 - val_loss: 0.7370 - val_acc: 0.5278\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 969us/step - loss: 0.6374 - acc: 0.6543 - val_loss: 0.7362 - val_acc: 0.5278\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 932us/step - loss: 0.6435 - acc: 0.6296 - val_loss: 0.7353 - val_acc: 0.5278\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 885us/step - loss: 0.6432 - acc: 0.6543 - val_loss: 0.7339 - val_acc: 0.5278\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 854us/step - loss: 0.6405 - acc: 0.6420 - val_loss: 0.7327 - val_acc: 0.5278\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6572 - acc: 0.6296 - val_loss: 0.7307 - val_acc: 0.5278\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.6690 - acc: 0.6049 - val_loss: 0.7272 - val_acc: 0.5278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.6438 - acc: 0.6296 - val_loss: 0.7244 - val_acc: 0.5278\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6646 - acc: 0.6173 - val_loss: 0.7228 - val_acc: 0.5278\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.6566 - acc: 0.6543 - val_loss: 0.7208 - val_acc: 0.5278\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6421 - acc: 0.6049 - val_loss: 0.7202 - val_acc: 0.5278\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.6532 - acc: 0.6296 - val_loss: 0.7205 - val_acc: 0.5278\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 0.6484 - acc: 0.6173 - val_loss: 0.7206 - val_acc: 0.5278\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.6541 - acc: 0.6296 - val_loss: 0.7208 - val_acc: 0.5278\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 0.6286 - acc: 0.6543 - val_loss: 0.7217 - val_acc: 0.5278\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.6606 - acc: 0.6296 - val_loss: 0.7231 - val_acc: 0.5278\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 813us/step - loss: 0.6378 - acc: 0.6049 - val_loss: 0.7244 - val_acc: 0.5278\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 743us/step - loss: 0.6334 - acc: 0.6420 - val_loss: 0.7253 - val_acc: 0.5278\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.6461 - acc: 0.6296 - val_loss: 0.7263 - val_acc: 0.5278\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 0.6284 - acc: 0.6296 - val_loss: 0.7280 - val_acc: 0.5278\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.6455 - acc: 0.6173 - val_loss: 0.7293 - val_acc: 0.5278\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6484 - acc: 0.6296 - val_loss: 0.7290 - val_acc: 0.5278\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 761us/step - loss: 0.6427 - acc: 0.6296 - val_loss: 0.7277 - val_acc: 0.5278\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 845us/step - loss: 0.6479 - acc: 0.6543 - val_loss: 0.7265 - val_acc: 0.5278\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6455 - acc: 0.6790 - val_loss: 0.7243 - val_acc: 0.5278\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6397 - acc: 0.6543 - val_loss: 0.7244 - val_acc: 0.5278\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6458 - acc: 0.6667 - val_loss: 0.7246 - val_acc: 0.5278\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.6493 - acc: 0.6296 - val_loss: 0.7232 - val_acc: 0.5278\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.6481 - acc: 0.6420 - val_loss: 0.7219 - val_acc: 0.5278\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6489 - acc: 0.6049 - val_loss: 0.7215 - val_acc: 0.5278\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 862us/step - loss: 0.6383 - acc: 0.6420 - val_loss: 0.7223 - val_acc: 0.5278\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 855us/step - loss: 0.6379 - acc: 0.6420 - val_loss: 0.7222 - val_acc: 0.5278\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.6564 - acc: 0.6173 - val_loss: 0.7221 - val_acc: 0.5278\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.6478 - acc: 0.6296 - val_loss: 0.7225 - val_acc: 0.5278\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 0.6569 - acc: 0.6420 - val_loss: 0.7220 - val_acc: 0.5278\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6472 - acc: 0.6296 - val_loss: 0.7217 - val_acc: 0.5278\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.6344 - acc: 0.6049 - val_loss: 0.7221 - val_acc: 0.5278\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6433 - acc: 0.6543 - val_loss: 0.7226 - val_acc: 0.5278\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.6451 - acc: 0.6543 - val_loss: 0.7241 - val_acc: 0.5278\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 813us/step - loss: 0.6457 - acc: 0.6420 - val_loss: 0.7251 - val_acc: 0.5278\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6504 - acc: 0.6296 - val_loss: 0.7250 - val_acc: 0.5278\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.6531 - acc: 0.6420 - val_loss: 0.7240 - val_acc: 0.5278\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.6393 - acc: 0.6173 - val_loss: 0.7233 - val_acc: 0.5278\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 0.6376 - acc: 0.6420 - val_loss: 0.7231 - val_acc: 0.5278\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.6449 - acc: 0.6173 - val_loss: 0.7239 - val_acc: 0.5278\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.6520 - acc: 0.6049 - val_loss: 0.7258 - val_acc: 0.5278\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.6374 - acc: 0.6543 - val_loss: 0.7261 - val_acc: 0.5278\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.6340 - acc: 0.6296 - val_loss: 0.7263 - val_acc: 0.5278\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 858us/step - loss: 0.6493 - acc: 0.6173 - val_loss: 0.7275 - val_acc: 0.5278\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 874us/step - loss: 0.6368 - acc: 0.6420 - val_loss: 0.7279 - val_acc: 0.5278\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 870us/step - loss: 0.6274 - acc: 0.6296 - val_loss: 0.7284 - val_acc: 0.5278\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 877us/step - loss: 0.6543 - acc: 0.6173 - val_loss: 0.7288 - val_acc: 0.5278\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6373 - acc: 0.6543 - val_loss: 0.7287 - val_acc: 0.5278\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6120 - acc: 0.6296 - val_loss: 0.7291 - val_acc: 0.5278\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.6497 - acc: 0.6296 - val_loss: 0.7292 - val_acc: 0.5278\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 0.6151 - acc: 0.6420 - val_loss: 0.7290 - val_acc: 0.5278\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 828us/step - loss: 0.6347 - acc: 0.6173 - val_loss: 0.7290 - val_acc: 0.5278\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 843us/step - loss: 0.6542 - acc: 0.6420 - val_loss: 0.7288 - val_acc: 0.5278\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 0.6404 - acc: 0.6543 - val_loss: 0.7286 - val_acc: 0.5278\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 893us/step - loss: 0.6268 - acc: 0.5926 - val_loss: 0.7282 - val_acc: 0.5278\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 859us/step - loss: 0.6349 - acc: 0.6420 - val_loss: 0.7279 - val_acc: 0.5278\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 880us/step - loss: 0.6277 - acc: 0.6667 - val_loss: 0.7276 - val_acc: 0.5278\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 948us/step - loss: 0.6200 - acc: 0.6667 - val_loss: 0.7281 - val_acc: 0.5278\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 903us/step - loss: 0.6464 - acc: 0.6296 - val_loss: 0.7275 - val_acc: 0.5278\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 940us/step - loss: 0.6371 - acc: 0.6420 - val_loss: 0.7271 - val_acc: 0.5278\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 966us/step - loss: 0.6393 - acc: 0.6420 - val_loss: 0.7279 - val_acc: 0.5278\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 965us/step - loss: 0.6496 - acc: 0.6420 - val_loss: 0.7270 - val_acc: 0.5278\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 959us/step - loss: 0.6307 - acc: 0.6296 - val_loss: 0.7272 - val_acc: 0.5278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 934us/step - loss: 0.6311 - acc: 0.6420 - val_loss: 0.7287 - val_acc: 0.5278\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 944us/step - loss: 0.6512 - acc: 0.6296 - val_loss: 0.7294 - val_acc: 0.5278\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 887us/step - loss: 0.6304 - acc: 0.6667 - val_loss: 0.7302 - val_acc: 0.5278\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 901us/step - loss: 0.6381 - acc: 0.6296 - val_loss: 0.7310 - val_acc: 0.5278\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 896us/step - loss: 0.6352 - acc: 0.6296 - val_loss: 0.7315 - val_acc: 0.5278\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 907us/step - loss: 0.6410 - acc: 0.6296 - val_loss: 0.7308 - val_acc: 0.5278\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 955us/step - loss: 0.6416 - acc: 0.6296 - val_loss: 0.7303 - val_acc: 0.5278\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 891us/step - loss: 0.6350 - acc: 0.6420 - val_loss: 0.7307 - val_acc: 0.5278\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 885us/step - loss: 0.6356 - acc: 0.6543 - val_loss: 0.7318 - val_acc: 0.5278\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 844us/step - loss: 0.6252 - acc: 0.6420 - val_loss: 0.7336 - val_acc: 0.5278\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.6334 - acc: 0.6420 - val_loss: 0.7364 - val_acc: 0.5278\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 877us/step - loss: 0.6230 - acc: 0.6296 - val_loss: 0.7369 - val_acc: 0.5278\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 859us/step - loss: 0.6197 - acc: 0.6543 - val_loss: 0.7372 - val_acc: 0.5278\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 879us/step - loss: 0.6461 - acc: 0.6543 - val_loss: 0.7378 - val_acc: 0.5278\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6396 - acc: 0.6420 - val_loss: 0.7378 - val_acc: 0.5278\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6362 - acc: 0.6049 - val_loss: 0.7357 - val_acc: 0.5278\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.6450 - acc: 0.6049 - val_loss: 0.7349 - val_acc: 0.5278\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 896us/step - loss: 0.6332 - acc: 0.6296 - val_loss: 0.7338 - val_acc: 0.5278\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 0.6197 - acc: 0.6296 - val_loss: 0.7345 - val_acc: 0.5278\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 868us/step - loss: 0.6336 - acc: 0.6420 - val_loss: 0.7354 - val_acc: 0.5278\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 859us/step - loss: 0.6365 - acc: 0.6420 - val_loss: 0.7350 - val_acc: 0.5278\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 870us/step - loss: 0.6203 - acc: 0.6296 - val_loss: 0.7367 - val_acc: 0.5278\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6252 - acc: 0.6420 - val_loss: 0.7372 - val_acc: 0.5278\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 0.6236 - acc: 0.6543 - val_loss: 0.7400 - val_acc: 0.5278\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6240 - acc: 0.6543 - val_loss: 0.7416 - val_acc: 0.5278\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 843us/step - loss: 0.6181 - acc: 0.6173 - val_loss: 0.7427 - val_acc: 0.5278\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 859us/step - loss: 0.6250 - acc: 0.6420 - val_loss: 0.7442 - val_acc: 0.5278\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 887us/step - loss: 0.6233 - acc: 0.6296 - val_loss: 0.7457 - val_acc: 0.5278\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 914us/step - loss: 0.6267 - acc: 0.6173 - val_loss: 0.7443 - val_acc: 0.5278\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 850us/step - loss: 0.6079 - acc: 0.6420 - val_loss: 0.7423 - val_acc: 0.5278\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 865us/step - loss: 0.6315 - acc: 0.6667 - val_loss: 0.7405 - val_acc: 0.5278\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6259 - acc: 0.6667 - val_loss: 0.7396 - val_acc: 0.5278\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 873us/step - loss: 0.6329 - acc: 0.6420 - val_loss: 0.7386 - val_acc: 0.5278\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.6262 - acc: 0.6420 - val_loss: 0.7384 - val_acc: 0.5278\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 873us/step - loss: 0.6160 - acc: 0.6667 - val_loss: 0.7380 - val_acc: 0.5278\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 854us/step - loss: 0.6355 - acc: 0.6296 - val_loss: 0.7387 - val_acc: 0.5278\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 900us/step - loss: 0.6118 - acc: 0.6543 - val_loss: 0.7398 - val_acc: 0.5278\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 901us/step - loss: 0.6310 - acc: 0.6667 - val_loss: 0.7417 - val_acc: 0.5278\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 950us/step - loss: 0.6161 - acc: 0.6667 - val_loss: 0.7432 - val_acc: 0.5278\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 938us/step - loss: 0.6157 - acc: 0.6296 - val_loss: 0.7440 - val_acc: 0.5278\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 0.6228 - acc: 0.6296 - val_loss: 0.7482 - val_acc: 0.5278\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 862us/step - loss: 0.6321 - acc: 0.6296 - val_loss: 0.7476 - val_acc: 0.5278\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 898us/step - loss: 0.6350 - acc: 0.6296 - val_loss: 0.7446 - val_acc: 0.5278\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 876us/step - loss: 0.6349 - acc: 0.6173 - val_loss: 0.7429 - val_acc: 0.5278\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 0.6178 - acc: 0.6420 - val_loss: 0.7417 - val_acc: 0.5278\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 897us/step - loss: 0.6107 - acc: 0.6296 - val_loss: 0.7427 - val_acc: 0.5278\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 978us/step - loss: 0.6389 - acc: 0.6296 - val_loss: 0.7449 - val_acc: 0.5278\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 929us/step - loss: 0.6300 - acc: 0.6914 - val_loss: 0.7455 - val_acc: 0.5278\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 930us/step - loss: 0.6154 - acc: 0.6543 - val_loss: 0.7462 - val_acc: 0.5278\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6230 - acc: 0.6543 - val_loss: 0.7465 - val_acc: 0.5278\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 968us/step - loss: 0.6322 - acc: 0.6296 - val_loss: 0.7467 - val_acc: 0.5278\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 943us/step - loss: 0.6189 - acc: 0.6420 - val_loss: 0.7484 - val_acc: 0.5278\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 962us/step - loss: 0.6051 - acc: 0.6420 - val_loss: 0.7504 - val_acc: 0.5278\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 962us/step - loss: 0.6165 - acc: 0.6049 - val_loss: 0.7525 - val_acc: 0.5278\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 960us/step - loss: 0.6279 - acc: 0.6296 - val_loss: 0.7527 - val_acc: 0.5278\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6324 - acc: 0.6420 - val_loss: 0.7510 - val_acc: 0.5278\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 977us/step - loss: 0.6185 - acc: 0.6296 - val_loss: 0.7483 - val_acc: 0.5278\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 986us/step - loss: 0.6259 - acc: 0.6420 - val_loss: 0.7456 - val_acc: 0.5278\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 979us/step - loss: 0.6341 - acc: 0.6049 - val_loss: 0.7472 - val_acc: 0.5278\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 991us/step - loss: 0.6005 - acc: 0.6296 - val_loss: 0.7478 - val_acc: 0.5278\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 978us/step - loss: 0.6053 - acc: 0.6173 - val_loss: 0.7507 - val_acc: 0.5278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 994us/step - loss: 0.6259 - acc: 0.6420 - val_loss: 0.7556 - val_acc: 0.5278\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 926us/step - loss: 0.6230 - acc: 0.6296 - val_loss: 0.7559 - val_acc: 0.5278\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 882us/step - loss: 0.6340 - acc: 0.6296 - val_loss: 0.7555 - val_acc: 0.5278\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 877us/step - loss: 0.6252 - acc: 0.6173 - val_loss: 0.7556 - val_acc: 0.5278\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 0.6142 - acc: 0.6296 - val_loss: 0.7554 - val_acc: 0.5278\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 885us/step - loss: 0.6313 - acc: 0.6420 - val_loss: 0.7553 - val_acc: 0.5278\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 863us/step - loss: 0.6060 - acc: 0.6543 - val_loss: 0.7547 - val_acc: 0.5278\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.6229 - acc: 0.6420 - val_loss: 0.7560 - val_acc: 0.5278\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 939us/step - loss: 0.6006 - acc: 0.6543 - val_loss: 0.7582 - val_acc: 0.5278\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 899us/step - loss: 0.6348 - acc: 0.6173 - val_loss: 0.7586 - val_acc: 0.5278\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 974us/step - loss: 0.6170 - acc: 0.6543 - val_loss: 0.7594 - val_acc: 0.5278\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 930us/step - loss: 0.6308 - acc: 0.6296 - val_loss: 0.7588 - val_acc: 0.5278\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 922us/step - loss: 0.6185 - acc: 0.6420 - val_loss: 0.7573 - val_acc: 0.5278\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 896us/step - loss: 0.6179 - acc: 0.6543 - val_loss: 0.7544 - val_acc: 0.5278\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 893us/step - loss: 0.6211 - acc: 0.6420 - val_loss: 0.7579 - val_acc: 0.5278\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 889us/step - loss: 0.6155 - acc: 0.6173 - val_loss: 0.7564 - val_acc: 0.5278\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 0.6383 - acc: 0.5926 - val_loss: 0.7545 - val_acc: 0.5278\n",
      "<keras.callbacks.History object at 0x1a1ac8e7f0>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 197us/step\n",
      "loss: 0.8010463714599609\n",
      "acc: 0.5384615659713745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a28bf3f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83624774]\n",
      " [0.7165852 ]\n",
      " [0.6130231 ]\n",
      " [0.70814836]\n",
      " [0.7612719 ]\n",
      " [0.797065  ]\n",
      " [0.87080127]\n",
      " [0.8047989 ]\n",
      " [0.8282402 ]\n",
      " [0.7888115 ]\n",
      " [0.6910508 ]\n",
      " [0.77179897]\n",
      " [0.6846151 ]\n",
      " [0.5989586 ]\n",
      " [0.65077466]\n",
      " [0.6535641 ]\n",
      " [0.53145075]\n",
      " [0.45334014]\n",
      " [0.4871906 ]\n",
      " [0.43419337]\n",
      " [0.45050415]\n",
      " [0.5630208 ]\n",
      " [0.5844173 ]\n",
      " [0.5315968 ]\n",
      " [0.5255142 ]\n",
      " [0.63749164]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        14\n",
      "        1.0       0.46      1.00      0.63        12\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.07      0.13        14\n",
      "        1.0       0.48      1.00      0.65        12\n",
      "\n",
      "avg / total       0.76      0.50      0.37        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.21      0.33        14\n",
      "        1.0       0.50      0.92      0.65        12\n",
      "\n",
      "avg / total       0.63      0.54      0.48        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.36      0.48        14\n",
      "        1.0       0.53      0.83      0.65        12\n",
      "\n",
      "avg / total       0.63      0.58      0.55        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.43      0.50        14\n",
      "        1.0       0.50      0.67      0.57        12\n",
      "\n",
      "avg / total       0.55      0.54      0.53        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      0.50      0.54        14\n",
      "        1.0       0.50      0.58      0.54        12\n",
      "\n",
      "avg / total       0.54      0.54      0.54        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.57      0.53        14\n",
      "        1.0       0.40      0.33      0.36        12\n",
      "\n",
      "avg / total       0.45      0.46      0.46        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.64      0.56        14\n",
      "        1.0       0.38      0.25      0.30        12\n",
      "\n",
      "avg / total       0.44      0.46      0.44        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.86      0.67        14\n",
      "        1.0       0.50      0.17      0.25        12\n",
      "\n",
      "avg / total       0.52      0.54      0.47        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      0.93      0.67        14\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.28      0.50      0.36        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.54      1.00      0.70        14\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XRAY\n",
      "Target\tPredict\tConsequence\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "0.0\t1\tLoss\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "1.0\t1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t0\tNothing\n",
      "\n",
      "\n",
      "[{'month_id': 223, 'QAId': 'XRAY'}, {'month_id': 224, 'QAId': 'XRAY'}, {'month_id': 226, 'QAId': 'XRAY'}, {'month_id': 227, 'QAId': 'XRAY'}, {'month_id': 228, 'QAId': 'XRAY'}, {'month_id': 229, 'QAId': 'XRAY'}, {'month_id': 230, 'QAId': 'XRAY'}, {'month_id': 231, 'QAId': 'XRAY'}, {'month_id': 232, 'QAId': 'XRAY'}, {'month_id': 233, 'QAId': 'XRAY'}, {'month_id': 234, 'QAId': 'XRAY'}, {'month_id': 235, 'QAId': 'XRAY'}]\n",
      "[{'month_id': 236, 'QAId': 'XRAY'}, {'month_id': 239, 'QAId': 'XRAY'}, {'month_id': 240, 'QAId': 'XRAY'}, {'month_id': 241, 'QAId': 'XRAY'}, {'month_id': 242, 'QAId': 'XRAY'}, {'month_id': 243, 'QAId': 'XRAY'}, {'month_id': 244, 'QAId': 'XRAY'}, {'month_id': 245, 'QAId': 'XRAY'}, {'month_id': 246, 'QAId': 'XRAY'}, {'month_id': 247, 'QAId': 'XRAY'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "for j, stock in enumerate(chosen_stocks):\n",
    "  print(stock)\n",
    "  sorted_result = sorted(map(lambda x: x[j], result))\n",
    "  midpt = (sorted_result[-2] + sorted_result[1]) / 2\n",
    "  upper_threshold = midpt * 1.05\n",
    "  lower_threshold = midpt * 0.95\n",
    "  \n",
    "  print(\"Target\\tPredict\\tConsequence\")\n",
    "  for i, r in enumerate(result):\n",
    "    prediction = r[j].item()\n",
    "    target = y_test[i][j].item()\n",
    "    buy_or_sell = 1 if prediction > upper_threshold else (-1 if prediction < lower_threshold else 0)\n",
    "    if prediction > upper_threshold:\n",
    "      buy_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    if prediction < lower_threshold:\n",
    "      sell_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    \n",
    "    to_print = str(target) + \"\\t\" + str(buy_or_sell)\n",
    "    if (buy_or_sell == -1 and target == 0) or (buy_or_sell == 1 and target == 1):\n",
    "      print(to_print + \"\\tGain\")\n",
    "    elif (buy_or_sell == -1 and target == 1) or (buy_or_sell == 1 and target == 0):\n",
    "      print(to_print + \"\\tLoss\")\n",
    "    else:\n",
    "      print(to_print + \"\\tNothing\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       223  XRAY\n",
       "1       224  XRAY\n",
       "2       226  XRAY\n",
       "3       227  XRAY\n",
       "4       228  XRAY"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242</td>\n",
       "      <td>XRAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       236  XRAY\n",
       "1       239  XRAY\n",
       "2       240  XRAY\n",
       "3       241  XRAY\n",
       "4       242  XRAY"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
