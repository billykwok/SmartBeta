{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12 # or 54\n",
    "lookback = 3\n",
    "chosen_stocks = [\"GE\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=256, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 2s 30ms/step - loss: 5.2547 - acc: 0.4691 - val_loss: 3.1344 - val_acc: 0.4167\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 746us/step - loss: 2.7014 - acc: 0.4691 - val_loss: 2.6515 - val_acc: 0.4167\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 758us/step - loss: 2.3854 - acc: 0.4691 - val_loss: 2.4100 - val_acc: 0.4167\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 747us/step - loss: 2.2118 - acc: 0.4691 - val_loss: 2.2637 - val_acc: 0.4167\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 739us/step - loss: 2.0858 - acc: 0.4691 - val_loss: 2.1585 - val_acc: 0.4167\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 743us/step - loss: 2.0021 - acc: 0.4691 - val_loss: 2.0774 - val_acc: 0.4167\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 735us/step - loss: 1.9157 - acc: 0.4691 - val_loss: 2.0100 - val_acc: 0.4167\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 745us/step - loss: 1.8749 - acc: 0.4691 - val_loss: 1.9509 - val_acc: 0.4167\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 750us/step - loss: 1.8065 - acc: 0.4691 - val_loss: 1.8977 - val_acc: 0.4167\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 1.7494 - acc: 0.4691 - val_loss: 1.8491 - val_acc: 0.4167\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 1.7191 - acc: 0.4691 - val_loss: 1.8037 - val_acc: 0.4167\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 758us/step - loss: 1.6647 - acc: 0.4691 - val_loss: 1.7608 - val_acc: 0.4167\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 1.6459 - acc: 0.4691 - val_loss: 1.7201 - val_acc: 0.4167\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 795us/step - loss: 1.5946 - acc: 0.4691 - val_loss: 1.6811 - val_acc: 0.4167\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 1.5834 - acc: 0.4691 - val_loss: 1.6432 - val_acc: 0.4167\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 1.5265 - acc: 0.4691 - val_loss: 1.6067 - val_acc: 0.4167\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 1.5066 - acc: 0.4691 - val_loss: 1.5721 - val_acc: 0.4167\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 1.4811 - acc: 0.4691 - val_loss: 1.5387 - val_acc: 0.4167\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 1.4469 - acc: 0.4691 - val_loss: 1.5070 - val_acc: 0.4167\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 759us/step - loss: 1.4198 - acc: 0.4691 - val_loss: 1.4763 - val_acc: 0.4167\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 728us/step - loss: 1.3844 - acc: 0.4691 - val_loss: 1.4460 - val_acc: 0.4167\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 719us/step - loss: 1.3611 - acc: 0.4691 - val_loss: 1.4162 - val_acc: 0.4167\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 682us/step - loss: 1.3365 - acc: 0.4691 - val_loss: 1.3866 - val_acc: 0.4167\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 716us/step - loss: 1.3067 - acc: 0.4691 - val_loss: 1.3578 - val_acc: 0.4167\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 1.2769 - acc: 0.4691 - val_loss: 1.3292 - val_acc: 0.4167\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 1.2650 - acc: 0.4691 - val_loss: 1.3012 - val_acc: 0.4167\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 1.2326 - acc: 0.4691 - val_loss: 1.2738 - val_acc: 0.4167\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 1.2087 - acc: 0.4691 - val_loss: 1.2466 - val_acc: 0.4167\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 1.1898 - acc: 0.4691 - val_loss: 1.2195 - val_acc: 0.4167\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 1.1613 - acc: 0.4691 - val_loss: 1.1937 - val_acc: 0.4167\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 771us/step - loss: 1.1441 - acc: 0.4691 - val_loss: 1.1683 - val_acc: 0.4167\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 1.1228 - acc: 0.4691 - val_loss: 1.1437 - val_acc: 0.4167\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 1.0993 - acc: 0.4691 - val_loss: 1.1193 - val_acc: 0.4167\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 1.0817 - acc: 0.4691 - val_loss: 1.0954 - val_acc: 0.4167\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 1.0562 - acc: 0.4691 - val_loss: 1.0721 - val_acc: 0.4167\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 753us/step - loss: 1.0310 - acc: 0.4691 - val_loss: 1.0491 - val_acc: 0.4167\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 844us/step - loss: 1.0078 - acc: 0.4691 - val_loss: 1.0267 - val_acc: 0.4167\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 929us/step - loss: 0.9948 - acc: 0.4691 - val_loss: 1.0043 - val_acc: 0.4167\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.9768 - acc: 0.4691 - val_loss: 0.9824 - val_acc: 0.4167\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 870us/step - loss: 0.9593 - acc: 0.4691 - val_loss: 0.9613 - val_acc: 0.4167\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.9330 - acc: 0.4691 - val_loss: 0.9406 - val_acc: 0.4167\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 0.9278 - acc: 0.4691 - val_loss: 0.9206 - val_acc: 0.4167\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 0.9030 - acc: 0.4691 - val_loss: 0.9016 - val_acc: 0.4167\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.8889 - acc: 0.4691 - val_loss: 0.8833 - val_acc: 0.4167\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 769us/step - loss: 0.8674 - acc: 0.4691 - val_loss: 0.8653 - val_acc: 0.4167\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 0.8586 - acc: 0.4691 - val_loss: 0.8484 - val_acc: 0.4167\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.8434 - acc: 0.4691 - val_loss: 0.8321 - val_acc: 0.4167\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 0.8388 - acc: 0.4691 - val_loss: 0.8170 - val_acc: 0.4167\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.8163 - acc: 0.4691 - val_loss: 0.8023 - val_acc: 0.4167\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.8090 - acc: 0.4691 - val_loss: 0.7878 - val_acc: 0.4167\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 0.7952 - acc: 0.4691 - val_loss: 0.7747 - val_acc: 0.4167\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 868us/step - loss: 0.7790 - acc: 0.4691 - val_loss: 0.7630 - val_acc: 0.4167\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 773us/step - loss: 0.7558 - acc: 0.4691 - val_loss: 0.7521 - val_acc: 0.4167\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 764us/step - loss: 0.7725 - acc: 0.4691 - val_loss: 0.7421 - val_acc: 0.4167\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 0.7506 - acc: 0.4691 - val_loss: 0.7333 - val_acc: 0.4167\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 764us/step - loss: 0.7382 - acc: 0.4691 - val_loss: 0.7259 - val_acc: 0.4167\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 0.7372 - acc: 0.4815 - val_loss: 0.7194 - val_acc: 0.4444\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.7383 - acc: 0.4198 - val_loss: 0.7137 - val_acc: 0.4167\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.7345 - acc: 0.4691 - val_loss: 0.7094 - val_acc: 0.3611\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.7219 - acc: 0.4198 - val_loss: 0.7060 - val_acc: 0.3333\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.7300 - acc: 0.4321 - val_loss: 0.7034 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.7186 - acc: 0.4691 - val_loss: 0.7014 - val_acc: 0.5000\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 755us/step - loss: 0.7127 - acc: 0.4568 - val_loss: 0.7001 - val_acc: 0.5278\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.7230 - acc: 0.4691 - val_loss: 0.6994 - val_acc: 0.5833\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6976 - acc: 0.5185 - val_loss: 0.6990 - val_acc: 0.5833\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.7167 - acc: 0.3951 - val_loss: 0.6989 - val_acc: 0.5833\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.7240 - acc: 0.4198 - val_loss: 0.6990 - val_acc: 0.5833\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.7162 - acc: 0.4444 - val_loss: 0.6991 - val_acc: 0.5833\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 736us/step - loss: 0.7175 - acc: 0.4691 - val_loss: 0.6993 - val_acc: 0.5833\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 734us/step - loss: 0.7315 - acc: 0.3827 - val_loss: 0.6994 - val_acc: 0.5833\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.7210 - acc: 0.4198 - val_loss: 0.6995 - val_acc: 0.5833\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.7090 - acc: 0.4691 - val_loss: 0.6995 - val_acc: 0.5833\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 0.7307 - acc: 0.4074 - val_loss: 0.6994 - val_acc: 0.5833\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 929us/step - loss: 0.7278 - acc: 0.4074 - val_loss: 0.6993 - val_acc: 0.5833\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 951us/step - loss: 0.7170 - acc: 0.4691 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 759us/step - loss: 0.7020 - acc: 0.4938 - val_loss: 0.6991 - val_acc: 0.5833\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.7110 - acc: 0.4691 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.7110 - acc: 0.4444 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 890us/step - loss: 0.7060 - acc: 0.4691 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 0.6931 - acc: 0.5432 - val_loss: 0.6993 - val_acc: 0.5833\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 757us/step - loss: 0.7123 - acc: 0.4321 - val_loss: 0.6993 - val_acc: 0.5833\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 773us/step - loss: 0.7055 - acc: 0.4938 - val_loss: 0.6993 - val_acc: 0.5833\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 770us/step - loss: 0.7039 - acc: 0.4198 - val_loss: 0.6995 - val_acc: 0.5833\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 762us/step - loss: 0.7103 - acc: 0.4198 - val_loss: 0.6996 - val_acc: 0.5833\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.7182 - acc: 0.4198 - val_loss: 0.6998 - val_acc: 0.5833\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 764us/step - loss: 0.6993 - acc: 0.5185 - val_loss: 0.7001 - val_acc: 0.5833\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 756us/step - loss: 0.6994 - acc: 0.4074 - val_loss: 0.7002 - val_acc: 0.5833\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 746us/step - loss: 0.7053 - acc: 0.4568 - val_loss: 0.7004 - val_acc: 0.5833\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.7117 - acc: 0.4444 - val_loss: 0.7003 - val_acc: 0.5833\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 0.6973 - acc: 0.5309 - val_loss: 0.6999 - val_acc: 0.5833\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 747us/step - loss: 0.6996 - acc: 0.5062 - val_loss: 0.6998 - val_acc: 0.5833\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.7200 - acc: 0.3704 - val_loss: 0.6999 - val_acc: 0.5833\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 0.6960 - acc: 0.4938 - val_loss: 0.6998 - val_acc: 0.5833\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.7090 - acc: 0.4691 - val_loss: 0.6998 - val_acc: 0.5833\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.7079 - acc: 0.4321 - val_loss: 0.6999 - val_acc: 0.5833\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 756us/step - loss: 0.7062 - acc: 0.4568 - val_loss: 0.7000 - val_acc: 0.5833\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 795us/step - loss: 0.6955 - acc: 0.4815 - val_loss: 0.7002 - val_acc: 0.5833\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.7203 - acc: 0.4198 - val_loss: 0.7002 - val_acc: 0.5833\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.7128 - acc: 0.4815 - val_loss: 0.7002 - val_acc: 0.5833\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.7000 - val_acc: 0.5833\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.7121 - acc: 0.4938 - val_loss: 0.6999 - val_acc: 0.5833\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 840us/step - loss: 0.7035 - acc: 0.4568 - val_loss: 0.6998 - val_acc: 0.5833\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.7014 - acc: 0.4691 - val_loss: 0.6997 - val_acc: 0.5833\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 769us/step - loss: 0.7033 - acc: 0.4444 - val_loss: 0.6997 - val_acc: 0.5833\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 0.7059 - acc: 0.4691 - val_loss: 0.6996 - val_acc: 0.5833\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 0.7105 - acc: 0.4444 - val_loss: 0.6994 - val_acc: 0.5833\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 738us/step - loss: 0.7118 - acc: 0.4815 - val_loss: 0.6994 - val_acc: 0.5833\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 742us/step - loss: 0.7166 - acc: 0.4568 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 713us/step - loss: 0.6910 - acc: 0.5309 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.7048 - acc: 0.4938 - val_loss: 0.6994 - val_acc: 0.5833\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.7004 - acc: 0.5309 - val_loss: 0.6996 - val_acc: 0.5833\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.7005 - acc: 0.4815 - val_loss: 0.6996 - val_acc: 0.5833\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.6956 - acc: 0.5062 - val_loss: 0.6999 - val_acc: 0.5833\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 0.6846 - acc: 0.6173 - val_loss: 0.7001 - val_acc: 0.5833\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 729us/step - loss: 0.7152 - acc: 0.4444 - val_loss: 0.7003 - val_acc: 0.5833\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 721us/step - loss: 0.7142 - acc: 0.4321 - val_loss: 0.7008 - val_acc: 0.5833\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 712us/step - loss: 0.6988 - acc: 0.4938 - val_loss: 0.7008 - val_acc: 0.5833\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 760us/step - loss: 0.7089 - acc: 0.4568 - val_loss: 0.7011 - val_acc: 0.5833\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.6933 - acc: 0.5185 - val_loss: 0.7011 - val_acc: 0.5833\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.7062 - acc: 0.4074 - val_loss: 0.7014 - val_acc: 0.5833\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.6892 - acc: 0.4938 - val_loss: 0.7015 - val_acc: 0.5833\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 745us/step - loss: 0.7142 - acc: 0.4568 - val_loss: 0.7016 - val_acc: 0.5833\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 757us/step - loss: 0.7024 - acc: 0.4198 - val_loss: 0.7015 - val_acc: 0.5833\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 756us/step - loss: 0.7019 - acc: 0.5185 - val_loss: 0.7018 - val_acc: 0.5833\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 773us/step - loss: 0.7055 - acc: 0.4815 - val_loss: 0.7018 - val_acc: 0.5833\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 720us/step - loss: 0.7151 - acc: 0.4568 - val_loss: 0.7017 - val_acc: 0.5833\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 729us/step - loss: 0.6968 - acc: 0.4568 - val_loss: 0.7017 - val_acc: 0.5833\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 0.7003 - acc: 0.4815 - val_loss: 0.7015 - val_acc: 0.5833\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 0.6920 - acc: 0.5062 - val_loss: 0.7011 - val_acc: 0.5833\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.7030 - acc: 0.4938 - val_loss: 0.7010 - val_acc: 0.5833\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.6924 - acc: 0.4815 - val_loss: 0.7014 - val_acc: 0.5833\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 0.7179 - acc: 0.4444 - val_loss: 0.7015 - val_acc: 0.5833\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 761us/step - loss: 0.6982 - acc: 0.5556 - val_loss: 0.7011 - val_acc: 0.5833\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 769us/step - loss: 0.6881 - acc: 0.5185 - val_loss: 0.7013 - val_acc: 0.5833\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 0.7001 - acc: 0.5185 - val_loss: 0.7013 - val_acc: 0.5833\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6964 - acc: 0.4691 - val_loss: 0.7015 - val_acc: 0.5833\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.6924 - acc: 0.4938 - val_loss: 0.7019 - val_acc: 0.5833\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 0.6911 - acc: 0.5432 - val_loss: 0.7023 - val_acc: 0.5833\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 0.6793 - acc: 0.5679 - val_loss: 0.7034 - val_acc: 0.5833\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.6993 - acc: 0.5062 - val_loss: 0.7031 - val_acc: 0.5833\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6949 - acc: 0.5556 - val_loss: 0.7035 - val_acc: 0.5833\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 845us/step - loss: 0.6913 - acc: 0.5556 - val_loss: 0.7036 - val_acc: 0.5833\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6848 - acc: 0.5432 - val_loss: 0.7036 - val_acc: 0.5833\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.7062 - acc: 0.4691 - val_loss: 0.7040 - val_acc: 0.5833\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.6980 - acc: 0.4815 - val_loss: 0.7037 - val_acc: 0.5833\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.6862 - acc: 0.5556 - val_loss: 0.7039 - val_acc: 0.5833\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.6867 - acc: 0.5309 - val_loss: 0.7045 - val_acc: 0.5833\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.7006 - acc: 0.4938 - val_loss: 0.7046 - val_acc: 0.5833\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6934 - acc: 0.5185 - val_loss: 0.7043 - val_acc: 0.5833\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 813us/step - loss: 0.6905 - acc: 0.5679 - val_loss: 0.7041 - val_acc: 0.5833\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.6945 - acc: 0.4815 - val_loss: 0.7041 - val_acc: 0.5833\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6928 - acc: 0.5062 - val_loss: 0.7037 - val_acc: 0.5833\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 0.6866 - acc: 0.4938 - val_loss: 0.7036 - val_acc: 0.5833\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 872us/step - loss: 0.6915 - acc: 0.5309 - val_loss: 0.7049 - val_acc: 0.5833\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6877 - acc: 0.5802 - val_loss: 0.7057 - val_acc: 0.5833\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.6873 - acc: 0.5679 - val_loss: 0.7056 - val_acc: 0.5833\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 0.6841 - acc: 0.5185 - val_loss: 0.7053 - val_acc: 0.5833\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6856 - acc: 0.5185 - val_loss: 0.7052 - val_acc: 0.5833\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 0.7022 - acc: 0.5309 - val_loss: 0.7053 - val_acc: 0.5833\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.6774 - acc: 0.5556 - val_loss: 0.7047 - val_acc: 0.5833\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6812 - acc: 0.5309 - val_loss: 0.7049 - val_acc: 0.5833\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6829 - acc: 0.5185 - val_loss: 0.7051 - val_acc: 0.5833\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6732 - acc: 0.5556 - val_loss: 0.7051 - val_acc: 0.5833\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.6918 - acc: 0.4444 - val_loss: 0.7045 - val_acc: 0.5833\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6849 - acc: 0.5432 - val_loss: 0.7037 - val_acc: 0.5833\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6892 - acc: 0.5185 - val_loss: 0.7043 - val_acc: 0.5833\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.6814 - acc: 0.5062 - val_loss: 0.7043 - val_acc: 0.5833\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.6932 - acc: 0.5432 - val_loss: 0.7047 - val_acc: 0.5833\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.6897 - acc: 0.4444 - val_loss: 0.7041 - val_acc: 0.5833\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6865 - acc: 0.5679 - val_loss: 0.7037 - val_acc: 0.5833\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6784 - acc: 0.5432 - val_loss: 0.7040 - val_acc: 0.5833\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.6779 - acc: 0.4815 - val_loss: 0.7052 - val_acc: 0.5833\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 0.6772 - acc: 0.5309 - val_loss: 0.7057 - val_acc: 0.5833\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6913 - acc: 0.5185 - val_loss: 0.7058 - val_acc: 0.5833\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.7041 - acc: 0.4815 - val_loss: 0.7059 - val_acc: 0.5833\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.6848 - acc: 0.5309 - val_loss: 0.7052 - val_acc: 0.5833\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 780us/step - loss: 0.6792 - acc: 0.5802 - val_loss: 0.7050 - val_acc: 0.5833\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.6751 - acc: 0.4815 - val_loss: 0.7053 - val_acc: 0.5833\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6822 - acc: 0.5926 - val_loss: 0.7048 - val_acc: 0.5833\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 874us/step - loss: 0.6857 - acc: 0.5802 - val_loss: 0.7048 - val_acc: 0.5833\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.6967 - acc: 0.5432 - val_loss: 0.7049 - val_acc: 0.5833\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 863us/step - loss: 0.6874 - acc: 0.5309 - val_loss: 0.7040 - val_acc: 0.5833\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 914us/step - loss: 0.6919 - acc: 0.5432 - val_loss: 0.7036 - val_acc: 0.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 851us/step - loss: 0.6807 - acc: 0.5309 - val_loss: 0.7032 - val_acc: 0.5833\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 873us/step - loss: 0.6798 - acc: 0.6173 - val_loss: 0.7035 - val_acc: 0.5833\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 843us/step - loss: 0.6697 - acc: 0.5679 - val_loss: 0.7042 - val_acc: 0.5833\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 879us/step - loss: 0.6819 - acc: 0.6420 - val_loss: 0.7037 - val_acc: 0.5833\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6761 - acc: 0.5309 - val_loss: 0.7041 - val_acc: 0.5833\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 887us/step - loss: 0.6824 - acc: 0.5679 - val_loss: 0.7043 - val_acc: 0.5833\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 0.6693 - acc: 0.5679 - val_loss: 0.7051 - val_acc: 0.5833\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 879us/step - loss: 0.6801 - acc: 0.5432 - val_loss: 0.7059 - val_acc: 0.5833\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.6698 - acc: 0.5679 - val_loss: 0.7065 - val_acc: 0.5833\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 0.6704 - acc: 0.6049 - val_loss: 0.7067 - val_acc: 0.5833\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6663 - acc: 0.5926 - val_loss: 0.7080 - val_acc: 0.5833\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6741 - acc: 0.5802 - val_loss: 0.7089 - val_acc: 0.5833\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.6869 - acc: 0.5432 - val_loss: 0.7095 - val_acc: 0.5833\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6721 - acc: 0.5802 - val_loss: 0.7106 - val_acc: 0.5833\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 0.6775 - acc: 0.5679 - val_loss: 0.7106 - val_acc: 0.5833\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6690 - acc: 0.6173 - val_loss: 0.7098 - val_acc: 0.5833\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6717 - acc: 0.6173 - val_loss: 0.7084 - val_acc: 0.5833\n",
      "<keras.callbacks.History object at 0x1a2cd9d978>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 352us/step\n",
      "loss: 0.6924936771392822\n",
      "acc: 0.4615384638309479\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1105279e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6209168 ]\n",
      " [0.5824183 ]\n",
      " [0.54834145]\n",
      " [0.6001399 ]\n",
      " [0.6020034 ]\n",
      " [0.557506  ]\n",
      " [0.54927593]\n",
      " [0.5473402 ]\n",
      " [0.49038213]\n",
      " [0.5112806 ]\n",
      " [0.53024036]\n",
      " [0.5109982 ]\n",
      " [0.48778164]\n",
      " [0.52744657]\n",
      " [0.51308423]\n",
      " [0.48034063]\n",
      " [0.48324537]\n",
      " [0.51277494]\n",
      " [0.5258196 ]\n",
      " [0.53673804]\n",
      " [0.53051704]\n",
      " [0.52143604]\n",
      " [0.5395088 ]\n",
      " [0.5316327 ]\n",
      " [0.5940569 ]\n",
      " [0.5416289 ]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.25      0.08      0.12        12\n",
      "        1.0       0.50      0.79      0.61        14\n",
      "\n",
      "avg / total       0.38      0.46      0.39        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.45      0.75      0.56        12\n",
      "        1.0       0.50      0.21      0.30        14\n",
      "\n",
      "avg / total       0.48      0.46      0.42        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.92      0.63        12\n",
      "        1.0       0.67      0.14      0.24        14\n",
      "\n",
      "avg / total       0.58      0.50      0.42        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE\n",
      "Target\tPredict\tConsequence\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "0.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t-1\tLoss\n",
      "1.0\t-1\tLoss\n",
      "1.0\t0\tNothing\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "1.0\t0\tNothing\n",
      "0.0\t-1\tGain\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "1.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "0.0\t0\tNothing\n",
      "\n",
      "\n",
      "[{'month_id': 223, 'QAId': 'GE'}, {'month_id': 224, 'QAId': 'GE'}, {'month_id': 226, 'QAId': 'GE'}, {'month_id': 227, 'QAId': 'GE'}, {'month_id': 247, 'QAId': 'GE'}]\n",
      "[{'month_id': 231, 'QAId': 'GE'}, {'month_id': 232, 'QAId': 'GE'}, {'month_id': 234, 'QAId': 'GE'}, {'month_id': 235, 'QAId': 'GE'}, {'month_id': 237, 'QAId': 'GE'}, {'month_id': 238, 'QAId': 'GE'}, {'month_id': 239, 'QAId': 'GE'}, {'month_id': 240, 'QAId': 'GE'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "for j, stock in enumerate(chosen_stocks):\n",
    "  print(stock)\n",
    "  sorted_result = sorted(map(lambda x: x[j], result))\n",
    "  midpt = (sorted_result[-2] + sorted_result[1]) / 2\n",
    "  upper_threshold = midpt * 1.05\n",
    "  lower_threshold = midpt * 0.95\n",
    "  \n",
    "  print(\"Target\\tPredict\\tConsequence\")\n",
    "  for i, r in enumerate(result):\n",
    "    prediction = r[j].item()\n",
    "    target = y_test[i][j].item()\n",
    "    buy_or_sell = 1 if prediction > upper_threshold else (-1 if prediction < lower_threshold else 0)\n",
    "    if prediction > upper_threshold:\n",
    "      buy_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    if prediction < lower_threshold:\n",
    "      sell_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    \n",
    "    to_print = str(target) + \"\\t\" + str(buy_or_sell)\n",
    "    if (buy_or_sell == -1 and target == 0) or (buy_or_sell == 1 and target == 1):\n",
    "      print(to_print + \"\\tGain\")\n",
    "    elif (buy_or_sell == -1 and target == 1) or (buy_or_sell == 1 and target == 0):\n",
    "      print(to_print + \"\\tLoss\")\n",
    "    else:\n",
    "      print(to_print + \"\\tNothing\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id QAId\n",
       "0       223   GE\n",
       "1       224   GE\n",
       "2       226   GE\n",
       "3       227   GE\n",
       "4       247   GE"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id QAId\n",
       "0       231   GE\n",
       "1       232   GE\n",
       "2       234   GE\n",
       "3       235   GE\n",
       "4       237   GE"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
