{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-215d41aa-d8ba-44d8-b10a-820d6a9ab70d\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-215d41aa-d8ba-44d8-b10a-820d6a9ab70d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving return_2004_40.csv to return_2004_40.csv\n",
      "User uploaded file \"return_2004_40.csv\" with length 1494219 bytes\n"
     ]
    }
   ],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"GS\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 2s 29ms/step - loss: 3.4734 - acc: 0.4321 - val_loss: 3.0926 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 585us/step - loss: 2.6315 - acc: 0.4321 - val_loss: 2.7119 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 574us/step - loss: 2.3129 - acc: 0.4321 - val_loss: 2.5146 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 604us/step - loss: 2.1499 - acc: 0.4321 - val_loss: 2.3713 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 2.0197 - acc: 0.4321 - val_loss: 2.2596 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 1.9423 - acc: 0.4321 - val_loss: 2.1674 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 1.8663 - acc: 0.4321 - val_loss: 2.0890 - val_acc: 0.3333\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 1.7876 - acc: 0.4321 - val_loss: 2.0212 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 1.7247 - acc: 0.4321 - val_loss: 1.9611 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 1.6780 - acc: 0.4321 - val_loss: 1.9076 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 1.6498 - acc: 0.4321 - val_loss: 1.8588 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 1.6130 - acc: 0.4321 - val_loss: 1.8139 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 1.5576 - acc: 0.4321 - val_loss: 1.7729 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 614us/step - loss: 1.5379 - acc: 0.4321 - val_loss: 1.7345 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 560us/step - loss: 1.5047 - acc: 0.4321 - val_loss: 1.6974 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 1.4644 - acc: 0.4321 - val_loss: 1.6620 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 1.4367 - acc: 0.4321 - val_loss: 1.6279 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 1.4107 - acc: 0.4321 - val_loss: 1.5947 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 1.3868 - acc: 0.4321 - val_loss: 1.5624 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 1.3584 - acc: 0.4321 - val_loss: 1.5310 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 1.3260 - acc: 0.4321 - val_loss: 1.5009 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 1.2938 - acc: 0.4321 - val_loss: 1.4715 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 1.2884 - acc: 0.4321 - val_loss: 1.4429 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 557us/step - loss: 1.2461 - acc: 0.4321 - val_loss: 1.4148 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 1.2485 - acc: 0.4321 - val_loss: 1.3872 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 562us/step - loss: 1.2113 - acc: 0.4321 - val_loss: 1.3604 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 1.1939 - acc: 0.4321 - val_loss: 1.3340 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 557us/step - loss: 1.1686 - acc: 0.4321 - val_loss: 1.3084 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 556us/step - loss: 1.1438 - acc: 0.4321 - val_loss: 1.2832 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 569us/step - loss: 1.1212 - acc: 0.4321 - val_loss: 1.2584 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 1.1177 - acc: 0.4321 - val_loss: 1.2336 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 546us/step - loss: 1.0990 - acc: 0.4321 - val_loss: 1.2096 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 1.0751 - acc: 0.4321 - val_loss: 1.1858 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 1.0663 - acc: 0.4321 - val_loss: 1.1621 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 574us/step - loss: 1.0347 - acc: 0.4321 - val_loss: 1.1388 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 1.0218 - acc: 0.4321 - val_loss: 1.1160 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.9918 - acc: 0.4321 - val_loss: 1.0939 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 531us/step - loss: 0.9860 - acc: 0.4321 - val_loss: 1.0724 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 529us/step - loss: 0.9618 - acc: 0.4321 - val_loss: 1.0510 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.9492 - acc: 0.4321 - val_loss: 1.0296 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.9196 - acc: 0.4321 - val_loss: 1.0091 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 0.9049 - acc: 0.4321 - val_loss: 0.9888 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 498us/step - loss: 0.8925 - acc: 0.4321 - val_loss: 0.9690 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.8909 - acc: 0.4321 - val_loss: 0.9495 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 501us/step - loss: 0.8605 - acc: 0.4321 - val_loss: 0.9304 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 505us/step - loss: 0.8504 - acc: 0.4321 - val_loss: 0.9117 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.8541 - acc: 0.4321 - val_loss: 0.8936 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.8240 - acc: 0.4321 - val_loss: 0.8762 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 0.7988 - acc: 0.4321 - val_loss: 0.8594 - val_acc: 0.3333\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 0.8003 - acc: 0.4321 - val_loss: 0.8433 - val_acc: 0.3333\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.7775 - acc: 0.4321 - val_loss: 0.8274 - val_acc: 0.3333\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.7743 - acc: 0.4321 - val_loss: 0.8126 - val_acc: 0.3333\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 498us/step - loss: 0.7649 - acc: 0.4198 - val_loss: 0.7982 - val_acc: 0.3333\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.7633 - acc: 0.4198 - val_loss: 0.7851 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 504us/step - loss: 0.7331 - acc: 0.4568 - val_loss: 0.7727 - val_acc: 0.3333\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 502us/step - loss: 0.7435 - acc: 0.3951 - val_loss: 0.7607 - val_acc: 0.3333\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 502us/step - loss: 0.7272 - acc: 0.4691 - val_loss: 0.7499 - val_acc: 0.3056\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 498us/step - loss: 0.7412 - acc: 0.4198 - val_loss: 0.7397 - val_acc: 0.2500\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.7124 - acc: 0.4198 - val_loss: 0.7310 - val_acc: 0.2500\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 549us/step - loss: 0.7099 - acc: 0.5062 - val_loss: 0.7228 - val_acc: 0.3056\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.7249 - acc: 0.4444 - val_loss: 0.7152 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6915 - acc: 0.5432 - val_loss: 0.7092 - val_acc: 0.4167\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 0.7112 - acc: 0.4568 - val_loss: 0.7035 - val_acc: 0.4722\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.7259 - acc: 0.4815 - val_loss: 0.6989 - val_acc: 0.5833\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 726us/step - loss: 0.6950 - acc: 0.5309 - val_loss: 0.6949 - val_acc: 0.6111\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 844us/step - loss: 0.6962 - acc: 0.5185 - val_loss: 0.6917 - val_acc: 0.6389\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 765us/step - loss: 0.6987 - acc: 0.5309 - val_loss: 0.6888 - val_acc: 0.6667\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6904 - acc: 0.5432 - val_loss: 0.6868 - val_acc: 0.6667\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.7005 - acc: 0.5679 - val_loss: 0.6848 - val_acc: 0.6667\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 0.7102 - acc: 0.5309 - val_loss: 0.6835 - val_acc: 0.6389\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6896 - acc: 0.5802 - val_loss: 0.6828 - val_acc: 0.6389\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 522us/step - loss: 0.7017 - acc: 0.5926 - val_loss: 0.6826 - val_acc: 0.6389\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.7083 - acc: 0.5185 - val_loss: 0.6823 - val_acc: 0.6389\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 0.7033 - acc: 0.5432 - val_loss: 0.6825 - val_acc: 0.6389\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 0.6889 - acc: 0.5802 - val_loss: 0.6821 - val_acc: 0.6389\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6787 - acc: 0.6173 - val_loss: 0.6817 - val_acc: 0.6389\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.7223 - acc: 0.4938 - val_loss: 0.6819 - val_acc: 0.6389\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 512us/step - loss: 0.6848 - acc: 0.5432 - val_loss: 0.6822 - val_acc: 0.6389\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6930 - acc: 0.6049 - val_loss: 0.6825 - val_acc: 0.6389\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.6909 - acc: 0.5309 - val_loss: 0.6825 - val_acc: 0.6389\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 498us/step - loss: 0.6877 - acc: 0.5802 - val_loss: 0.6823 - val_acc: 0.6389\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 630us/step - loss: 0.7118 - acc: 0.4938 - val_loss: 0.6826 - val_acc: 0.6389\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 0.6944 - acc: 0.5185 - val_loss: 0.6826 - val_acc: 0.6389\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 710us/step - loss: 0.6975 - acc: 0.5556 - val_loss: 0.6823 - val_acc: 0.6389\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 655us/step - loss: 0.7056 - acc: 0.4815 - val_loss: 0.6820 - val_acc: 0.6389\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 0.6909 - acc: 0.5556 - val_loss: 0.6819 - val_acc: 0.6389\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6961 - acc: 0.5679 - val_loss: 0.6820 - val_acc: 0.6389\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 0.6965 - acc: 0.5802 - val_loss: 0.6821 - val_acc: 0.6389\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.7024 - acc: 0.4938 - val_loss: 0.6821 - val_acc: 0.6389\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6876 - acc: 0.5802 - val_loss: 0.6820 - val_acc: 0.6389\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 0.6979 - acc: 0.5432 - val_loss: 0.6820 - val_acc: 0.6389\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.6834 - acc: 0.6049 - val_loss: 0.6815 - val_acc: 0.6389\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6901 - acc: 0.5062 - val_loss: 0.6812 - val_acc: 0.6389\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 523us/step - loss: 0.6988 - acc: 0.5556 - val_loss: 0.6810 - val_acc: 0.6389\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.7104 - acc: 0.5679 - val_loss: 0.6812 - val_acc: 0.6389\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 505us/step - loss: 0.7199 - acc: 0.4938 - val_loss: 0.6810 - val_acc: 0.6389\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 508us/step - loss: 0.6899 - acc: 0.5432 - val_loss: 0.6808 - val_acc: 0.6389\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6977 - acc: 0.5185 - val_loss: 0.6802 - val_acc: 0.6389\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 590us/step - loss: 0.7124 - acc: 0.5432 - val_loss: 0.6801 - val_acc: 0.6389\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 649us/step - loss: 0.6746 - acc: 0.5802 - val_loss: 0.6796 - val_acc: 0.6389\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 700us/step - loss: 0.6829 - acc: 0.5556 - val_loss: 0.6795 - val_acc: 0.6389\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 677us/step - loss: 0.7003 - acc: 0.5802 - val_loss: 0.6796 - val_acc: 0.6389\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 547us/step - loss: 0.6910 - acc: 0.5556 - val_loss: 0.6792 - val_acc: 0.6667\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 519us/step - loss: 0.7109 - acc: 0.6049 - val_loss: 0.6791 - val_acc: 0.6667\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 534us/step - loss: 0.7061 - acc: 0.5062 - val_loss: 0.6790 - val_acc: 0.6667\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 520us/step - loss: 0.6877 - acc: 0.5432 - val_loss: 0.6790 - val_acc: 0.6667\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 0.6910 - acc: 0.5185 - val_loss: 0.6785 - val_acc: 0.6667\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.6772 - acc: 0.5556 - val_loss: 0.6784 - val_acc: 0.6667\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 498us/step - loss: 0.6873 - acc: 0.5556 - val_loss: 0.6783 - val_acc: 0.6667\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 510us/step - loss: 0.6939 - acc: 0.6049 - val_loss: 0.6782 - val_acc: 0.6667\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6712 - acc: 0.6420 - val_loss: 0.6778 - val_acc: 0.6667\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 506us/step - loss: 0.6978 - acc: 0.5802 - val_loss: 0.6778 - val_acc: 0.6667\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.7016 - acc: 0.5432 - val_loss: 0.6779 - val_acc: 0.6667\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 0.7090 - acc: 0.5679 - val_loss: 0.6780 - val_acc: 0.6667\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6972 - acc: 0.5679 - val_loss: 0.6786 - val_acc: 0.6667\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 499us/step - loss: 0.6809 - acc: 0.5679 - val_loss: 0.6787 - val_acc: 0.6667\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 508us/step - loss: 0.6952 - acc: 0.6173 - val_loss: 0.6786 - val_acc: 0.6667\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6883 - acc: 0.6049 - val_loss: 0.6786 - val_acc: 0.6667\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 522us/step - loss: 0.6905 - acc: 0.6049 - val_loss: 0.6785 - val_acc: 0.6667\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6873 - acc: 0.5926 - val_loss: 0.6782 - val_acc: 0.6667\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.6899 - acc: 0.6049 - val_loss: 0.6783 - val_acc: 0.6667\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 508us/step - loss: 0.6932 - acc: 0.6049 - val_loss: 0.6783 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 525us/step - loss: 0.6922 - acc: 0.5926 - val_loss: 0.6777 - val_acc: 0.6667\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 519us/step - loss: 0.6769 - acc: 0.6049 - val_loss: 0.6770 - val_acc: 0.6667\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6857 - acc: 0.5679 - val_loss: 0.6770 - val_acc: 0.6667\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6910 - acc: 0.5309 - val_loss: 0.6770 - val_acc: 0.6667\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 535us/step - loss: 0.6819 - acc: 0.5556 - val_loss: 0.6767 - val_acc: 0.6667\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 655us/step - loss: 0.6938 - acc: 0.5556 - val_loss: 0.6767 - val_acc: 0.6667\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.7040 - acc: 0.5556 - val_loss: 0.6765 - val_acc: 0.6667\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 512us/step - loss: 0.6991 - acc: 0.5802 - val_loss: 0.6763 - val_acc: 0.6667\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 567us/step - loss: 0.6849 - acc: 0.6049 - val_loss: 0.6761 - val_acc: 0.6667\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6832 - acc: 0.5679 - val_loss: 0.6759 - val_acc: 0.6667\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6961 - acc: 0.6049 - val_loss: 0.6758 - val_acc: 0.6667\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.6899 - acc: 0.5432 - val_loss: 0.6754 - val_acc: 0.6667\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 544us/step - loss: 0.6821 - acc: 0.5679 - val_loss: 0.6750 - val_acc: 0.6667\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6918 - acc: 0.5926 - val_loss: 0.6746 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 510us/step - loss: 0.6908 - acc: 0.5679 - val_loss: 0.6745 - val_acc: 0.6667\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6873 - acc: 0.5556 - val_loss: 0.6747 - val_acc: 0.6667\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.7050 - acc: 0.5556 - val_loss: 0.6746 - val_acc: 0.6667\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 523us/step - loss: 0.6817 - acc: 0.5926 - val_loss: 0.6745 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.6936 - acc: 0.5802 - val_loss: 0.6746 - val_acc: 0.6667\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6833 - acc: 0.5679 - val_loss: 0.6746 - val_acc: 0.6667\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 491us/step - loss: 0.6992 - acc: 0.5556 - val_loss: 0.6749 - val_acc: 0.6667\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.6749 - val_acc: 0.6667\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 0.7014 - acc: 0.5679 - val_loss: 0.6757 - val_acc: 0.6667\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 499us/step - loss: 0.6816 - acc: 0.6049 - val_loss: 0.6757 - val_acc: 0.6667\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6821 - acc: 0.6049 - val_loss: 0.6759 - val_acc: 0.6667\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 550us/step - loss: 0.6773 - acc: 0.6173 - val_loss: 0.6760 - val_acc: 0.6667\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6900 - acc: 0.5926 - val_loss: 0.6758 - val_acc: 0.6667\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.6716 - acc: 0.6296 - val_loss: 0.6756 - val_acc: 0.6667\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 0.6892 - acc: 0.5185 - val_loss: 0.6756 - val_acc: 0.6667\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6942 - acc: 0.5926 - val_loss: 0.6755 - val_acc: 0.6667\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 561us/step - loss: 0.6838 - acc: 0.5679 - val_loss: 0.6751 - val_acc: 0.6667\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 591us/step - loss: 0.6830 - acc: 0.5432 - val_loss: 0.6746 - val_acc: 0.6667\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 554us/step - loss: 0.6793 - acc: 0.5926 - val_loss: 0.6742 - val_acc: 0.6667\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 591us/step - loss: 0.6951 - acc: 0.6173 - val_loss: 0.6741 - val_acc: 0.6667\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 553us/step - loss: 0.6959 - acc: 0.5556 - val_loss: 0.6743 - val_acc: 0.6667\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 0.6723 - acc: 0.5926 - val_loss: 0.6743 - val_acc: 0.6667\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 591us/step - loss: 0.6738 - acc: 0.5556 - val_loss: 0.6743 - val_acc: 0.6667\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 546us/step - loss: 0.6791 - acc: 0.5926 - val_loss: 0.6741 - val_acc: 0.6667\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 0.6961 - acc: 0.5556 - val_loss: 0.6738 - val_acc: 0.6667\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 499us/step - loss: 0.6654 - acc: 0.6296 - val_loss: 0.6738 - val_acc: 0.6667\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 530us/step - loss: 0.6942 - acc: 0.5679 - val_loss: 0.6738 - val_acc: 0.6667\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6857 - acc: 0.5679 - val_loss: 0.6742 - val_acc: 0.6667\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.6767 - acc: 0.5926 - val_loss: 0.6740 - val_acc: 0.6667\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 574us/step - loss: 0.6832 - acc: 0.5679 - val_loss: 0.6740 - val_acc: 0.6667\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6888 - acc: 0.6049 - val_loss: 0.6738 - val_acc: 0.6667\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 520us/step - loss: 0.6898 - acc: 0.5926 - val_loss: 0.6736 - val_acc: 0.6667\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 505us/step - loss: 0.6778 - acc: 0.6173 - val_loss: 0.6735 - val_acc: 0.6667\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.6888 - acc: 0.5556 - val_loss: 0.6734 - val_acc: 0.6667\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.6749 - acc: 0.5802 - val_loss: 0.6730 - val_acc: 0.6667\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 545us/step - loss: 0.6883 - acc: 0.5679 - val_loss: 0.6727 - val_acc: 0.6667\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 0.6919 - acc: 0.6296 - val_loss: 0.6729 - val_acc: 0.6667\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6822 - acc: 0.5679 - val_loss: 0.6729 - val_acc: 0.6667\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 525us/step - loss: 0.6947 - acc: 0.5556 - val_loss: 0.6729 - val_acc: 0.6667\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 542us/step - loss: 0.6838 - acc: 0.6543 - val_loss: 0.6730 - val_acc: 0.6667\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 559us/step - loss: 0.6910 - acc: 0.5556 - val_loss: 0.6733 - val_acc: 0.6667\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6814 - acc: 0.5802 - val_loss: 0.6735 - val_acc: 0.6667\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 563us/step - loss: 0.6808 - acc: 0.5679 - val_loss: 0.6736 - val_acc: 0.6667\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6971 - acc: 0.5432 - val_loss: 0.6740 - val_acc: 0.6667\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6883 - acc: 0.6173 - val_loss: 0.6744 - val_acc: 0.6667\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 0.6850 - acc: 0.5432 - val_loss: 0.6749 - val_acc: 0.6667\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 552us/step - loss: 0.7012 - acc: 0.5309 - val_loss: 0.6752 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6802 - acc: 0.6173 - val_loss: 0.6747 - val_acc: 0.6667\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 558us/step - loss: 0.6836 - acc: 0.5556 - val_loss: 0.6747 - val_acc: 0.6667\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6953 - acc: 0.5926 - val_loss: 0.6742 - val_acc: 0.6667\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 527us/step - loss: 0.6936 - acc: 0.5926 - val_loss: 0.6740 - val_acc: 0.6667\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 529us/step - loss: 0.6824 - acc: 0.5802 - val_loss: 0.6735 - val_acc: 0.6667\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 0.7029 - acc: 0.5802 - val_loss: 0.6734 - val_acc: 0.6667\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 533us/step - loss: 0.6908 - acc: 0.5679 - val_loss: 0.6736 - val_acc: 0.6667\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 539us/step - loss: 0.6782 - acc: 0.5556 - val_loss: 0.6737 - val_acc: 0.6667\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 519us/step - loss: 0.7029 - acc: 0.5556 - val_loss: 0.6739 - val_acc: 0.6667\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6961 - acc: 0.5802 - val_loss: 0.6739 - val_acc: 0.6667\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.6948 - acc: 0.5802 - val_loss: 0.6742 - val_acc: 0.6667\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 540us/step - loss: 0.6963 - acc: 0.5309 - val_loss: 0.6742 - val_acc: 0.6667\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6738 - acc: 0.5802 - val_loss: 0.6740 - val_acc: 0.6667\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 536us/step - loss: 0.6960 - acc: 0.4815 - val_loss: 0.6737 - val_acc: 0.6667\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 510us/step - loss: 0.6835 - acc: 0.5926 - val_loss: 0.6736 - val_acc: 0.6667\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 512us/step - loss: 0.6714 - acc: 0.6543 - val_loss: 0.6735 - val_acc: 0.6667\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.6754 - acc: 0.6296 - val_loss: 0.6732 - val_acc: 0.6667\n",
      "<keras.callbacks.History object at 0x1a2eae7860>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 237us/step\n",
      "loss: 0.6907483339309692\n",
      "acc: 0.5384615659713745\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2c761dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56653774]\n",
      " [0.53969437]\n",
      " [0.5064615 ]\n",
      " [0.55630136]\n",
      " [0.5667262 ]\n",
      " [0.55900276]\n",
      " [0.5606319 ]\n",
      " [0.56749123]\n",
      " [0.53871036]\n",
      " [0.5071217 ]\n",
      " [0.51616704]\n",
      " [0.5303634 ]\n",
      " [0.52287483]\n",
      " [0.4980864 ]\n",
      " [0.49181396]\n",
      " [0.47283018]\n",
      " [0.48693877]\n",
      " [0.5206561 ]\n",
      " [0.5076249 ]\n",
      " [0.50872064]\n",
      " [0.5622761 ]\n",
      " [0.54465675]\n",
      " [0.5701835 ]\n",
      " [0.6108758 ]\n",
      " [0.6469806 ]\n",
      " [0.59423864]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.54      1.00      0.70        14\n",
      "\n",
      "avg / total       0.29      0.54      0.38        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.17      0.25        12\n",
      "        1.0       0.55      0.86      0.67        14\n",
      "\n",
      "avg / total       0.52      0.54      0.47        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.58      0.52        12\n",
      "        1.0       0.55      0.43      0.48        14\n",
      "\n",
      "avg / total       0.51      0.50      0.50        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.92      0.61        12\n",
      "        1.0       0.50      0.07      0.12        14\n",
      "\n",
      "avg / total       0.48      0.46      0.35        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      1.00      0.63        12\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.21      0.46      0.29        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 1\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "0.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "0.0: -1\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "0.0: 1\n",
      "Hey\n",
      "[{'month_id': 247, 'QAId': 'GS'}]\n",
      "[{'month_id': 236, 'QAId': 'GS'}, {'month_id': 237, 'QAId': 'GS'}, {'month_id': 238, 'QAId': 'GS'}, {'month_id': 239, 'QAId': 'GS'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "midpt = (max(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1 else (-1 if r.item() < midpt * 0.9 else 0)\n",
    "  if r.item() > midpt * 1.1:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.9:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id QAId\n",
       "0       236   GS\n",
       "1       237   GS\n",
       "2       238   GS\n",
       "3       239   GS"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
