{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"EBAY\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=512, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=256, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 4s 54ms/step - loss: 1.6544 - acc: 0.5309 - val_loss: 1.4710 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 1.2666 - acc: 0.5309 - val_loss: 1.2646 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 1.0982 - acc: 0.5309 - val_loss: 1.1365 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 1.0029 - acc: 0.5309 - val_loss: 1.0447 - val_acc: 0.5000\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.9264 - acc: 0.5309 - val_loss: 0.9733 - val_acc: 0.5000\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.8718 - acc: 0.5309 - val_loss: 0.9173 - val_acc: 0.5000\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.8206 - acc: 0.5309 - val_loss: 0.8728 - val_acc: 0.5000\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.7897 - acc: 0.5309 - val_loss: 0.8366 - val_acc: 0.5000\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.7579 - acc: 0.5309 - val_loss: 0.8071 - val_acc: 0.5000\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.7322 - acc: 0.5309 - val_loss: 0.7828 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.7327 - acc: 0.5309 - val_loss: 0.7625 - val_acc: 0.5000\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.7116 - acc: 0.5309 - val_loss: 0.7467 - val_acc: 0.5000\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6988 - acc: 0.5309 - val_loss: 0.7343 - val_acc: 0.5000\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6945 - acc: 0.5309 - val_loss: 0.7252 - val_acc: 0.5000\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6983 - acc: 0.5185 - val_loss: 0.7178 - val_acc: 0.5000\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6834 - acc: 0.5679 - val_loss: 0.7123 - val_acc: 0.5000\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5185 - val_loss: 0.7082 - val_acc: 0.5000\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5556 - val_loss: 0.7049 - val_acc: 0.5000\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6938 - acc: 0.5556 - val_loss: 0.7032 - val_acc: 0.5000\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6947 - acc: 0.4815 - val_loss: 0.7023 - val_acc: 0.5000\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6910 - acc: 0.5062 - val_loss: 0.7017 - val_acc: 0.5000\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.4938 - val_loss: 0.7014 - val_acc: 0.5000\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.4444 - val_loss: 0.7013 - val_acc: 0.5000\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6833 - acc: 0.5432 - val_loss: 0.7016 - val_acc: 0.5000\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6896 - acc: 0.5309 - val_loss: 0.7021 - val_acc: 0.5000\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6992 - acc: 0.5062 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5556 - val_loss: 0.7035 - val_acc: 0.5000\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6854 - acc: 0.5309 - val_loss: 0.7034 - val_acc: 0.5000\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6878 - acc: 0.5309 - val_loss: 0.7035 - val_acc: 0.5000\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6848 - acc: 0.5432 - val_loss: 0.7044 - val_acc: 0.5000\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.5802 - val_loss: 0.7048 - val_acc: 0.5000\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.5432 - val_loss: 0.7047 - val_acc: 0.5000\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6903 - acc: 0.5802 - val_loss: 0.7047 - val_acc: 0.5000\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6883 - acc: 0.5802 - val_loss: 0.7042 - val_acc: 0.5000\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6903 - acc: 0.5802 - val_loss: 0.7037 - val_acc: 0.5000\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6837 - acc: 0.5679 - val_loss: 0.7028 - val_acc: 0.5000\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6838 - acc: 0.5679 - val_loss: 0.7030 - val_acc: 0.5000\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6829 - acc: 0.6049 - val_loss: 0.7019 - val_acc: 0.5000\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6872 - acc: 0.5432 - val_loss: 0.7014 - val_acc: 0.5000\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6866 - acc: 0.6173 - val_loss: 0.7011 - val_acc: 0.5000\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6795 - acc: 0.6296 - val_loss: 0.7009 - val_acc: 0.5000\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6833 - acc: 0.5679 - val_loss: 0.7012 - val_acc: 0.5000\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6810 - acc: 0.6049 - val_loss: 0.7003 - val_acc: 0.5000\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6820 - acc: 0.5802 - val_loss: 0.6996 - val_acc: 0.5000\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6785 - acc: 0.6173 - val_loss: 0.7000 - val_acc: 0.5000\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6829 - acc: 0.5802 - val_loss: 0.6999 - val_acc: 0.5000\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6795 - acc: 0.6420 - val_loss: 0.6994 - val_acc: 0.5000\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.6296 - val_loss: 0.6988 - val_acc: 0.5278\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6765 - acc: 0.6296 - val_loss: 0.6985 - val_acc: 0.5278\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6785 - acc: 0.6049 - val_loss: 0.6989 - val_acc: 0.5278\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6770 - acc: 0.6049 - val_loss: 0.6995 - val_acc: 0.5000\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6868 - acc: 0.5802 - val_loss: 0.6996 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6731 - acc: 0.6173 - val_loss: 0.6998 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6810 - acc: 0.5926 - val_loss: 0.6998 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6789 - acc: 0.6296 - val_loss: 0.6999 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6822 - acc: 0.5926 - val_loss: 0.7000 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.6049 - val_loss: 0.7000 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6789 - acc: 0.6296 - val_loss: 0.6997 - val_acc: 0.5000\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6850 - acc: 0.5432 - val_loss: 0.6994 - val_acc: 0.5278\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.6173 - val_loss: 0.6995 - val_acc: 0.5278\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6802 - acc: 0.5802 - val_loss: 0.6992 - val_acc: 0.5278\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6784 - acc: 0.5926 - val_loss: 0.6991 - val_acc: 0.5278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6786 - acc: 0.6420 - val_loss: 0.6991 - val_acc: 0.5278\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6776 - acc: 0.6173 - val_loss: 0.6988 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6696 - acc: 0.6420 - val_loss: 0.6987 - val_acc: 0.5000\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6781 - acc: 0.6296 - val_loss: 0.6987 - val_acc: 0.5278\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6812 - acc: 0.6420 - val_loss: 0.6989 - val_acc: 0.5278\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6784 - acc: 0.6296 - val_loss: 0.6992 - val_acc: 0.5278\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6821 - acc: 0.6173 - val_loss: 0.6997 - val_acc: 0.5000\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6723 - acc: 0.6914 - val_loss: 0.7000 - val_acc: 0.5000\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6736 - acc: 0.6173 - val_loss: 0.7004 - val_acc: 0.5278\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6786 - acc: 0.6296 - val_loss: 0.7000 - val_acc: 0.5000\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.6420 - val_loss: 0.6999 - val_acc: 0.5000\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6805 - acc: 0.6296 - val_loss: 0.6999 - val_acc: 0.5000\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6721 - acc: 0.6790 - val_loss: 0.7002 - val_acc: 0.5000\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6759 - acc: 0.6420 - val_loss: 0.7006 - val_acc: 0.5000\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6773 - acc: 0.6296 - val_loss: 0.7007 - val_acc: 0.5000\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6759 - acc: 0.6296 - val_loss: 0.7011 - val_acc: 0.5278\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6802 - acc: 0.6543 - val_loss: 0.7010 - val_acc: 0.5278\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6733 - acc: 0.6173 - val_loss: 0.7010 - val_acc: 0.5000\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.6543 - val_loss: 0.7006 - val_acc: 0.5000\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6799 - acc: 0.5926 - val_loss: 0.7005 - val_acc: 0.5000\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.6667 - val_loss: 0.7003 - val_acc: 0.5556\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6664 - acc: 0.6667 - val_loss: 0.7002 - val_acc: 0.5556\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6695 - acc: 0.6667 - val_loss: 0.7000 - val_acc: 0.5556\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6653 - acc: 0.7037 - val_loss: 0.7005 - val_acc: 0.5833\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6733 - acc: 0.6296 - val_loss: 0.7008 - val_acc: 0.5556\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6668 - acc: 0.6296 - val_loss: 0.7009 - val_acc: 0.5556\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.6543 - val_loss: 0.7011 - val_acc: 0.5556\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6661 - acc: 0.6790 - val_loss: 0.7012 - val_acc: 0.5833\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6679 - acc: 0.6296 - val_loss: 0.7016 - val_acc: 0.5833\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6633 - acc: 0.6790 - val_loss: 0.7020 - val_acc: 0.5833\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6696 - acc: 0.6667 - val_loss: 0.7020 - val_acc: 0.5833\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6706 - acc: 0.6543 - val_loss: 0.7023 - val_acc: 0.5833\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.6708 - acc: 0.6667 - val_loss: 0.7025 - val_acc: 0.5833\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6768 - acc: 0.6049 - val_loss: 0.7036 - val_acc: 0.5278\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.6296 - val_loss: 0.7060 - val_acc: 0.5000\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6763 - acc: 0.6049 - val_loss: 0.7060 - val_acc: 0.5000\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6696 - acc: 0.6296 - val_loss: 0.7053 - val_acc: 0.5000\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6708 - acc: 0.6543 - val_loss: 0.7042 - val_acc: 0.5278\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6647 - acc: 0.6914 - val_loss: 0.7043 - val_acc: 0.5278\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6734 - acc: 0.6667 - val_loss: 0.7042 - val_acc: 0.5278\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6631 - acc: 0.6420 - val_loss: 0.7042 - val_acc: 0.5278\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6582 - acc: 0.6914 - val_loss: 0.7044 - val_acc: 0.5278\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6660 - acc: 0.6790 - val_loss: 0.7054 - val_acc: 0.5278\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6692 - acc: 0.5926 - val_loss: 0.7064 - val_acc: 0.5000\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6703 - acc: 0.6173 - val_loss: 0.7070 - val_acc: 0.5000\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6641 - acc: 0.6667 - val_loss: 0.7079 - val_acc: 0.5278\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6727 - acc: 0.6296 - val_loss: 0.7087 - val_acc: 0.5000\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6675 - acc: 0.6296 - val_loss: 0.7082 - val_acc: 0.5278\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6705 - acc: 0.6790 - val_loss: 0.7074 - val_acc: 0.5000\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6662 - acc: 0.6296 - val_loss: 0.7066 - val_acc: 0.5278\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6711 - acc: 0.6296 - val_loss: 0.7066 - val_acc: 0.5278\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6623 - acc: 0.6296 - val_loss: 0.7061 - val_acc: 0.5000\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6625 - acc: 0.6667 - val_loss: 0.7063 - val_acc: 0.4722\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6635 - acc: 0.6420 - val_loss: 0.7073 - val_acc: 0.5278\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6636 - acc: 0.6667 - val_loss: 0.7080 - val_acc: 0.5278\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6682 - acc: 0.6296 - val_loss: 0.7087 - val_acc: 0.5000\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6707 - acc: 0.6543 - val_loss: 0.7084 - val_acc: 0.5278\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6632 - acc: 0.6296 - val_loss: 0.7087 - val_acc: 0.5278\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6666 - acc: 0.6543 - val_loss: 0.7089 - val_acc: 0.5278\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6709 - acc: 0.6296 - val_loss: 0.7090 - val_acc: 0.5000\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6567 - acc: 0.6543 - val_loss: 0.7092 - val_acc: 0.5000\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6673 - acc: 0.5802 - val_loss: 0.7092 - val_acc: 0.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6643 - acc: 0.6296 - val_loss: 0.7099 - val_acc: 0.5000\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6570 - acc: 0.6667 - val_loss: 0.7125 - val_acc: 0.5000\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6608 - acc: 0.6914 - val_loss: 0.7141 - val_acc: 0.5278\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6605 - acc: 0.6667 - val_loss: 0.7149 - val_acc: 0.5278\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6664 - acc: 0.6296 - val_loss: 0.7146 - val_acc: 0.5278\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.6658 - acc: 0.5926 - val_loss: 0.7141 - val_acc: 0.5000\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6596 - acc: 0.6914 - val_loss: 0.7143 - val_acc: 0.5000\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6677 - acc: 0.6667 - val_loss: 0.7142 - val_acc: 0.5000\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6518 - acc: 0.6914 - val_loss: 0.7129 - val_acc: 0.5000\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6570 - acc: 0.6173 - val_loss: 0.7125 - val_acc: 0.4722\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.6574 - acc: 0.6420 - val_loss: 0.7131 - val_acc: 0.4722\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6631 - acc: 0.6173 - val_loss: 0.7135 - val_acc: 0.5000\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6542 - acc: 0.6296 - val_loss: 0.7152 - val_acc: 0.5000\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6550 - acc: 0.6667 - val_loss: 0.7169 - val_acc: 0.5278\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6547 - acc: 0.6420 - val_loss: 0.7180 - val_acc: 0.5278\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.6667 - val_loss: 0.7186 - val_acc: 0.5278\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.7037 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6504 - acc: 0.6667 - val_loss: 0.7147 - val_acc: 0.4444\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6535 - acc: 0.6420 - val_loss: 0.7142 - val_acc: 0.4722\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6647 - acc: 0.5679 - val_loss: 0.7172 - val_acc: 0.5000\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6595 - acc: 0.6420 - val_loss: 0.7189 - val_acc: 0.5000\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6583 - acc: 0.6420 - val_loss: 0.7198 - val_acc: 0.5278\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6547 - acc: 0.6667 - val_loss: 0.7233 - val_acc: 0.5278\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6478 - acc: 0.6420 - val_loss: 0.7224 - val_acc: 0.5278\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6616 - acc: 0.6420 - val_loss: 0.7211 - val_acc: 0.5000\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6495 - acc: 0.6667 - val_loss: 0.7209 - val_acc: 0.5000\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6460 - acc: 0.6667 - val_loss: 0.7206 - val_acc: 0.4722\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6474 - acc: 0.6914 - val_loss: 0.7220 - val_acc: 0.5000\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6914 - val_loss: 0.7233 - val_acc: 0.5000\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6590 - acc: 0.6296 - val_loss: 0.7251 - val_acc: 0.5278\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6500 - acc: 0.6790 - val_loss: 0.7248 - val_acc: 0.5278\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6462 - acc: 0.6667 - val_loss: 0.7277 - val_acc: 0.5278\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 0.6790 - val_loss: 0.7277 - val_acc: 0.5278\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.6790 - val_loss: 0.7274 - val_acc: 0.5278\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6473 - acc: 0.6543 - val_loss: 0.7282 - val_acc: 0.5278\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6516 - acc: 0.6543 - val_loss: 0.7304 - val_acc: 0.5278\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6420 - val_loss: 0.7331 - val_acc: 0.5278\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6493 - acc: 0.6790 - val_loss: 0.7354 - val_acc: 0.5278\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6500 - acc: 0.6914 - val_loss: 0.7360 - val_acc: 0.5278\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.6790 - val_loss: 0.7323 - val_acc: 0.5278\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6543 - val_loss: 0.7331 - val_acc: 0.5278\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6479 - acc: 0.6914 - val_loss: 0.7334 - val_acc: 0.5278\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6561 - acc: 0.6173 - val_loss: 0.7349 - val_acc: 0.5278\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.6543 - val_loss: 0.7404 - val_acc: 0.5278\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6429 - acc: 0.6914 - val_loss: 0.7433 - val_acc: 0.5278\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6397 - acc: 0.7160 - val_loss: 0.7417 - val_acc: 0.5278\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6411 - acc: 0.6790 - val_loss: 0.7386 - val_acc: 0.5000\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6420 - val_loss: 0.7371 - val_acc: 0.4722\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6443 - acc: 0.6667 - val_loss: 0.7389 - val_acc: 0.5000\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6416 - acc: 0.6296 - val_loss: 0.7370 - val_acc: 0.4722\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.6667 - val_loss: 0.7406 - val_acc: 0.4722\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6667 - val_loss: 0.7462 - val_acc: 0.5000\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6406 - acc: 0.6543 - val_loss: 0.7529 - val_acc: 0.5278\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6383 - acc: 0.6667 - val_loss: 0.7558 - val_acc: 0.5278\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6364 - acc: 0.6790 - val_loss: 0.7534 - val_acc: 0.5278\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.7160 - val_loss: 0.7462 - val_acc: 0.4722\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6285 - acc: 0.6543 - val_loss: 0.7443 - val_acc: 0.4722\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6405 - acc: 0.5926 - val_loss: 0.7473 - val_acc: 0.4722\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6348 - acc: 0.6667 - val_loss: 0.7548 - val_acc: 0.5000\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6428 - acc: 0.6173 - val_loss: 0.7587 - val_acc: 0.5000\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6408 - acc: 0.6914 - val_loss: 0.7669 - val_acc: 0.5278\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6312 - acc: 0.7037 - val_loss: 0.7676 - val_acc: 0.5278\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6440 - acc: 0.6914 - val_loss: 0.7711 - val_acc: 0.5278\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6294 - acc: 0.7037 - val_loss: 0.7631 - val_acc: 0.5000\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6408 - acc: 0.6543 - val_loss: 0.7633 - val_acc: 0.5000\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6352 - acc: 0.6420 - val_loss: 0.7662 - val_acc: 0.5000\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.6914 - val_loss: 0.7690 - val_acc: 0.5000\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6356 - acc: 0.6543 - val_loss: 0.7804 - val_acc: 0.5278\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6349 - acc: 0.6420 - val_loss: 0.7815 - val_acc: 0.5278\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6334 - acc: 0.6790 - val_loss: 0.7876 - val_acc: 0.5278\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6245 - acc: 0.6420 - val_loss: 0.7831 - val_acc: 0.5000\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6291 - acc: 0.6543 - val_loss: 0.7755 - val_acc: 0.5000\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6323 - acc: 0.6667 - val_loss: 0.7708 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.6296 - val_loss: 0.7811 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6302 - acc: 0.6420 - val_loss: 0.7880 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6337 - acc: 0.6667 - val_loss: 0.7883 - val_acc: 0.5000\n",
      "<keras.callbacks.History object at 0x1a55bcfb00>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 626us/step\n",
      "loss: 0.765826940536499\n",
      "acc: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a55bcf3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41982383]\n",
      " [0.34690595]\n",
      " [0.32753676]\n",
      " [0.35161152]\n",
      " [0.49985594]\n",
      " [0.48365524]\n",
      " [0.55283034]\n",
      " [0.5339333 ]\n",
      " [0.4287281 ]\n",
      " [0.6361661 ]\n",
      " [0.52598524]\n",
      " [0.37305078]\n",
      " [0.4148199 ]\n",
      " [0.57844484]\n",
      " [0.5228593 ]\n",
      " [0.43795407]\n",
      " [0.4208304 ]\n",
      " [0.43743926]\n",
      " [0.5571462 ]\n",
      " [0.50994426]\n",
      " [0.36056125]\n",
      " [0.46968603]\n",
      " [0.54700446]\n",
      " [0.517686  ]\n",
      " [0.3991667 ]\n",
      " [0.8848782 ]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.10      0.17        10\n",
      "        1.0       0.62      0.94      0.75        16\n",
      "\n",
      "avg / total       0.58      0.62      0.53        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.30      0.37        10\n",
      "        1.0       0.65      0.81      0.72        16\n",
      "\n",
      "avg / total       0.59      0.62      0.59        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.33      0.40      0.36        10\n",
      "        1.0       0.57      0.50      0.53        16\n",
      "\n",
      "avg / total       0.48      0.46      0.47        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.60      0.48        10\n",
      "        1.0       0.64      0.44      0.52        16\n",
      "\n",
      "avg / total       0.55      0.50      0.50        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      0.80      0.52        10\n",
      "        1.0       0.60      0.19      0.29        16\n",
      "\n",
      "avg / total       0.52      0.42      0.37        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      0.90      0.53        10\n",
      "        1.0       0.50      0.06      0.11        16\n",
      "\n",
      "avg / total       0.45      0.38      0.27        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      0.90      0.51        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.14      0.35      0.20        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      0.90      0.51        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.14      0.35      0.20        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      0.90      0.51        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.14      0.35      0.20        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      0.90      0.51        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.14      0.35      0.20        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      0.90      0.51        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.14      0.35      0.20        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: 1\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: -1\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "0.0: -1\n",
      "0.0: 0\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "[{'month_id': 229, 'QAId': 'EBAY'}, {'month_id': 230, 'QAId': 'EBAY'}, {'month_id': 232, 'QAId': 'EBAY'}, {'month_id': 233, 'QAId': 'EBAY'}, {'month_id': 236, 'QAId': 'EBAY'}, {'month_id': 237, 'QAId': 'EBAY'}, {'month_id': 241, 'QAId': 'EBAY'}, {'month_id': 242, 'QAId': 'EBAY'}, {'month_id': 245, 'QAId': 'EBAY'}, {'month_id': 246, 'QAId': 'EBAY'}, {'month_id': 248, 'QAId': 'EBAY'}]\n",
      "[{'month_id': 223, 'QAId': 'EBAY'}, {'month_id': 224, 'QAId': 'EBAY'}, {'month_id': 225, 'QAId': 'EBAY'}, {'month_id': 226, 'QAId': 'EBAY'}, {'month_id': 231, 'QAId': 'EBAY'}, {'month_id': 234, 'QAId': 'EBAY'}, {'month_id': 235, 'QAId': 'EBAY'}, {'month_id': 238, 'QAId': 'EBAY'}, {'month_id': 239, 'QAId': 'EBAY'}, {'month_id': 240, 'QAId': 'EBAY'}, {'month_id': 243, 'QAId': 'EBAY'}, {'month_id': 247, 'QAId': 'EBAY'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "def second_largest(numbers):\n",
    "    count = 0\n",
    "    m1 = m2 = float('-inf')\n",
    "    for x in numbers:\n",
    "        count += 1\n",
    "        if x > m2:\n",
    "            if x >= m1:\n",
    "                m1, m2 = x, m1            \n",
    "            else:\n",
    "                m2 = x\n",
    "    return m2 if count >= 2 else None\n",
    "\n",
    "midpt = (second_largest(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1.05 else (-1 if r.item() < midpt * 0.95 else 0)\n",
    "  if r.item() > midpt * 1.05:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.95:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>EBAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>EBAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>EBAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226</td>\n",
       "      <td>EBAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231</td>\n",
       "      <td>EBAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       223  EBAY\n",
       "1       224  EBAY\n",
       "2       225  EBAY\n",
       "3       226  EBAY\n",
       "4       231  EBAY"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
