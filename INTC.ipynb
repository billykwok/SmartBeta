{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"INTC\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=256, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 2s 26ms/step - loss: 7.9560 - acc: 0.4444 - val_loss: 3.6114 - val_acc: 0.4167\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 727us/step - loss: 3.6887 - acc: 0.4444 - val_loss: 2.8282 - val_acc: 0.4167\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 735us/step - loss: 2.6029 - acc: 0.4444 - val_loss: 2.5410 - val_acc: 0.4167\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 726us/step - loss: 2.4010 - acc: 0.4444 - val_loss: 2.3688 - val_acc: 0.4167\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 742us/step - loss: 2.2531 - acc: 0.4444 - val_loss: 2.2537 - val_acc: 0.4167\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 747us/step - loss: 2.1511 - acc: 0.4444 - val_loss: 2.1718 - val_acc: 0.4167\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 2.0701 - acc: 0.4444 - val_loss: 2.1061 - val_acc: 0.4167\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 2.0195 - acc: 0.4444 - val_loss: 2.0511 - val_acc: 0.4167\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 1.9882 - acc: 0.4444 - val_loss: 2.0023 - val_acc: 0.4167\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 1.9260 - acc: 0.4444 - val_loss: 1.9590 - val_acc: 0.4167\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 1.8812 - acc: 0.4444 - val_loss: 1.9199 - val_acc: 0.4167\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 1.8488 - acc: 0.4444 - val_loss: 1.8838 - val_acc: 0.4167\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 1.8238 - acc: 0.4444 - val_loss: 1.8503 - val_acc: 0.4167\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 1.7897 - acc: 0.4444 - val_loss: 1.8186 - val_acc: 0.4167\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 789us/step - loss: 1.7654 - acc: 0.4444 - val_loss: 1.7888 - val_acc: 0.4167\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 1.7236 - acc: 0.4444 - val_loss: 1.7605 - val_acc: 0.4167\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 1.7017 - acc: 0.4444 - val_loss: 1.7332 - val_acc: 0.4167\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 1.6785 - acc: 0.4444 - val_loss: 1.7072 - val_acc: 0.4167\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 755us/step - loss: 1.6483 - acc: 0.4444 - val_loss: 1.6821 - val_acc: 0.4167\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 1.6462 - acc: 0.4444 - val_loss: 1.6576 - val_acc: 0.4167\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 1.5944 - acc: 0.4444 - val_loss: 1.6336 - val_acc: 0.4167\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 1.5771 - acc: 0.4444 - val_loss: 1.6099 - val_acc: 0.4167\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 1.5682 - acc: 0.4444 - val_loss: 1.5862 - val_acc: 0.4167\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 762us/step - loss: 1.5429 - acc: 0.4444 - val_loss: 1.5631 - val_acc: 0.4167\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 733us/step - loss: 1.5197 - acc: 0.4444 - val_loss: 1.5401 - val_acc: 0.4167\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 721us/step - loss: 1.4962 - acc: 0.4444 - val_loss: 1.5175 - val_acc: 0.4167\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 762us/step - loss: 1.4640 - acc: 0.4444 - val_loss: 1.4954 - val_acc: 0.4167\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 1.4564 - acc: 0.4444 - val_loss: 1.4732 - val_acc: 0.4167\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 1.4449 - acc: 0.4444 - val_loss: 1.4511 - val_acc: 0.4167\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 779us/step - loss: 1.4132 - acc: 0.4444 - val_loss: 1.4292 - val_acc: 0.4167\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 707us/step - loss: 1.3964 - acc: 0.4444 - val_loss: 1.4079 - val_acc: 0.4167\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 743us/step - loss: 1.3807 - acc: 0.4444 - val_loss: 1.3867 - val_acc: 0.4167\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 1.3477 - acc: 0.4444 - val_loss: 1.3653 - val_acc: 0.4167\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 757us/step - loss: 1.3324 - acc: 0.4444 - val_loss: 1.3444 - val_acc: 0.4167\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 1.3184 - acc: 0.4444 - val_loss: 1.3235 - val_acc: 0.4167\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 1.2900 - acc: 0.4444 - val_loss: 1.3024 - val_acc: 0.4167\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 1.2740 - acc: 0.4444 - val_loss: 1.2813 - val_acc: 0.4167\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 726us/step - loss: 1.2578 - acc: 0.4444 - val_loss: 1.2604 - val_acc: 0.4167\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 746us/step - loss: 1.2411 - acc: 0.4444 - val_loss: 1.2395 - val_acc: 0.4167\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 724us/step - loss: 1.2236 - acc: 0.4444 - val_loss: 1.2188 - val_acc: 0.4167\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 1.1888 - acc: 0.4444 - val_loss: 1.1976 - val_acc: 0.4167\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 1.1855 - acc: 0.4444 - val_loss: 1.1768 - val_acc: 0.4167\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 1.1489 - acc: 0.4444 - val_loss: 1.1560 - val_acc: 0.4167\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 765us/step - loss: 1.1407 - acc: 0.4444 - val_loss: 1.1355 - val_acc: 0.4167\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 750us/step - loss: 1.1084 - acc: 0.4444 - val_loss: 1.1145 - val_acc: 0.4167\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 1.0911 - acc: 0.4444 - val_loss: 1.0937 - val_acc: 0.4167\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 769us/step - loss: 1.0676 - acc: 0.4444 - val_loss: 1.0732 - val_acc: 0.4167\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 1.0641 - acc: 0.4444 - val_loss: 1.0531 - val_acc: 0.4167\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 740us/step - loss: 1.0442 - acc: 0.4444 - val_loss: 1.0328 - val_acc: 0.4167\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 1.0329 - acc: 0.4444 - val_loss: 1.0129 - val_acc: 0.4167\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 1.0155 - acc: 0.4444 - val_loss: 0.9932 - val_acc: 0.4167\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 730us/step - loss: 0.9723 - acc: 0.4444 - val_loss: 0.9736 - val_acc: 0.4167\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.9686 - acc: 0.4444 - val_loss: 0.9545 - val_acc: 0.4167\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.9511 - acc: 0.4444 - val_loss: 0.9357 - val_acc: 0.4167\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.9233 - acc: 0.4444 - val_loss: 0.9174 - val_acc: 0.4167\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.9074 - acc: 0.4444 - val_loss: 0.8992 - val_acc: 0.4167\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 771us/step - loss: 0.9016 - acc: 0.4444 - val_loss: 0.8809 - val_acc: 0.4167\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.8791 - acc: 0.4444 - val_loss: 0.8637 - val_acc: 0.4167\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 0.8696 - acc: 0.4444 - val_loss: 0.8469 - val_acc: 0.4167\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 731us/step - loss: 0.8457 - acc: 0.4444 - val_loss: 0.8305 - val_acc: 0.4167\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 768us/step - loss: 0.8430 - acc: 0.4444 - val_loss: 0.8143 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.8291 - acc: 0.4444 - val_loss: 0.7988 - val_acc: 0.4167\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.8037 - acc: 0.4444 - val_loss: 0.7842 - val_acc: 0.4167\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 769us/step - loss: 0.8075 - acc: 0.4444 - val_loss: 0.7706 - val_acc: 0.4167\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 739us/step - loss: 0.7690 - acc: 0.4444 - val_loss: 0.7584 - val_acc: 0.4167\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 0.7799 - acc: 0.4444 - val_loss: 0.7462 - val_acc: 0.4167\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 0.7731 - acc: 0.4444 - val_loss: 0.7351 - val_acc: 0.4167\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.7479 - acc: 0.4321 - val_loss: 0.7250 - val_acc: 0.4167\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 0.7527 - acc: 0.4568 - val_loss: 0.7160 - val_acc: 0.4167\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 739us/step - loss: 0.7398 - acc: 0.4444 - val_loss: 0.7075 - val_acc: 0.3611\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 0.7148 - acc: 0.4691 - val_loss: 0.7004 - val_acc: 0.4444\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 0.7217 - acc: 0.4691 - val_loss: 0.6942 - val_acc: 0.5556\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 0.7075 - acc: 0.5062 - val_loss: 0.6893 - val_acc: 0.5833\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 0.7221 - acc: 0.4321 - val_loss: 0.6850 - val_acc: 0.5278\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.7058 - acc: 0.5062 - val_loss: 0.6814 - val_acc: 0.6111\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 745us/step - loss: 0.7095 - acc: 0.4568 - val_loss: 0.6790 - val_acc: 0.5556\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 0.7043 - acc: 0.5062 - val_loss: 0.6769 - val_acc: 0.5833\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 771us/step - loss: 0.6911 - acc: 0.5432 - val_loss: 0.6755 - val_acc: 0.6389\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 0.6996 - acc: 0.5432 - val_loss: 0.6746 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 744us/step - loss: 0.6998 - acc: 0.5062 - val_loss: 0.6741 - val_acc: 0.6111\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 721us/step - loss: 0.7082 - acc: 0.4444 - val_loss: 0.6738 - val_acc: 0.5833\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 709us/step - loss: 0.6890 - acc: 0.5309 - val_loss: 0.6736 - val_acc: 0.5833\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 704us/step - loss: 0.7178 - acc: 0.4691 - val_loss: 0.6736 - val_acc: 0.5833\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 691us/step - loss: 0.7053 - acc: 0.4938 - val_loss: 0.6734 - val_acc: 0.5833\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 0.7163 - acc: 0.5185 - val_loss: 0.6733 - val_acc: 0.5833\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.6998 - acc: 0.5432 - val_loss: 0.6732 - val_acc: 0.5833\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.6951 - acc: 0.5185 - val_loss: 0.6730 - val_acc: 0.5833\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.7028 - acc: 0.5185 - val_loss: 0.6728 - val_acc: 0.5833\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 0.7153 - acc: 0.4691 - val_loss: 0.6727 - val_acc: 0.5833\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.7015 - acc: 0.5062 - val_loss: 0.6725 - val_acc: 0.5833\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 0.6856 - acc: 0.5556 - val_loss: 0.6723 - val_acc: 0.5833\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.7090 - acc: 0.4568 - val_loss: 0.6721 - val_acc: 0.5833\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 755us/step - loss: 0.6926 - acc: 0.5185 - val_loss: 0.6719 - val_acc: 0.5833\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 722us/step - loss: 0.6849 - acc: 0.5679 - val_loss: 0.6717 - val_acc: 0.5833\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 721us/step - loss: 0.7047 - acc: 0.4815 - val_loss: 0.6716 - val_acc: 0.5833\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 666us/step - loss: 0.6880 - acc: 0.4815 - val_loss: 0.6714 - val_acc: 0.5833\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 679us/step - loss: 0.6963 - acc: 0.5432 - val_loss: 0.6713 - val_acc: 0.5833\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 799us/step - loss: 0.6869 - acc: 0.5309 - val_loss: 0.6711 - val_acc: 0.5833\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 681us/step - loss: 0.6956 - acc: 0.4938 - val_loss: 0.6710 - val_acc: 0.5833\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 680us/step - loss: 0.7016 - acc: 0.4815 - val_loss: 0.6710 - val_acc: 0.5833\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 676us/step - loss: 0.7038 - acc: 0.4815 - val_loss: 0.6708 - val_acc: 0.5833\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 683us/step - loss: 0.6819 - acc: 0.5802 - val_loss: 0.6706 - val_acc: 0.5833\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 0.6975 - acc: 0.5062 - val_loss: 0.6705 - val_acc: 0.5833\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 773us/step - loss: 0.7057 - acc: 0.3827 - val_loss: 0.6703 - val_acc: 0.5833\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.7107 - acc: 0.4568 - val_loss: 0.6702 - val_acc: 0.5833\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 731us/step - loss: 0.7012 - acc: 0.5679 - val_loss: 0.6700 - val_acc: 0.5833\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 779us/step - loss: 0.6746 - acc: 0.5679 - val_loss: 0.6699 - val_acc: 0.5833\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 795us/step - loss: 0.6914 - acc: 0.5185 - val_loss: 0.6698 - val_acc: 0.5833\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.7013 - acc: 0.5679 - val_loss: 0.6697 - val_acc: 0.5833\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6999 - acc: 0.4938 - val_loss: 0.6695 - val_acc: 0.5833\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 0.6993 - acc: 0.4815 - val_loss: 0.6694 - val_acc: 0.5833\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.6795 - acc: 0.5679 - val_loss: 0.6693 - val_acc: 0.5833\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.7060 - acc: 0.4198 - val_loss: 0.6692 - val_acc: 0.5833\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.6911 - acc: 0.5185 - val_loss: 0.6690 - val_acc: 0.5833\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 751us/step - loss: 0.6963 - acc: 0.4938 - val_loss: 0.6688 - val_acc: 0.5833\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.6953 - acc: 0.5062 - val_loss: 0.6687 - val_acc: 0.5833\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.7013 - acc: 0.5432 - val_loss: 0.6686 - val_acc: 0.5833\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 746us/step - loss: 0.6886 - acc: 0.5062 - val_loss: 0.6686 - val_acc: 0.5833\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6980 - acc: 0.5185 - val_loss: 0.6685 - val_acc: 0.5833\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 756us/step - loss: 0.6981 - acc: 0.5679 - val_loss: 0.6685 - val_acc: 0.5833\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 722us/step - loss: 0.6950 - acc: 0.4938 - val_loss: 0.6684 - val_acc: 0.5833\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 0.6900 - acc: 0.5185 - val_loss: 0.6683 - val_acc: 0.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 742us/step - loss: 0.6968 - acc: 0.5309 - val_loss: 0.6682 - val_acc: 0.5833\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 768us/step - loss: 0.7000 - acc: 0.5185 - val_loss: 0.6680 - val_acc: 0.5833\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 765us/step - loss: 0.7036 - acc: 0.4938 - val_loss: 0.6680 - val_acc: 0.5833\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.6919 - acc: 0.5185 - val_loss: 0.6680 - val_acc: 0.5833\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 0.7018 - acc: 0.5309 - val_loss: 0.6680 - val_acc: 0.5833\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 799us/step - loss: 0.6841 - acc: 0.5432 - val_loss: 0.6677 - val_acc: 0.5833\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.6786 - acc: 0.5679 - val_loss: 0.6676 - val_acc: 0.5833\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 0.6897 - acc: 0.5432 - val_loss: 0.6676 - val_acc: 0.5833\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6943 - acc: 0.4938 - val_loss: 0.6675 - val_acc: 0.5833\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 0.7041 - acc: 0.4691 - val_loss: 0.6674 - val_acc: 0.5833\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 744us/step - loss: 0.6829 - acc: 0.5926 - val_loss: 0.6672 - val_acc: 0.5833\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.6984 - acc: 0.4815 - val_loss: 0.6672 - val_acc: 0.5833\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.6901 - acc: 0.5432 - val_loss: 0.6672 - val_acc: 0.5833\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 0.6976 - acc: 0.5309 - val_loss: 0.6672 - val_acc: 0.5833\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 777us/step - loss: 0.6902 - acc: 0.5802 - val_loss: 0.6669 - val_acc: 0.5833\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 731us/step - loss: 0.6919 - acc: 0.5309 - val_loss: 0.6666 - val_acc: 0.5833\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 0.6624 - acc: 0.6173 - val_loss: 0.6666 - val_acc: 0.5833\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 725us/step - loss: 0.6968 - acc: 0.5679 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 757us/step - loss: 0.6899 - acc: 0.5309 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 736us/step - loss: 0.6977 - acc: 0.5679 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.6957 - acc: 0.5309 - val_loss: 0.6664 - val_acc: 0.5833\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 768us/step - loss: 0.6931 - acc: 0.5309 - val_loss: 0.6661 - val_acc: 0.5833\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 740us/step - loss: 0.6988 - acc: 0.5432 - val_loss: 0.6658 - val_acc: 0.5833\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.6817 - acc: 0.5926 - val_loss: 0.6655 - val_acc: 0.5833\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 0.7075 - acc: 0.4815 - val_loss: 0.6652 - val_acc: 0.5833\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 770us/step - loss: 0.6719 - acc: 0.5802 - val_loss: 0.6650 - val_acc: 0.5833\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 0.7019 - acc: 0.5679 - val_loss: 0.6648 - val_acc: 0.5833\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6680 - acc: 0.5556 - val_loss: 0.6644 - val_acc: 0.5833\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 734us/step - loss: 0.6882 - acc: 0.4815 - val_loss: 0.6642 - val_acc: 0.5833\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.6872 - acc: 0.5556 - val_loss: 0.6642 - val_acc: 0.5833\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 730us/step - loss: 0.6764 - acc: 0.5679 - val_loss: 0.6638 - val_acc: 0.5833\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.6813 - acc: 0.5926 - val_loss: 0.6637 - val_acc: 0.5833\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.6809 - acc: 0.5062 - val_loss: 0.6636 - val_acc: 0.5833\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 768us/step - loss: 0.6905 - acc: 0.5556 - val_loss: 0.6636 - val_acc: 0.5833\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 758us/step - loss: 0.6756 - acc: 0.5679 - val_loss: 0.6636 - val_acc: 0.5833\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 0.6905 - acc: 0.5185 - val_loss: 0.6637 - val_acc: 0.5833\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 0.6965 - acc: 0.5185 - val_loss: 0.6635 - val_acc: 0.5833\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6858 - acc: 0.5309 - val_loss: 0.6631 - val_acc: 0.5833\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6806 - acc: 0.5679 - val_loss: 0.6630 - val_acc: 0.5833\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 0.6727 - acc: 0.5556 - val_loss: 0.6631 - val_acc: 0.5833\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6916 - acc: 0.5309 - val_loss: 0.6630 - val_acc: 0.5833\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6899 - acc: 0.5926 - val_loss: 0.6627 - val_acc: 0.5833\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6978 - acc: 0.5062 - val_loss: 0.6623 - val_acc: 0.5833\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.6884 - acc: 0.5556 - val_loss: 0.6620 - val_acc: 0.5833\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 930us/step - loss: 0.6896 - acc: 0.5802 - val_loss: 0.6618 - val_acc: 0.5833\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 908us/step - loss: 0.6943 - acc: 0.5679 - val_loss: 0.6616 - val_acc: 0.5833\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.7067 - acc: 0.5309 - val_loss: 0.6610 - val_acc: 0.5833\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.6875 - acc: 0.5679 - val_loss: 0.6607 - val_acc: 0.5833\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 783us/step - loss: 0.6954 - acc: 0.5432 - val_loss: 0.6604 - val_acc: 0.5833\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 830us/step - loss: 0.6814 - acc: 0.5309 - val_loss: 0.6602 - val_acc: 0.5833\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.6618 - acc: 0.5432 - val_loss: 0.6601 - val_acc: 0.5833\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.6890 - acc: 0.5062 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6855 - acc: 0.5432 - val_loss: 0.6601 - val_acc: 0.5833\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 770us/step - loss: 0.6872 - acc: 0.5432 - val_loss: 0.6602 - val_acc: 0.5833\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 758us/step - loss: 0.6858 - acc: 0.5432 - val_loss: 0.6601 - val_acc: 0.5833\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 0.6713 - acc: 0.5802 - val_loss: 0.6603 - val_acc: 0.5833\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 898us/step - loss: 0.7001 - acc: 0.5309 - val_loss: 0.6599 - val_acc: 0.5833\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 891us/step - loss: 0.6792 - acc: 0.5556 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 899us/step - loss: 0.6821 - acc: 0.5802 - val_loss: 0.6599 - val_acc: 0.5833\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 879us/step - loss: 0.6946 - acc: 0.5432 - val_loss: 0.6597 - val_acc: 0.5833\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6858 - acc: 0.5679 - val_loss: 0.6595 - val_acc: 0.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 916us/step - loss: 0.6795 - acc: 0.5556 - val_loss: 0.6596 - val_acc: 0.5833\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 863us/step - loss: 0.6796 - acc: 0.5432 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6973 - acc: 0.4568 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.6771 - acc: 0.5556 - val_loss: 0.6595 - val_acc: 0.5833\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.6712 - acc: 0.5679 - val_loss: 0.6597 - val_acc: 0.5833\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.6820 - acc: 0.5556 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 876us/step - loss: 0.6860 - acc: 0.5309 - val_loss: 0.6599 - val_acc: 0.5833\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 881us/step - loss: 0.6977 - acc: 0.4815 - val_loss: 0.6602 - val_acc: 0.5833\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6943 - acc: 0.5679 - val_loss: 0.6601 - val_acc: 0.5833\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 929us/step - loss: 0.6706 - acc: 0.6296 - val_loss: 0.6598 - val_acc: 0.5833\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.6656 - acc: 0.5802 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6807 - acc: 0.5309 - val_loss: 0.6607 - val_acc: 0.5833\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 0.6863 - acc: 0.5432 - val_loss: 0.6607 - val_acc: 0.5833\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.6720 - acc: 0.5679 - val_loss: 0.6607 - val_acc: 0.5833\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6722 - acc: 0.5679 - val_loss: 0.6605 - val_acc: 0.5833\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 867us/step - loss: 0.6897 - acc: 0.5309 - val_loss: 0.6598 - val_acc: 0.5833\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6732 - acc: 0.5802 - val_loss: 0.6597 - val_acc: 0.5833\n",
      "<keras.callbacks.History object at 0x1169727f0>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 182us/step\n",
      "loss: 0.6840814352035522\n",
      "acc: 0.6153846383094788\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116972048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51044583]\n",
      " [0.48725224]\n",
      " [0.45726198]\n",
      " [0.44539204]\n",
      " [0.48299208]\n",
      " [0.5422576 ]\n",
      " [0.5420239 ]\n",
      " [0.53090924]\n",
      " [0.5306036 ]\n",
      " [0.54211646]\n",
      " [0.56266516]\n",
      " [0.5420735 ]\n",
      " [0.48192263]\n",
      " [0.4790198 ]\n",
      " [0.4625235 ]\n",
      " [0.52341586]\n",
      " [0.53152454]\n",
      " [0.52451056]\n",
      " [0.57180303]\n",
      " [0.6248308 ]\n",
      " [0.61516225]\n",
      " [0.5838981 ]\n",
      " [0.57473737]\n",
      " [0.47778383]\n",
      " [0.47592115]\n",
      " [0.52530044]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.56      0.93      0.70        15\n",
      "\n",
      "avg / total       0.32      0.54      0.40        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.45      0.50        11\n",
      "        1.0       0.65      0.73      0.69        15\n",
      "\n",
      "avg / total       0.61      0.62      0.61        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.45      0.82      0.58        11\n",
      "        1.0       0.67      0.27      0.38        15\n",
      "\n",
      "avg / total       0.57      0.50      0.47        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      0.91      0.57        11\n",
      "        1.0       0.50      0.07      0.12        15\n",
      "\n",
      "avg / total       0.46      0.42      0.31        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 0\n",
      "0.0: -1\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 0\n",
      "0.0: -1\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "0.0: 0\n",
      "[{'month_id': 233, 'QAId': 'INTC'}, {'month_id': 241, 'QAId': 'INTC'}, {'month_id': 242, 'QAId': 'INTC'}, {'month_id': 243, 'QAId': 'INTC'}, {'month_id': 244, 'QAId': 'INTC'}, {'month_id': 245, 'QAId': 'INTC'}]\n",
      "[{'month_id': 224, 'QAId': 'INTC'}, {'month_id': 225, 'QAId': 'INTC'}, {'month_id': 226, 'QAId': 'INTC'}, {'month_id': 227, 'QAId': 'INTC'}, {'month_id': 235, 'QAId': 'INTC'}, {'month_id': 236, 'QAId': 'INTC'}, {'month_id': 237, 'QAId': 'INTC'}, {'month_id': 246, 'QAId': 'INTC'}, {'month_id': 247, 'QAId': 'INTC'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "midpt = (max(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1.05 else (-1 if r.item() < midpt * 0.95 else 0)\n",
    "  if r.item() > midpt * 1.05:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.95:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       224  INTC\n",
       "1       225  INTC\n",
       "2       226  INTC\n",
       "3       227  INTC\n",
       "4       235  INTC"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
