{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12 # or 54\n",
    "lookback = 3\n",
    "chosen_stocks = [\"JNJ\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=256, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 3.1260 - acc: 0.4815 - val_loss: 3.1105 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 751us/step - loss: 2.3236 - acc: 0.4815 - val_loss: 2.7878 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 757us/step - loss: 2.1192 - acc: 0.4815 - val_loss: 2.5845 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 734us/step - loss: 1.9779 - acc: 0.4815 - val_loss: 2.4397 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 742us/step - loss: 1.8785 - acc: 0.4815 - val_loss: 2.3252 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 1.7787 - acc: 0.4815 - val_loss: 2.2286 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 799us/step - loss: 1.7230 - acc: 0.4815 - val_loss: 2.1451 - val_acc: 0.3333\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 795us/step - loss: 1.6453 - acc: 0.4815 - val_loss: 2.0720 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 1.5915 - acc: 0.4815 - val_loss: 2.0067 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 866us/step - loss: 1.5600 - acc: 0.4815 - val_loss: 1.9462 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 1.5062 - acc: 0.4815 - val_loss: 1.8901 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 1.4617 - acc: 0.4815 - val_loss: 1.8384 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 863us/step - loss: 1.4248 - acc: 0.4815 - val_loss: 1.7900 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 1.3944 - acc: 0.4815 - val_loss: 1.7436 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 1.3510 - acc: 0.4815 - val_loss: 1.6998 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 865us/step - loss: 1.3238 - acc: 0.4815 - val_loss: 1.6569 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 862us/step - loss: 1.2921 - acc: 0.4815 - val_loss: 1.6159 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 870us/step - loss: 1.2567 - acc: 0.4815 - val_loss: 1.5758 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 1.2303 - acc: 0.4815 - val_loss: 1.5364 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 1.2046 - acc: 0.4815 - val_loss: 1.4973 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 882us/step - loss: 1.1667 - acc: 0.4815 - val_loss: 1.4593 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 1.1371 - acc: 0.4815 - val_loss: 1.4210 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 1.1098 - acc: 0.4815 - val_loss: 1.3821 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 1.0773 - acc: 0.4815 - val_loss: 1.3435 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 892us/step - loss: 1.0512 - acc: 0.4815 - val_loss: 1.3065 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 1.0218 - acc: 0.4815 - val_loss: 1.2696 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 865us/step - loss: 1.0106 - acc: 0.4815 - val_loss: 1.2328 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 979us/step - loss: 0.9772 - acc: 0.4815 - val_loss: 1.1975 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 877us/step - loss: 0.9505 - acc: 0.4815 - val_loss: 1.1622 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 869us/step - loss: 0.9330 - acc: 0.4815 - val_loss: 1.1284 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 893us/step - loss: 0.9072 - acc: 0.4815 - val_loss: 1.0949 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 975us/step - loss: 0.8782 - acc: 0.4815 - val_loss: 1.0633 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 881us/step - loss: 0.8600 - acc: 0.4815 - val_loss: 1.0328 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.8392 - acc: 0.4815 - val_loss: 1.0033 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 0.8131 - acc: 0.4815 - val_loss: 0.9755 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.8107 - acc: 0.4815 - val_loss: 0.9475 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.7902 - acc: 0.4815 - val_loss: 0.9222 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 869us/step - loss: 0.7647 - acc: 0.4815 - val_loss: 0.8972 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 845us/step - loss: 0.7583 - acc: 0.4815 - val_loss: 0.8724 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.7476 - acc: 0.4815 - val_loss: 0.8490 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.7318 - acc: 0.4815 - val_loss: 0.8287 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.7171 - acc: 0.4815 - val_loss: 0.8095 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 0.7108 - acc: 0.4815 - val_loss: 0.7910 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 843us/step - loss: 0.7138 - acc: 0.4815 - val_loss: 0.7738 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.7068 - acc: 0.4691 - val_loss: 0.7599 - val_acc: 0.2778\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6982 - acc: 0.5309 - val_loss: 0.7477 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.7043 - acc: 0.4568 - val_loss: 0.7372 - val_acc: 0.3889\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6940 - acc: 0.5062 - val_loss: 0.7287 - val_acc: 0.4444\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 865us/step - loss: 0.6927 - acc: 0.5062 - val_loss: 0.7229 - val_acc: 0.4444\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6944 - acc: 0.4938 - val_loss: 0.7166 - val_acc: 0.4722\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 0.6902 - acc: 0.4938 - val_loss: 0.7129 - val_acc: 0.5278\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 0.6883 - acc: 0.5556 - val_loss: 0.7099 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 840us/step - loss: 0.6939 - acc: 0.5062 - val_loss: 0.7088 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6906 - acc: 0.5679 - val_loss: 0.7064 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.7044 - acc: 0.5432 - val_loss: 0.7058 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6899 - acc: 0.5062 - val_loss: 0.7060 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.6799 - acc: 0.5802 - val_loss: 0.7060 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.7029 - acc: 0.4691 - val_loss: 0.7071 - val_acc: 0.5000\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 0.6907 - acc: 0.5309 - val_loss: 0.7071 - val_acc: 0.5000\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 0.6867 - acc: 0.5556 - val_loss: 0.7079 - val_acc: 0.5000\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 0.6827 - acc: 0.5309 - val_loss: 0.7090 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.6854 - acc: 0.5185 - val_loss: 0.7093 - val_acc: 0.5000\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 0.6835 - acc: 0.5926 - val_loss: 0.7090 - val_acc: 0.5000\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 0.7008 - acc: 0.4815 - val_loss: 0.7089 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.6746 - acc: 0.5556 - val_loss: 0.7088 - val_acc: 0.5000\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 0.6920 - acc: 0.5309 - val_loss: 0.7087 - val_acc: 0.5000\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 828us/step - loss: 0.6838 - acc: 0.5802 - val_loss: 0.7090 - val_acc: 0.5000\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 0.6802 - acc: 0.5556 - val_loss: 0.7091 - val_acc: 0.5000\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.6839 - acc: 0.5926 - val_loss: 0.7086 - val_acc: 0.4722\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.6813 - acc: 0.5802 - val_loss: 0.7069 - val_acc: 0.4722\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6824 - acc: 0.5679 - val_loss: 0.7059 - val_acc: 0.4722\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 0.6884 - acc: 0.5309 - val_loss: 0.7059 - val_acc: 0.4722\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 0.6964 - acc: 0.5309 - val_loss: 0.7054 - val_acc: 0.4722\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6836 - acc: 0.5802 - val_loss: 0.7044 - val_acc: 0.4722\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6873 - acc: 0.4815 - val_loss: 0.7037 - val_acc: 0.5000\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6932 - acc: 0.5556 - val_loss: 0.7031 - val_acc: 0.5000\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.6897 - acc: 0.5556 - val_loss: 0.7036 - val_acc: 0.5000\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 0.6883 - acc: 0.5432 - val_loss: 0.7044 - val_acc: 0.4722\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.6755 - acc: 0.6296 - val_loss: 0.7047 - val_acc: 0.4722\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 879us/step - loss: 0.6768 - acc: 0.5556 - val_loss: 0.7049 - val_acc: 0.4722\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6870 - acc: 0.5926 - val_loss: 0.7055 - val_acc: 0.4722\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 0.6798 - acc: 0.5926 - val_loss: 0.7069 - val_acc: 0.4444\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 851us/step - loss: 0.6779 - acc: 0.6173 - val_loss: 0.7079 - val_acc: 0.4167\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6776 - acc: 0.6173 - val_loss: 0.7087 - val_acc: 0.4167\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.6795 - acc: 0.6173 - val_loss: 0.7082 - val_acc: 0.4167\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6828 - acc: 0.5802 - val_loss: 0.7084 - val_acc: 0.4167\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6771 - acc: 0.5926 - val_loss: 0.7077 - val_acc: 0.4167\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 873us/step - loss: 0.6845 - acc: 0.5802 - val_loss: 0.7067 - val_acc: 0.4167\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 867us/step - loss: 0.6900 - acc: 0.5309 - val_loss: 0.7056 - val_acc: 0.4722\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 903us/step - loss: 0.6890 - acc: 0.5309 - val_loss: 0.7046 - val_acc: 0.4722\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6858 - acc: 0.4938 - val_loss: 0.7050 - val_acc: 0.4444\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 830us/step - loss: 0.6883 - acc: 0.5679 - val_loss: 0.7041 - val_acc: 0.4722\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 880us/step - loss: 0.6727 - acc: 0.6173 - val_loss: 0.7047 - val_acc: 0.4444\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6846 - acc: 0.5926 - val_loss: 0.7048 - val_acc: 0.4444\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6927 - acc: 0.5432 - val_loss: 0.7049 - val_acc: 0.4444\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6888 - acc: 0.5309 - val_loss: 0.7039 - val_acc: 0.4722\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6791 - acc: 0.6296 - val_loss: 0.7036 - val_acc: 0.4722\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6815 - acc: 0.5802 - val_loss: 0.7030 - val_acc: 0.4722\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 0.6699 - acc: 0.5926 - val_loss: 0.7017 - val_acc: 0.5000\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.6768 - acc: 0.6049 - val_loss: 0.7010 - val_acc: 0.5278\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6785 - acc: 0.6173 - val_loss: 0.7003 - val_acc: 0.5278\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 869us/step - loss: 0.6753 - acc: 0.6173 - val_loss: 0.6988 - val_acc: 0.5278\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 0.6852 - acc: 0.5432 - val_loss: 0.6969 - val_acc: 0.5278\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6875 - acc: 0.5556 - val_loss: 0.6965 - val_acc: 0.5278\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6788 - acc: 0.5679 - val_loss: 0.6975 - val_acc: 0.5278\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 0.6754 - acc: 0.6420 - val_loss: 0.6965 - val_acc: 0.5278\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.6758 - acc: 0.6173 - val_loss: 0.6957 - val_acc: 0.5278\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6822 - acc: 0.5926 - val_loss: 0.6954 - val_acc: 0.5278\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 0.6713 - acc: 0.6543 - val_loss: 0.6959 - val_acc: 0.5278\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6798 - acc: 0.6173 - val_loss: 0.6959 - val_acc: 0.5278\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 0.6781 - acc: 0.5802 - val_loss: 0.6968 - val_acc: 0.5278\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6802 - acc: 0.5556 - val_loss: 0.6974 - val_acc: 0.5278\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6786 - acc: 0.5926 - val_loss: 0.6976 - val_acc: 0.5278\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 847us/step - loss: 0.6616 - acc: 0.5926 - val_loss: 0.6985 - val_acc: 0.5278\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 0.6644 - acc: 0.6543 - val_loss: 0.6980 - val_acc: 0.5278\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 868us/step - loss: 0.6723 - acc: 0.5926 - val_loss: 0.6986 - val_acc: 0.5000\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 0.6733 - acc: 0.4938 - val_loss: 0.6975 - val_acc: 0.5000\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 854us/step - loss: 0.6805 - acc: 0.5926 - val_loss: 0.6978 - val_acc: 0.4722\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 830us/step - loss: 0.6710 - acc: 0.6049 - val_loss: 0.6979 - val_acc: 0.4722\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.6793 - acc: 0.5679 - val_loss: 0.6979 - val_acc: 0.4722\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 0.6868 - acc: 0.5679 - val_loss: 0.6986 - val_acc: 0.4444\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.6746 - acc: 0.5926 - val_loss: 0.6985 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.6712 - acc: 0.6049 - val_loss: 0.6988 - val_acc: 0.4722\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6740 - acc: 0.5802 - val_loss: 0.6984 - val_acc: 0.4722\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6761 - acc: 0.5802 - val_loss: 0.6979 - val_acc: 0.4722\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6779 - acc: 0.5679 - val_loss: 0.6975 - val_acc: 0.4722\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6767 - acc: 0.5679 - val_loss: 0.6973 - val_acc: 0.4722\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 779us/step - loss: 0.6715 - acc: 0.6049 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 0.6792 - acc: 0.5432 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6823 - acc: 0.5679 - val_loss: 0.6958 - val_acc: 0.5000\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.6688 - acc: 0.6173 - val_loss: 0.6954 - val_acc: 0.5278\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.6823 - acc: 0.5432 - val_loss: 0.6947 - val_acc: 0.5278\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6759 - acc: 0.6296 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6780 - acc: 0.5679 - val_loss: 0.6941 - val_acc: 0.5278\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.6836 - acc: 0.5432 - val_loss: 0.6952 - val_acc: 0.5278\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6735 - acc: 0.5679 - val_loss: 0.6945 - val_acc: 0.5278\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 0.6853 - acc: 0.5926 - val_loss: 0.6945 - val_acc: 0.5278\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 0.6706 - acc: 0.6296 - val_loss: 0.6951 - val_acc: 0.5000\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6720 - acc: 0.5556 - val_loss: 0.6961 - val_acc: 0.5000\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 845us/step - loss: 0.6632 - acc: 0.6173 - val_loss: 0.6962 - val_acc: 0.5000\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.6856 - acc: 0.5679 - val_loss: 0.6962 - val_acc: 0.5000\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6803 - acc: 0.5679 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6718 - acc: 0.5432 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6661 - acc: 0.5926 - val_loss: 0.6954 - val_acc: 0.5000\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 0.6694 - acc: 0.6173 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 859us/step - loss: 0.6795 - acc: 0.6173 - val_loss: 0.6963 - val_acc: 0.5000\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6686 - acc: 0.5926 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6740 - acc: 0.6049 - val_loss: 0.6943 - val_acc: 0.5278\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 987us/step - loss: 0.6653 - acc: 0.6296 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 0.6626 - acc: 0.6296 - val_loss: 0.6929 - val_acc: 0.5556\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6712 - acc: 0.6173 - val_loss: 0.6937 - val_acc: 0.5556\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 0.6630 - acc: 0.6420 - val_loss: 0.6934 - val_acc: 0.5556\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6701 - acc: 0.6049 - val_loss: 0.6923 - val_acc: 0.5556\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.6615 - acc: 0.6173 - val_loss: 0.6934 - val_acc: 0.5556\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.6610 - acc: 0.6173 - val_loss: 0.6929 - val_acc: 0.5556\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 839us/step - loss: 0.6659 - acc: 0.6296 - val_loss: 0.6939 - val_acc: 0.5556\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 0.6560 - acc: 0.6914 - val_loss: 0.6940 - val_acc: 0.5556\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 840us/step - loss: 0.6677 - acc: 0.6049 - val_loss: 0.6932 - val_acc: 0.5556\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.6696 - acc: 0.6173 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6635 - acc: 0.6049 - val_loss: 0.6933 - val_acc: 0.5556\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.6573 - acc: 0.6173 - val_loss: 0.6931 - val_acc: 0.5556\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 856us/step - loss: 0.6546 - acc: 0.6049 - val_loss: 0.6942 - val_acc: 0.5556\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6568 - acc: 0.6049 - val_loss: 0.6938 - val_acc: 0.5556\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6683 - acc: 0.5926 - val_loss: 0.6948 - val_acc: 0.5556\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.6595 - acc: 0.6420 - val_loss: 0.6954 - val_acc: 0.5556\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 0.6733 - acc: 0.5679 - val_loss: 0.6964 - val_acc: 0.5556\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.6629 - acc: 0.5926 - val_loss: 0.6961 - val_acc: 0.5556\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.6712 - acc: 0.5679 - val_loss: 0.6959 - val_acc: 0.5556\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 854us/step - loss: 0.6809 - acc: 0.5926 - val_loss: 0.6957 - val_acc: 0.5556\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 850us/step - loss: 0.6642 - acc: 0.6296 - val_loss: 0.6953 - val_acc: 0.5556\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.6599 - acc: 0.6049 - val_loss: 0.6963 - val_acc: 0.5556\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 858us/step - loss: 0.6621 - acc: 0.5679 - val_loss: 0.6961 - val_acc: 0.5556\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 0.6793 - acc: 0.5926 - val_loss: 0.6963 - val_acc: 0.5556\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6567 - acc: 0.6173 - val_loss: 0.6967 - val_acc: 0.5556\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 869us/step - loss: 0.6711 - acc: 0.6173 - val_loss: 0.6972 - val_acc: 0.5556\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 0.6696 - acc: 0.5802 - val_loss: 0.6982 - val_acc: 0.5556\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 0.6690 - acc: 0.6173 - val_loss: 0.6980 - val_acc: 0.5556\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.6620 - acc: 0.5926 - val_loss: 0.6975 - val_acc: 0.5556\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6548 - acc: 0.6173 - val_loss: 0.6984 - val_acc: 0.5556\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6496 - acc: 0.6420 - val_loss: 0.6992 - val_acc: 0.5556\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 0.6662 - acc: 0.6296 - val_loss: 0.6979 - val_acc: 0.5556\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.6644 - acc: 0.5679 - val_loss: 0.6981 - val_acc: 0.5556\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 847us/step - loss: 0.6561 - acc: 0.6420 - val_loss: 0.6979 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.6537 - acc: 0.5802 - val_loss: 0.6969 - val_acc: 0.5833\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6605 - acc: 0.5802 - val_loss: 0.6975 - val_acc: 0.5833\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.6635 - acc: 0.5926 - val_loss: 0.6962 - val_acc: 0.5833\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.6648 - acc: 0.5926 - val_loss: 0.6952 - val_acc: 0.5833\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6624 - acc: 0.6049 - val_loss: 0.6956 - val_acc: 0.5833\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 855us/step - loss: 0.6557 - acc: 0.5926 - val_loss: 0.6961 - val_acc: 0.5833\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 813us/step - loss: 0.6672 - acc: 0.6049 - val_loss: 0.6961 - val_acc: 0.5833\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.6665 - acc: 0.6296 - val_loss: 0.6966 - val_acc: 0.5833\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 881us/step - loss: 0.6567 - acc: 0.6420 - val_loss: 0.6972 - val_acc: 0.5833\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.6494 - acc: 0.6296 - val_loss: 0.6975 - val_acc: 0.5833\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 866us/step - loss: 0.6593 - acc: 0.6049 - val_loss: 0.6987 - val_acc: 0.5833\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6646 - acc: 0.6543 - val_loss: 0.7006 - val_acc: 0.5833\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 884us/step - loss: 0.6650 - acc: 0.6049 - val_loss: 0.7025 - val_acc: 0.5556\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 907us/step - loss: 0.6656 - acc: 0.5926 - val_loss: 0.7052 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 921us/step - loss: 0.6653 - acc: 0.6173 - val_loss: 0.7058 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 916us/step - loss: 0.6592 - acc: 0.6296 - val_loss: 0.7062 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 916us/step - loss: 0.6823 - acc: 0.5926 - val_loss: 0.7065 - val_acc: 0.5000\n",
      "<keras.callbacks.History object at 0x1a3d7eedd8>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 273us/step\n",
      "loss: 0.6557193994522095\n",
      "acc: 0.692307710647583\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3d84d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6384963 ]\n",
      " [0.4805089 ]\n",
      " [0.5134663 ]\n",
      " [0.5216054 ]\n",
      " [0.52074355]\n",
      " [0.52322465]\n",
      " [0.5358086 ]\n",
      " [0.4823856 ]\n",
      " [0.5247076 ]\n",
      " [0.498589  ]\n",
      " [0.54575056]\n",
      " [0.597594  ]\n",
      " [0.5382341 ]\n",
      " [0.5038768 ]\n",
      " [0.50974816]\n",
      " [0.5872948 ]\n",
      " [0.56362   ]\n",
      " [0.5673108 ]\n",
      " [0.5469985 ]\n",
      " [0.4966356 ]\n",
      " [0.52707326]\n",
      " [0.46104988]\n",
      " [0.4106616 ]\n",
      " [0.42761815]\n",
      " [0.45892134]\n",
      " [0.55986446]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        10\n",
      "        1.0       0.62      1.00      0.76        16\n",
      "\n",
      "avg / total       0.38      0.62      0.47        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.10      0.17        10\n",
      "        1.0       0.62      0.94      0.75        16\n",
      "\n",
      "avg / total       0.58      0.62      0.53        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.50      0.56        10\n",
      "        1.0       0.72      0.81      0.76        16\n",
      "\n",
      "avg / total       0.68      0.69      0.68        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        10\n",
      "        1.0       1.00      0.38      0.55        16\n",
      "\n",
      "avg / total       0.81      0.62      0.59        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      1.00      0.57        10\n",
      "        1.0       1.00      0.06      0.12        16\n",
      "\n",
      "avg / total       0.77      0.42      0.29        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      1.00      0.56        10\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.15      0.38      0.21        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNJ\n",
      "Target\tPredict\tConsequence\n",
      "1.0\t1\tGain\n",
      "0.0\t-1\tGain\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "0.0\t-1\tGain\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "1.0\t1\tGain\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t0\tNothing\n",
      "1.0\t1\tGain\n",
      "1.0\t1\tGain\n",
      "1.0\t1\tGain\n",
      "0.0\t1\tLoss\n",
      "0.0\t0\tNothing\n",
      "0.0\t0\tNothing\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "0.0\t-1\tGain\n",
      "1.0\t-1\tLoss\n",
      "1.0\t1\tGain\n",
      "\n",
      "\n",
      "[{'month_id': 223, 'QAId': 'JNJ'}, {'month_id': 233, 'QAId': 'JNJ'}, {'month_id': 234, 'QAId': 'JNJ'}, {'month_id': 238, 'QAId': 'JNJ'}, {'month_id': 239, 'QAId': 'JNJ'}, {'month_id': 240, 'QAId': 'JNJ'}, {'month_id': 241, 'QAId': 'JNJ'}, {'month_id': 248, 'QAId': 'JNJ'}]\n",
      "[{'month_id': 224, 'QAId': 'JNJ'}, {'month_id': 230, 'QAId': 'JNJ'}, {'month_id': 244, 'QAId': 'JNJ'}, {'month_id': 245, 'QAId': 'JNJ'}, {'month_id': 246, 'QAId': 'JNJ'}, {'month_id': 247, 'QAId': 'JNJ'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "for j, stock in enumerate(chosen_stocks):\n",
    "  print(stock)\n",
    "  sorted_result = sorted(map(lambda x: x[j], result))\n",
    "  midpt = (sorted_result[-2] + sorted_result[1]) / 2\n",
    "  upper_threshold = midpt * 1.05\n",
    "  lower_threshold = midpt * 0.95\n",
    "  \n",
    "  print(\"Target\\tPredict\\tConsequence\")\n",
    "  for i, r in enumerate(result):\n",
    "    prediction = r[j].item()\n",
    "    target = y_test[i][j].item()\n",
    "    buy_or_sell = 1 if prediction > upper_threshold else (-1 if prediction < lower_threshold else 0)\n",
    "    if prediction > upper_threshold:\n",
    "      buy_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    if prediction < lower_threshold:\n",
    "      sell_list.append({'month_id': i + 223, 'QAId': stock})\n",
    "    \n",
    "    to_print = str(target) + \"\\t\" + str(buy_or_sell)\n",
    "    if (buy_or_sell == -1 and target == 0) or (buy_or_sell == 1 and target == 1):\n",
    "      print(to_print + \"\\tGain\")\n",
    "    elif (buy_or_sell == -1 and target == 1) or (buy_or_sell == 1 and target == 0):\n",
    "      print(to_print + \"\\tLoss\")\n",
    "    else:\n",
    "      print(to_print + \"\\tNothing\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id QAId\n",
       "0       223  JNJ\n",
       "1       233  JNJ\n",
       "2       234  JNJ\n",
       "3       238  JNJ\n",
       "4       239  JNJ"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>245</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246</td>\n",
       "      <td>JNJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id QAId\n",
       "0       224  JNJ\n",
       "1       230  JNJ\n",
       "2       244  JNJ\n",
       "3       245  JNJ\n",
       "4       246  JNJ"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
