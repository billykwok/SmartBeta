{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-215d41aa-d8ba-44d8-b10a-820d6a9ab70d\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-215d41aa-d8ba-44d8-b10a-820d6a9ab70d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving return_2004_40.csv to return_2004_40.csv\n",
      "User uploaded file \"return_2004_40.csv\" with length 1494219 bytes\n"
     ]
    }
   ],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"AMZN\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=256, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 4.0180 - acc: 0.4321 - val_loss: 2.9492 - val_acc: 0.3889\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 777us/step - loss: 2.6920 - acc: 0.4321 - val_loss: 2.7051 - val_acc: 0.3889\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 2.4705 - acc: 0.4321 - val_loss: 2.5303 - val_acc: 0.3889\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 856us/step - loss: 2.3166 - acc: 0.4321 - val_loss: 2.3859 - val_acc: 0.3889\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 866us/step - loss: 2.1959 - acc: 0.4321 - val_loss: 2.2664 - val_acc: 0.3889\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 2.0785 - acc: 0.4321 - val_loss: 2.1674 - val_acc: 0.3889\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 1.9926 - acc: 0.4321 - val_loss: 2.0803 - val_acc: 0.3889\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 813us/step - loss: 1.9056 - acc: 0.4321 - val_loss: 2.0035 - val_acc: 0.3889\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 1.8386 - acc: 0.4321 - val_loss: 1.9352 - val_acc: 0.3889\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 1.7889 - acc: 0.4321 - val_loss: 1.8742 - val_acc: 0.3889\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 799us/step - loss: 1.7240 - acc: 0.4321 - val_loss: 1.8182 - val_acc: 0.3889\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 1.6827 - acc: 0.4321 - val_loss: 1.7659 - val_acc: 0.3889\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 847us/step - loss: 1.6422 - acc: 0.4321 - val_loss: 1.7181 - val_acc: 0.3889\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 840us/step - loss: 1.6016 - acc: 0.4321 - val_loss: 1.6726 - val_acc: 0.3889\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 1.5591 - acc: 0.4321 - val_loss: 1.6295 - val_acc: 0.3889\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 1.5105 - acc: 0.4321 - val_loss: 1.5882 - val_acc: 0.3889\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 887us/step - loss: 1.4757 - acc: 0.4321 - val_loss: 1.5485 - val_acc: 0.3889\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 1.4372 - acc: 0.4321 - val_loss: 1.5101 - val_acc: 0.3889\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 1.4065 - acc: 0.4321 - val_loss: 1.4728 - val_acc: 0.3889\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 840us/step - loss: 1.3741 - acc: 0.4321 - val_loss: 1.4364 - val_acc: 0.3889\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 1.3393 - acc: 0.4321 - val_loss: 1.4013 - val_acc: 0.3889\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 1.3082 - acc: 0.4321 - val_loss: 1.3671 - val_acc: 0.3889\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 1.2726 - acc: 0.4321 - val_loss: 1.3334 - val_acc: 0.3889\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 1.2365 - acc: 0.4321 - val_loss: 1.3012 - val_acc: 0.3889\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 1.2086 - acc: 0.4321 - val_loss: 1.2689 - val_acc: 0.3889\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 1.1847 - acc: 0.4321 - val_loss: 1.2371 - val_acc: 0.3889\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 843us/step - loss: 1.1438 - acc: 0.4321 - val_loss: 1.2060 - val_acc: 0.3889\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 1.1233 - acc: 0.4321 - val_loss: 1.1753 - val_acc: 0.3889\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 1.0988 - acc: 0.4321 - val_loss: 1.1454 - val_acc: 0.3889\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 1.0576 - acc: 0.4321 - val_loss: 1.1160 - val_acc: 0.3889\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 1.0382 - acc: 0.4321 - val_loss: 1.0870 - val_acc: 0.3889\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 1.0221 - acc: 0.4321 - val_loss: 1.0583 - val_acc: 0.3889\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.9947 - acc: 0.4321 - val_loss: 1.0306 - val_acc: 0.3889\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 0.9604 - acc: 0.4321 - val_loss: 1.0032 - val_acc: 0.3889\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 828us/step - loss: 0.9449 - acc: 0.4321 - val_loss: 0.9773 - val_acc: 0.3889\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 902us/step - loss: 0.9224 - acc: 0.4321 - val_loss: 0.9513 - val_acc: 0.3889\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 857us/step - loss: 0.9062 - acc: 0.4321 - val_loss: 0.9267 - val_acc: 0.3889\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 839us/step - loss: 0.8636 - acc: 0.4321 - val_loss: 0.9034 - val_acc: 0.3889\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 0.8591 - acc: 0.4321 - val_loss: 0.8800 - val_acc: 0.3889\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 0.8331 - acc: 0.4321 - val_loss: 0.8577 - val_acc: 0.3889\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 799us/step - loss: 0.8186 - acc: 0.4321 - val_loss: 0.8360 - val_acc: 0.3889\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 0.7950 - acc: 0.4321 - val_loss: 0.8159 - val_acc: 0.3889\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 853us/step - loss: 0.7830 - acc: 0.4321 - val_loss: 0.7969 - val_acc: 0.3889\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.7538 - acc: 0.4321 - val_loss: 0.7789 - val_acc: 0.3889\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.7595 - acc: 0.4321 - val_loss: 0.7612 - val_acc: 0.3889\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 839us/step - loss: 0.7497 - acc: 0.4198 - val_loss: 0.7461 - val_acc: 0.3889\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.7249 - acc: 0.4444 - val_loss: 0.7323 - val_acc: 0.3889\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.7216 - acc: 0.4321 - val_loss: 0.7198 - val_acc: 0.4167\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.7176 - acc: 0.4321 - val_loss: 0.7085 - val_acc: 0.3889\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.7039 - acc: 0.4691 - val_loss: 0.6982 - val_acc: 0.5278\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 858us/step - loss: 0.7039 - acc: 0.4938 - val_loss: 0.6901 - val_acc: 0.5556\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 882us/step - loss: 0.6979 - acc: 0.5432 - val_loss: 0.6837 - val_acc: 0.5556\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6970 - acc: 0.4444 - val_loss: 0.6778 - val_acc: 0.5556\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 862us/step - loss: 0.6869 - acc: 0.5432 - val_loss: 0.6737 - val_acc: 0.5278\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.6973 - acc: 0.5185 - val_loss: 0.6703 - val_acc: 0.5833\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6826 - acc: 0.6049 - val_loss: 0.6676 - val_acc: 0.5833\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 0.6916 - acc: 0.5185 - val_loss: 0.6655 - val_acc: 0.5833\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 0.7022 - acc: 0.5556 - val_loss: 0.6643 - val_acc: 0.6111\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.7024 - acc: 0.5309 - val_loss: 0.6637 - val_acc: 0.6111\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 853us/step - loss: 0.7044 - acc: 0.5185 - val_loss: 0.6639 - val_acc: 0.6111\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 872us/step - loss: 0.7134 - acc: 0.4815 - val_loss: 0.6644 - val_acc: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 0.6996 - acc: 0.6049 - val_loss: 0.6653 - val_acc: 0.5833\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 0.7111 - acc: 0.5062 - val_loss: 0.6659 - val_acc: 0.5833\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6826 - acc: 0.5556 - val_loss: 0.6665 - val_acc: 0.5833\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.7041 - acc: 0.5679 - val_loss: 0.6665 - val_acc: 0.5833\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.6969 - acc: 0.5309 - val_loss: 0.6671 - val_acc: 0.5833\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.7066 - acc: 0.4938 - val_loss: 0.6677 - val_acc: 0.5833\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.7123 - acc: 0.5309 - val_loss: 0.6684 - val_acc: 0.5833\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 819us/step - loss: 0.6971 - acc: 0.5185 - val_loss: 0.6683 - val_acc: 0.5833\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.7027 - acc: 0.5185 - val_loss: 0.6687 - val_acc: 0.5833\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.6978 - acc: 0.5185 - val_loss: 0.6681 - val_acc: 0.5833\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.6823 - acc: 0.6173 - val_loss: 0.6681 - val_acc: 0.5833\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 0.6891 - acc: 0.5432 - val_loss: 0.6677 - val_acc: 0.5833\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.6891 - acc: 0.5185 - val_loss: 0.6668 - val_acc: 0.5833\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6968 - acc: 0.5679 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.7140 - acc: 0.5185 - val_loss: 0.6657 - val_acc: 0.5833\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.7013 - acc: 0.5309 - val_loss: 0.6655 - val_acc: 0.5833\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 833us/step - loss: 0.7006 - acc: 0.5432 - val_loss: 0.6658 - val_acc: 0.5833\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.6951 - acc: 0.5556 - val_loss: 0.6658 - val_acc: 0.5833\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.6834 - acc: 0.5556 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 0.6983 - acc: 0.5556 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 882us/step - loss: 0.6950 - acc: 0.5556 - val_loss: 0.6667 - val_acc: 0.5833\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 0.6798 - acc: 0.4938 - val_loss: 0.6666 - val_acc: 0.5833\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 0.6910 - acc: 0.5432 - val_loss: 0.6666 - val_acc: 0.5833\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 0.6992 - acc: 0.5309 - val_loss: 0.6662 - val_acc: 0.5833\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6985 - acc: 0.5185 - val_loss: 0.6664 - val_acc: 0.5833\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 841us/step - loss: 0.6949 - acc: 0.5309 - val_loss: 0.6662 - val_acc: 0.5833\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6835 - acc: 0.5926 - val_loss: 0.6659 - val_acc: 0.5833\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 0.6883 - acc: 0.5679 - val_loss: 0.6657 - val_acc: 0.5833\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 987us/step - loss: 0.6841 - acc: 0.5556 - val_loss: 0.6656 - val_acc: 0.5833\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.7065 - acc: 0.5309 - val_loss: 0.6657 - val_acc: 0.5833\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6836 - acc: 0.5556 - val_loss: 0.6659 - val_acc: 0.5833\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 777us/step - loss: 0.6905 - acc: 0.5432 - val_loss: 0.6659 - val_acc: 0.5833\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 0.6983 - acc: 0.5432 - val_loss: 0.6651 - val_acc: 0.5833\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 887us/step - loss: 0.7009 - acc: 0.5432 - val_loss: 0.6652 - val_acc: 0.5833\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6901 - acc: 0.5185 - val_loss: 0.6645 - val_acc: 0.5833\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 0.6856 - acc: 0.5432 - val_loss: 0.6644 - val_acc: 0.5833\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 0.6769 - acc: 0.5802 - val_loss: 0.6640 - val_acc: 0.5833\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 0.7006 - acc: 0.5185 - val_loss: 0.6634 - val_acc: 0.5833\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 758us/step - loss: 0.7038 - acc: 0.5679 - val_loss: 0.6623 - val_acc: 0.5833\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 780us/step - loss: 0.6877 - acc: 0.5432 - val_loss: 0.6624 - val_acc: 0.5833\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 741us/step - loss: 0.6913 - acc: 0.5556 - val_loss: 0.6621 - val_acc: 0.5833\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 0.6828 - acc: 0.5432 - val_loss: 0.6619 - val_acc: 0.5833\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 757us/step - loss: 0.6961 - acc: 0.5556 - val_loss: 0.6617 - val_acc: 0.6389\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 773us/step - loss: 0.6781 - acc: 0.6173 - val_loss: 0.6615 - val_acc: 0.6667\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6967 - acc: 0.5556 - val_loss: 0.6618 - val_acc: 0.6111\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 867us/step - loss: 0.6951 - acc: 0.4815 - val_loss: 0.6611 - val_acc: 0.6667\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.6879 - acc: 0.5802 - val_loss: 0.6614 - val_acc: 0.6667\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 0.7064 - acc: 0.5185 - val_loss: 0.6619 - val_acc: 0.5833\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.6788 - acc: 0.6049 - val_loss: 0.6626 - val_acc: 0.5833\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 0.6880 - acc: 0.5802 - val_loss: 0.6624 - val_acc: 0.5833\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 0.6968 - acc: 0.5185 - val_loss: 0.6628 - val_acc: 0.5833\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6893 - acc: 0.5309 - val_loss: 0.6632 - val_acc: 0.5833\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6958 - acc: 0.5062 - val_loss: 0.6632 - val_acc: 0.5833\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6875 - acc: 0.5309 - val_loss: 0.6631 - val_acc: 0.5833\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 982us/step - loss: 0.6841 - acc: 0.5679 - val_loss: 0.6627 - val_acc: 0.5833\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6896 - acc: 0.5185 - val_loss: 0.6626 - val_acc: 0.5833\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 0.6834 - acc: 0.5679 - val_loss: 0.6621 - val_acc: 0.6111\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 880us/step - loss: 0.6878 - acc: 0.6173 - val_loss: 0.6617 - val_acc: 0.6111\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6875 - acc: 0.6173 - val_loss: 0.6613 - val_acc: 0.6389\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6894 - acc: 0.5062 - val_loss: 0.6609 - val_acc: 0.6389\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 0.6861 - acc: 0.5556 - val_loss: 0.6603 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.7012 - acc: 0.4938 - val_loss: 0.6596 - val_acc: 0.6389\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6951 - acc: 0.5432 - val_loss: 0.6596 - val_acc: 0.6389\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 0.6819 - acc: 0.5556 - val_loss: 0.6597 - val_acc: 0.6389\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 0.6976 - acc: 0.5556 - val_loss: 0.6597 - val_acc: 0.6389\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 0.6938 - acc: 0.5432 - val_loss: 0.6601 - val_acc: 0.6389\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6941 - acc: 0.5556 - val_loss: 0.6606 - val_acc: 0.6111\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 0.6890 - acc: 0.5679 - val_loss: 0.6605 - val_acc: 0.6111\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6793 - acc: 0.5802 - val_loss: 0.6601 - val_acc: 0.6111\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 0.6971 - acc: 0.4815 - val_loss: 0.6599 - val_acc: 0.6389\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6890 - acc: 0.5432 - val_loss: 0.6602 - val_acc: 0.6111\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6846 - acc: 0.5432 - val_loss: 0.6596 - val_acc: 0.6389\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6967 - acc: 0.5432 - val_loss: 0.6599 - val_acc: 0.6389\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 0.6837 - acc: 0.5802 - val_loss: 0.6595 - val_acc: 0.6389\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6850 - acc: 0.6049 - val_loss: 0.6587 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 951us/step - loss: 0.6844 - acc: 0.5679 - val_loss: 0.6582 - val_acc: 0.6667\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 0.7036 - acc: 0.5185 - val_loss: 0.6582 - val_acc: 0.6667\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 0.6972 - acc: 0.4815 - val_loss: 0.6580 - val_acc: 0.6667\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 0.6938 - acc: 0.5185 - val_loss: 0.6576 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 0.6863 - acc: 0.5926 - val_loss: 0.6576 - val_acc: 0.6667\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 0.6967 - acc: 0.5185 - val_loss: 0.6582 - val_acc: 0.6667\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 0.6787 - acc: 0.5802 - val_loss: 0.6593 - val_acc: 0.6389\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 800us/step - loss: 0.6733 - acc: 0.6173 - val_loss: 0.6601 - val_acc: 0.6111\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 859us/step - loss: 0.6882 - acc: 0.5185 - val_loss: 0.6604 - val_acc: 0.6111\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.6857 - acc: 0.5926 - val_loss: 0.6602 - val_acc: 0.6111\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 828us/step - loss: 0.6890 - acc: 0.5556 - val_loss: 0.6606 - val_acc: 0.6111\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 0.6819 - acc: 0.5802 - val_loss: 0.6600 - val_acc: 0.6111\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6834 - acc: 0.5556 - val_loss: 0.6594 - val_acc: 0.6111\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.6753 - acc: 0.5679 - val_loss: 0.6586 - val_acc: 0.6667\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 795us/step - loss: 0.6897 - acc: 0.5309 - val_loss: 0.6576 - val_acc: 0.6667\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.6730 - acc: 0.5432 - val_loss: 0.6569 - val_acc: 0.6667\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.6807 - acc: 0.5802 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 836us/step - loss: 0.6762 - acc: 0.5926 - val_loss: 0.6572 - val_acc: 0.6667\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 843us/step - loss: 0.6863 - acc: 0.5802 - val_loss: 0.6571 - val_acc: 0.6667\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 0.6843 - acc: 0.5802 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6924 - acc: 0.5556 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.6877 - acc: 0.5679 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 863us/step - loss: 0.6901 - acc: 0.5432 - val_loss: 0.6569 - val_acc: 0.6667\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 834us/step - loss: 0.7060 - acc: 0.5185 - val_loss: 0.6563 - val_acc: 0.6667\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 0.6788 - acc: 0.5309 - val_loss: 0.6564 - val_acc: 0.6667\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6836 - acc: 0.5309 - val_loss: 0.6565 - val_acc: 0.6667\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 850us/step - loss: 0.6714 - acc: 0.5679 - val_loss: 0.6565 - val_acc: 0.6667\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 844us/step - loss: 0.6887 - acc: 0.5556 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6827 - acc: 0.5432 - val_loss: 0.6576 - val_acc: 0.6667\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.6878 - acc: 0.5802 - val_loss: 0.6577 - val_acc: 0.6667\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.6923 - acc: 0.5926 - val_loss: 0.6577 - val_acc: 0.6667\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6865 - acc: 0.5309 - val_loss: 0.6579 - val_acc: 0.6667\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 0.6844 - acc: 0.4938 - val_loss: 0.6573 - val_acc: 0.6667\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 0.6932 - acc: 0.5309 - val_loss: 0.6571 - val_acc: 0.6667\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 0.6820 - acc: 0.5802 - val_loss: 0.6564 - val_acc: 0.6667\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 828us/step - loss: 0.6885 - acc: 0.5432 - val_loss: 0.6562 - val_acc: 0.6667\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 0.6810 - acc: 0.5679 - val_loss: 0.6564 - val_acc: 0.6667\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 0.6836 - acc: 0.5062 - val_loss: 0.6565 - val_acc: 0.6667\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 0.6918 - acc: 0.5432 - val_loss: 0.6566 - val_acc: 0.6667\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.6958 - acc: 0.5185 - val_loss: 0.6573 - val_acc: 0.6667\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.6913 - acc: 0.5556 - val_loss: 0.6573 - val_acc: 0.6667\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6890 - acc: 0.5556 - val_loss: 0.6574 - val_acc: 0.6667\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 848us/step - loss: 0.6942 - acc: 0.4938 - val_loss: 0.6582 - val_acc: 0.6389\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 891us/step - loss: 0.6843 - acc: 0.5556 - val_loss: 0.6591 - val_acc: 0.6389\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 869us/step - loss: 0.6796 - acc: 0.6049 - val_loss: 0.6588 - val_acc: 0.6389\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 922us/step - loss: 0.6854 - acc: 0.5185 - val_loss: 0.6587 - val_acc: 0.6389\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 871us/step - loss: 0.6926 - acc: 0.5679 - val_loss: 0.6585 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.6658 - acc: 0.6049 - val_loss: 0.6580 - val_acc: 0.6389\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 855us/step - loss: 0.6793 - acc: 0.5309 - val_loss: 0.6578 - val_acc: 0.6389\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 0.6814 - acc: 0.5679 - val_loss: 0.6580 - val_acc: 0.6389\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 0.6772 - acc: 0.5802 - val_loss: 0.6575 - val_acc: 0.6389\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 0.6790 - acc: 0.5556 - val_loss: 0.6568 - val_acc: 0.6667\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 777us/step - loss: 0.6864 - acc: 0.5432 - val_loss: 0.6561 - val_acc: 0.6667\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.6641 - acc: 0.5679 - val_loss: 0.6556 - val_acc: 0.6667\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 839us/step - loss: 0.6943 - acc: 0.5679 - val_loss: 0.6553 - val_acc: 0.6667\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6862 - acc: 0.5309 - val_loss: 0.6552 - val_acc: 0.6667\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.6853 - acc: 0.5556 - val_loss: 0.6546 - val_acc: 0.6667\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 846us/step - loss: 0.6887 - acc: 0.5062 - val_loss: 0.6548 - val_acc: 0.6667\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.6961 - acc: 0.5432 - val_loss: 0.6546 - val_acc: 0.6667\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.6834 - acc: 0.6049 - val_loss: 0.6548 - val_acc: 0.6667\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6785 - acc: 0.5679 - val_loss: 0.6553 - val_acc: 0.6667\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 0.6892 - acc: 0.5185 - val_loss: 0.6560 - val_acc: 0.6667\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.6975 - acc: 0.5556 - val_loss: 0.6569 - val_acc: 0.6389\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 895us/step - loss: 0.6746 - acc: 0.5556 - val_loss: 0.6574 - val_acc: 0.6389\n",
      "<keras.callbacks.History object at 0x1a6bf4bf98>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 291us/step\n",
      "loss: 0.6913127899169922\n",
      "acc: 0.5769230723381042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a70ab1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50372016]\n",
      " [0.51988614]\n",
      " [0.53276575]\n",
      " [0.5256243 ]\n",
      " [0.45529324]\n",
      " [0.49322414]\n",
      " [0.52749485]\n",
      " [0.4944974 ]\n",
      " [0.5038082 ]\n",
      " [0.5413115 ]\n",
      " [0.5234985 ]\n",
      " [0.51645035]\n",
      " [0.55019027]\n",
      " [0.50593674]\n",
      " [0.5175493 ]\n",
      " [0.5030674 ]\n",
      " [0.54126173]\n",
      " [0.5412949 ]\n",
      " [0.5489893 ]\n",
      " [0.5338336 ]\n",
      " [0.51475805]\n",
      " [0.5657638 ]\n",
      " [0.5660205 ]\n",
      " [0.54085934]\n",
      " [0.4806085 ]\n",
      " [0.6080689 ]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         9\n",
      "        1.0       0.65      1.00      0.79        17\n",
      "\n",
      "avg / total       0.43      0.65      0.52        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.25      0.11      0.15         9\n",
      "        1.0       0.64      0.82      0.72        17\n",
      "\n",
      "avg / total       0.50      0.58      0.52        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      0.67      0.39         9\n",
      "        1.0       0.25      0.06      0.10        17\n",
      "\n",
      "avg / total       0.26      0.27      0.20        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      1.00      0.53         9\n",
      "        1.0       1.00      0.06      0.11        17\n",
      "\n",
      "avg / total       0.78      0.38      0.26        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      1.00      0.51         9\n",
      "        1.0       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.12      0.35      0.18        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      1.00      0.51         9\n",
      "        1.0       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.12      0.35      0.18        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      1.00      0.51         9\n",
      "        1.0       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.12      0.35      0.18        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      1.00      0.51         9\n",
      "        1.0       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.12      0.35      0.18        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      1.00      0.51         9\n",
      "        1.0       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.12      0.35      0.18        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      1.00      0.51         9\n",
      "        1.0       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.12      0.35      0.18        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 0\n",
      "0.0: 0\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "0.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "[{'month_id': 248, 'QAId': 'AMZN'}]\n",
      "[{'month_id': 227, 'QAId': 'AMZN'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "\n",
    "midpt = (max(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1 else (-1 if r.item() < midpt * 0.9 else 0)\n",
    "  if r.item() > midpt * 1.1:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.9:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       227  AMZN"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
