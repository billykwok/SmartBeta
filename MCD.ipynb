{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0085b2545f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Default title text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"MCD\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 7.3737 - acc: 0.3580 - val_loss: 2.9211 - val_acc: 0.4444\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 555us/step - loss: 4.6041 - acc: 0.3580 - val_loss: 2.6546 - val_acc: 0.4444\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 3.4750 - acc: 0.3580 - val_loss: 2.5358 - val_acc: 0.4444\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 571us/step - loss: 3.0726 - acc: 0.3580 - val_loss: 2.4556 - val_acc: 0.4444\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 2.9162 - acc: 0.3580 - val_loss: 2.3953 - val_acc: 0.4444\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 528us/step - loss: 2.8504 - acc: 0.3580 - val_loss: 2.3473 - val_acc: 0.4444\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 532us/step - loss: 2.7476 - acc: 0.3580 - val_loss: 2.3082 - val_acc: 0.4444\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 543us/step - loss: 2.7023 - acc: 0.3580 - val_loss: 2.2747 - val_acc: 0.4444\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 2.6397 - acc: 0.3580 - val_loss: 2.2461 - val_acc: 0.4444\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 570us/step - loss: 2.5945 - acc: 0.3580 - val_loss: 2.2204 - val_acc: 0.4444\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 615us/step - loss: 2.5806 - acc: 0.3580 - val_loss: 2.1963 - val_acc: 0.4444\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 568us/step - loss: 2.5544 - acc: 0.3580 - val_loss: 2.1738 - val_acc: 0.4444\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 547us/step - loss: 2.5220 - acc: 0.3580 - val_loss: 2.1523 - val_acc: 0.4444\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 501us/step - loss: 2.4956 - acc: 0.3580 - val_loss: 2.1311 - val_acc: 0.4444\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 2.4766 - acc: 0.3580 - val_loss: 2.1104 - val_acc: 0.4444\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 2.4385 - acc: 0.3580 - val_loss: 2.0907 - val_acc: 0.4444\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 512us/step - loss: 2.4221 - acc: 0.3580 - val_loss: 2.0713 - val_acc: 0.4444\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 2.4047 - acc: 0.3580 - val_loss: 2.0519 - val_acc: 0.4444\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 2.3629 - acc: 0.3580 - val_loss: 2.0330 - val_acc: 0.4444\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 2.3372 - acc: 0.3580 - val_loss: 2.0135 - val_acc: 0.4444\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 483us/step - loss: 2.3155 - acc: 0.3580 - val_loss: 1.9935 - val_acc: 0.4444\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 481us/step - loss: 2.3010 - acc: 0.3580 - val_loss: 1.9723 - val_acc: 0.4444\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 2.2786 - acc: 0.3580 - val_loss: 1.9512 - val_acc: 0.4444\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 501us/step - loss: 2.2472 - acc: 0.3580 - val_loss: 1.9305 - val_acc: 0.4444\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 459us/step - loss: 2.2250 - acc: 0.3580 - val_loss: 1.9103 - val_acc: 0.4444\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 2.2078 - acc: 0.3580 - val_loss: 1.8906 - val_acc: 0.4444\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 2.1773 - acc: 0.3580 - val_loss: 1.8709 - val_acc: 0.4444\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 484us/step - loss: 2.1711 - acc: 0.3580 - val_loss: 1.8514 - val_acc: 0.4444\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 484us/step - loss: 2.1337 - acc: 0.3580 - val_loss: 1.8320 - val_acc: 0.4444\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 2.1073 - acc: 0.3580 - val_loss: 1.8128 - val_acc: 0.4444\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 2.0928 - acc: 0.3580 - val_loss: 1.7940 - val_acc: 0.4444\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 497us/step - loss: 2.0655 - acc: 0.3580 - val_loss: 1.7756 - val_acc: 0.4444\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 2.0439 - acc: 0.3580 - val_loss: 1.7578 - val_acc: 0.4444\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 2.0267 - acc: 0.3580 - val_loss: 1.7399 - val_acc: 0.4444\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 2.0026 - acc: 0.3580 - val_loss: 1.7222 - val_acc: 0.4444\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 1.9830 - acc: 0.3580 - val_loss: 1.7047 - val_acc: 0.4444\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 505us/step - loss: 1.9668 - acc: 0.3580 - val_loss: 1.6878 - val_acc: 0.4444\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 1.9516 - acc: 0.3580 - val_loss: 1.6713 - val_acc: 0.4444\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 532us/step - loss: 1.9249 - acc: 0.3580 - val_loss: 1.6554 - val_acc: 0.4444\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 551us/step - loss: 1.9051 - acc: 0.3580 - val_loss: 1.6399 - val_acc: 0.4444\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 538us/step - loss: 1.8911 - acc: 0.3580 - val_loss: 1.6249 - val_acc: 0.4444\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 1.8688 - acc: 0.3580 - val_loss: 1.6102 - val_acc: 0.4444\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 1.8508 - acc: 0.3580 - val_loss: 1.5954 - val_acc: 0.4444\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 1.8389 - acc: 0.3580 - val_loss: 1.5811 - val_acc: 0.4444\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 504us/step - loss: 1.8057 - acc: 0.3580 - val_loss: 1.5668 - val_acc: 0.4444\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 449us/step - loss: 1.7994 - acc: 0.3580 - val_loss: 1.5530 - val_acc: 0.4444\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 472us/step - loss: 1.7847 - acc: 0.3580 - val_loss: 1.5393 - val_acc: 0.4444\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 1.7621 - acc: 0.3580 - val_loss: 1.5256 - val_acc: 0.4444\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 1.7550 - acc: 0.3580 - val_loss: 1.5121 - val_acc: 0.4444\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 1.7319 - acc: 0.3580 - val_loss: 1.4988 - val_acc: 0.4444\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 483us/step - loss: 1.7368 - acc: 0.3580 - val_loss: 1.4858 - val_acc: 0.4444\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 451us/step - loss: 1.6954 - acc: 0.3580 - val_loss: 1.4728 - val_acc: 0.4444\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 1.6762 - acc: 0.3580 - val_loss: 1.4602 - val_acc: 0.4444\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 1.6718 - acc: 0.3580 - val_loss: 1.4476 - val_acc: 0.4444\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 1.6528 - acc: 0.3580 - val_loss: 1.4352 - val_acc: 0.4444\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 1.6401 - acc: 0.3580 - val_loss: 1.4228 - val_acc: 0.4444\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 1.6258 - acc: 0.3580 - val_loss: 1.4106 - val_acc: 0.4444\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 488us/step - loss: 1.6110 - acc: 0.3580 - val_loss: 1.3986 - val_acc: 0.4444\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 1.6020 - acc: 0.3580 - val_loss: 1.3867 - val_acc: 0.4444\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 483us/step - loss: 1.5689 - acc: 0.3580 - val_loss: 1.3748 - val_acc: 0.4444\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 1.5791 - acc: 0.3580 - val_loss: 1.3631 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 1.5559 - acc: 0.3580 - val_loss: 1.3515 - val_acc: 0.4444\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 504us/step - loss: 1.5551 - acc: 0.3580 - val_loss: 1.3399 - val_acc: 0.4444\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 1.5344 - acc: 0.3580 - val_loss: 1.3286 - val_acc: 0.4444\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 513us/step - loss: 1.5137 - acc: 0.3580 - val_loss: 1.3172 - val_acc: 0.4444\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 1.4999 - acc: 0.3580 - val_loss: 1.3060 - val_acc: 0.4444\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 1.4899 - acc: 0.3580 - val_loss: 1.2948 - val_acc: 0.4444\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 508us/step - loss: 1.4736 - acc: 0.3580 - val_loss: 1.2839 - val_acc: 0.4444\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 1.4668 - acc: 0.3580 - val_loss: 1.2728 - val_acc: 0.4444\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 500us/step - loss: 1.4430 - acc: 0.3580 - val_loss: 1.2618 - val_acc: 0.4444\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 1.4378 - acc: 0.3580 - val_loss: 1.2512 - val_acc: 0.4444\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 484us/step - loss: 1.4280 - acc: 0.3580 - val_loss: 1.2405 - val_acc: 0.4444\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 476us/step - loss: 1.4092 - acc: 0.3580 - val_loss: 1.2297 - val_acc: 0.4444\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 469us/step - loss: 1.3946 - acc: 0.3580 - val_loss: 1.2193 - val_acc: 0.4444\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 460us/step - loss: 1.3747 - acc: 0.3580 - val_loss: 1.2089 - val_acc: 0.4444\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 1.3718 - acc: 0.3580 - val_loss: 1.1984 - val_acc: 0.4444\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 462us/step - loss: 1.3539 - acc: 0.3580 - val_loss: 1.1880 - val_acc: 0.4444\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 466us/step - loss: 1.3458 - acc: 0.3580 - val_loss: 1.1778 - val_acc: 0.4444\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 457us/step - loss: 1.3261 - acc: 0.3580 - val_loss: 1.1676 - val_acc: 0.4444\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 1.3110 - acc: 0.3580 - val_loss: 1.1574 - val_acc: 0.4444\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 469us/step - loss: 1.3086 - acc: 0.3580 - val_loss: 1.1475 - val_acc: 0.4444\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 446us/step - loss: 1.2971 - acc: 0.3580 - val_loss: 1.1376 - val_acc: 0.4444\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 490us/step - loss: 1.2837 - acc: 0.3580 - val_loss: 1.1278 - val_acc: 0.4444\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 1.2769 - acc: 0.3580 - val_loss: 1.1180 - val_acc: 0.4444\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 1.2576 - acc: 0.3580 - val_loss: 1.1085 - val_acc: 0.4444\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 470us/step - loss: 1.2515 - acc: 0.3580 - val_loss: 1.0990 - val_acc: 0.4444\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 1.2367 - acc: 0.3580 - val_loss: 1.0894 - val_acc: 0.4444\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 446us/step - loss: 1.2284 - acc: 0.3580 - val_loss: 1.0798 - val_acc: 0.4444\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 456us/step - loss: 1.2030 - acc: 0.3580 - val_loss: 1.0704 - val_acc: 0.4444\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 474us/step - loss: 1.2076 - acc: 0.3580 - val_loss: 1.0610 - val_acc: 0.4444\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 457us/step - loss: 1.1910 - acc: 0.3580 - val_loss: 1.0520 - val_acc: 0.4444\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 453us/step - loss: 1.1701 - acc: 0.3580 - val_loss: 1.0429 - val_acc: 0.4444\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 463us/step - loss: 1.1709 - acc: 0.3580 - val_loss: 1.0339 - val_acc: 0.4444\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 460us/step - loss: 1.1627 - acc: 0.3580 - val_loss: 1.0251 - val_acc: 0.4444\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 467us/step - loss: 1.1375 - acc: 0.3580 - val_loss: 1.0162 - val_acc: 0.4444\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 1.1343 - acc: 0.3580 - val_loss: 1.0073 - val_acc: 0.4444\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 491us/step - loss: 1.1096 - acc: 0.3580 - val_loss: 0.9988 - val_acc: 0.4444\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 486us/step - loss: 1.1122 - acc: 0.3580 - val_loss: 0.9901 - val_acc: 0.4444\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 1.1022 - acc: 0.3580 - val_loss: 0.9816 - val_acc: 0.4444\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 484us/step - loss: 1.0996 - acc: 0.3580 - val_loss: 0.9732 - val_acc: 0.4444\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 1.0717 - acc: 0.3580 - val_loss: 0.9651 - val_acc: 0.4444\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 488us/step - loss: 1.0752 - acc: 0.3580 - val_loss: 0.9570 - val_acc: 0.4444\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 1.0625 - acc: 0.3580 - val_loss: 0.9489 - val_acc: 0.4444\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 481us/step - loss: 1.0477 - acc: 0.3580 - val_loss: 0.9407 - val_acc: 0.4444\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 492us/step - loss: 1.0268 - acc: 0.3580 - val_loss: 0.9328 - val_acc: 0.4444\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 1.0217 - acc: 0.3580 - val_loss: 0.9249 - val_acc: 0.4444\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 519us/step - loss: 1.0170 - acc: 0.3580 - val_loss: 0.9168 - val_acc: 0.4444\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 526us/step - loss: 0.9950 - acc: 0.3580 - val_loss: 0.9090 - val_acc: 0.4444\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 541us/step - loss: 0.9915 - acc: 0.3580 - val_loss: 0.9010 - val_acc: 0.4444\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 521us/step - loss: 0.9745 - acc: 0.3580 - val_loss: 0.8929 - val_acc: 0.4444\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 516us/step - loss: 0.9739 - acc: 0.3580 - val_loss: 0.8851 - val_acc: 0.4444\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.9702 - acc: 0.3580 - val_loss: 0.8775 - val_acc: 0.4444\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.9571 - acc: 0.3580 - val_loss: 0.8699 - val_acc: 0.4444\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.9433 - acc: 0.3580 - val_loss: 0.8625 - val_acc: 0.4444\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 461us/step - loss: 0.9283 - acc: 0.3580 - val_loss: 0.8552 - val_acc: 0.4444\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 451us/step - loss: 0.9186 - acc: 0.3580 - val_loss: 0.8479 - val_acc: 0.4444\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 0.9124 - acc: 0.3580 - val_loss: 0.8408 - val_acc: 0.4444\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 457us/step - loss: 0.8988 - acc: 0.3580 - val_loss: 0.8338 - val_acc: 0.4444\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 456us/step - loss: 0.9051 - acc: 0.3580 - val_loss: 0.8271 - val_acc: 0.4444\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 451us/step - loss: 0.8905 - acc: 0.3580 - val_loss: 0.8206 - val_acc: 0.4444\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 450us/step - loss: 0.8779 - acc: 0.3580 - val_loss: 0.8141 - val_acc: 0.4444\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 430us/step - loss: 0.8629 - acc: 0.3580 - val_loss: 0.8077 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 436us/step - loss: 0.8710 - acc: 0.3580 - val_loss: 0.8014 - val_acc: 0.4444\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.8509 - acc: 0.3580 - val_loss: 0.7952 - val_acc: 0.4444\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.8336 - acc: 0.3580 - val_loss: 0.7891 - val_acc: 0.4444\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 444us/step - loss: 0.8437 - acc: 0.3580 - val_loss: 0.7830 - val_acc: 0.4444\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 445us/step - loss: 0.8294 - acc: 0.3580 - val_loss: 0.7771 - val_acc: 0.4444\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 460us/step - loss: 0.8123 - acc: 0.3580 - val_loss: 0.7714 - val_acc: 0.4444\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 503us/step - loss: 0.8050 - acc: 0.3580 - val_loss: 0.7658 - val_acc: 0.4444\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 467us/step - loss: 0.8058 - acc: 0.3580 - val_loss: 0.7606 - val_acc: 0.4444\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 0.8021 - acc: 0.3580 - val_loss: 0.7554 - val_acc: 0.4444\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 457us/step - loss: 0.7840 - acc: 0.3704 - val_loss: 0.7504 - val_acc: 0.4444\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 462us/step - loss: 0.7820 - acc: 0.3580 - val_loss: 0.7456 - val_acc: 0.4444\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 566us/step - loss: 0.7703 - acc: 0.3580 - val_loss: 0.7410 - val_acc: 0.4444\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.7886 - acc: 0.3580 - val_loss: 0.7368 - val_acc: 0.4444\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.7579 - acc: 0.3704 - val_loss: 0.7326 - val_acc: 0.4444\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.7374 - acc: 0.4074 - val_loss: 0.7288 - val_acc: 0.4444\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 474us/step - loss: 0.7512 - acc: 0.3827 - val_loss: 0.7251 - val_acc: 0.4444\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 467us/step - loss: 0.7371 - acc: 0.3704 - val_loss: 0.7215 - val_acc: 0.4444\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.7536 - acc: 0.3086 - val_loss: 0.7181 - val_acc: 0.4444\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 463us/step - loss: 0.7360 - acc: 0.4074 - val_loss: 0.7150 - val_acc: 0.4444\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 464us/step - loss: 0.7254 - acc: 0.3951 - val_loss: 0.7120 - val_acc: 0.4167\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 0.7105 - acc: 0.4074 - val_loss: 0.7093 - val_acc: 0.4167\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 456us/step - loss: 0.7154 - acc: 0.5185 - val_loss: 0.7067 - val_acc: 0.4444\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 488us/step - loss: 0.7039 - acc: 0.4568 - val_loss: 0.7044 - val_acc: 0.4722\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 0.7295 - acc: 0.4074 - val_loss: 0.7023 - val_acc: 0.5000\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 480us/step - loss: 0.7292 - acc: 0.4074 - val_loss: 0.7004 - val_acc: 0.5000\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 0.7097 - acc: 0.4444 - val_loss: 0.6989 - val_acc: 0.5000\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 522us/step - loss: 0.6894 - acc: 0.5432 - val_loss: 0.6974 - val_acc: 0.3889\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6864 - acc: 0.5556 - val_loss: 0.6961 - val_acc: 0.4722\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 465us/step - loss: 0.6983 - acc: 0.5062 - val_loss: 0.6951 - val_acc: 0.5000\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 445us/step - loss: 0.6944 - acc: 0.5556 - val_loss: 0.6941 - val_acc: 0.4722\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 456us/step - loss: 0.6847 - acc: 0.5432 - val_loss: 0.6934 - val_acc: 0.4722\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 474us/step - loss: 0.6774 - acc: 0.5309 - val_loss: 0.6928 - val_acc: 0.5556\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 454us/step - loss: 0.6753 - acc: 0.5679 - val_loss: 0.6923 - val_acc: 0.5556\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 471us/step - loss: 0.6713 - acc: 0.5556 - val_loss: 0.6919 - val_acc: 0.5278\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 470us/step - loss: 0.6569 - acc: 0.6420 - val_loss: 0.6916 - val_acc: 0.5556\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 469us/step - loss: 0.6763 - acc: 0.6049 - val_loss: 0.6914 - val_acc: 0.5556\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 452us/step - loss: 0.6726 - acc: 0.6296 - val_loss: 0.6913 - val_acc: 0.5556\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 469us/step - loss: 0.6883 - acc: 0.5679 - val_loss: 0.6913 - val_acc: 0.5556\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 0.6522 - acc: 0.6173 - val_loss: 0.6913 - val_acc: 0.5833\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 474us/step - loss: 0.6756 - acc: 0.6420 - val_loss: 0.6914 - val_acc: 0.5833\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 478us/step - loss: 0.6483 - acc: 0.6667 - val_loss: 0.6916 - val_acc: 0.5833\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 446us/step - loss: 0.6751 - acc: 0.6173 - val_loss: 0.6918 - val_acc: 0.6111\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 518us/step - loss: 0.6765 - acc: 0.6296 - val_loss: 0.6920 - val_acc: 0.6111\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 517us/step - loss: 0.6663 - acc: 0.6173 - val_loss: 0.6922 - val_acc: 0.5833\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 507us/step - loss: 0.6621 - acc: 0.6543 - val_loss: 0.6924 - val_acc: 0.5833\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.6837 - acc: 0.6173 - val_loss: 0.6926 - val_acc: 0.5556\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 476us/step - loss: 0.6731 - acc: 0.6173 - val_loss: 0.6928 - val_acc: 0.5556\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 485us/step - loss: 0.6695 - acc: 0.6296 - val_loss: 0.6930 - val_acc: 0.5556\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 493us/step - loss: 0.6681 - acc: 0.6296 - val_loss: 0.6931 - val_acc: 0.5556\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 0.6705 - acc: 0.5926 - val_loss: 0.6933 - val_acc: 0.5556\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6750 - acc: 0.6173 - val_loss: 0.6934 - val_acc: 0.5556\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6518 - acc: 0.6296 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 486us/step - loss: 0.6643 - acc: 0.6296 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 0.6738 - acc: 0.6543 - val_loss: 0.6937 - val_acc: 0.5556\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 468us/step - loss: 0.6611 - acc: 0.6543 - val_loss: 0.6938 - val_acc: 0.5556\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 475us/step - loss: 0.6620 - acc: 0.6173 - val_loss: 0.6938 - val_acc: 0.5556\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 520us/step - loss: 0.6763 - acc: 0.6049 - val_loss: 0.6938 - val_acc: 0.5556\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 453us/step - loss: 0.6731 - acc: 0.6173 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 488us/step - loss: 0.6854 - acc: 0.5926 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 0.6570 - acc: 0.6420 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 515us/step - loss: 0.6657 - acc: 0.6049 - val_loss: 0.6935 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 470us/step - loss: 0.6644 - acc: 0.5926 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 511us/step - loss: 0.6521 - acc: 0.6296 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 489us/step - loss: 0.6783 - acc: 0.5802 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 482us/step - loss: 0.6693 - acc: 0.5926 - val_loss: 0.6934 - val_acc: 0.5556\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 0.6423 - acc: 0.6420 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 509us/step - loss: 0.6825 - acc: 0.6173 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 514us/step - loss: 0.6745 - acc: 0.6049 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 520us/step - loss: 0.6779 - acc: 0.6296 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 473us/step - loss: 0.6485 - acc: 0.6296 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 496us/step - loss: 0.6671 - acc: 0.6296 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 494us/step - loss: 0.6608 - acc: 0.6420 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 487us/step - loss: 0.6770 - acc: 0.6420 - val_loss: 0.6937 - val_acc: 0.5556\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 495us/step - loss: 0.6755 - acc: 0.6296 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6739 - acc: 0.6296 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 479us/step - loss: 0.6692 - acc: 0.6173 - val_loss: 0.6935 - val_acc: 0.5556\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 477us/step - loss: 0.6524 - acc: 0.6173 - val_loss: 0.6936 - val_acc: 0.5556\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 469us/step - loss: 0.6756 - acc: 0.6049 - val_loss: 0.6937 - val_acc: 0.5556\n",
      "<keras.callbacks.History object at 0x1a24f1f2e8>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 117us/step\n",
      "loss: 0.6536162495613098\n",
      "acc: 0.5769230723381042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a55160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5462056 ]\n",
      " [0.5277704 ]\n",
      " [0.5546787 ]\n",
      " [0.581973  ]\n",
      " [0.5509689 ]\n",
      " [0.5358385 ]\n",
      " [0.56629246]\n",
      " [0.53196126]\n",
      " [0.55738467]\n",
      " [0.5831829 ]\n",
      " [0.61174273]\n",
      " [0.6317868 ]\n",
      " [0.581985  ]\n",
      " [0.6116964 ]\n",
      " [0.62528145]\n",
      " [0.6166206 ]\n",
      " [0.6030037 ]\n",
      " [0.56145865]\n",
      " [0.55774766]\n",
      " [0.53190035]\n",
      " [0.5538004 ]\n",
      " [0.56689626]\n",
      " [0.60271174]\n",
      " [0.5938265 ]\n",
      " [0.64058304]\n",
      " [0.69727415]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        11\n",
      "        1.0       0.58      1.00      0.73        15\n",
      "\n",
      "avg / total       0.33      0.58      0.42        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.18      0.25        11\n",
      "        1.0       0.57      0.80      0.67        15\n",
      "\n",
      "avg / total       0.50      0.54      0.49        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.53      0.82      0.64        11\n",
      "        1.0       0.78      0.47      0.58        15\n",
      "\n",
      "avg / total       0.67      0.62      0.61        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.44      1.00      0.61        11\n",
      "        1.0       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.76      0.46      0.33        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      1.00      0.59        11\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.18      0.42      0.25        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: -1\n",
      "Hey\n",
      "0.0: -1\n",
      "0.0: -1\n",
      "1.0: 0\n",
      "0.0: -1\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: 0\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "0.0: -1\n",
      "0.0: -1\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "[{'month_id': 234, 'QAId': 'MCD'}, {'month_id': 237, 'QAId': 'MCD'}, {'month_id': 238, 'QAId': 'MCD'}, {'month_id': 247, 'QAId': 'MCD'}, {'month_id': 248, 'QAId': 'MCD'}]\n",
      "[{'month_id': 223, 'QAId': 'MCD'}, {'month_id': 224, 'QAId': 'MCD'}, {'month_id': 225, 'QAId': 'MCD'}, {'month_id': 227, 'QAId': 'MCD'}, {'month_id': 228, 'QAId': 'MCD'}, {'month_id': 230, 'QAId': 'MCD'}, {'month_id': 242, 'QAId': 'MCD'}, {'month_id': 243, 'QAId': 'MCD'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "def second_largest(numbers):\n",
    "    count = 0\n",
    "    m1 = m2 = float('-inf')\n",
    "    for x in numbers:\n",
    "        count += 1\n",
    "        if x > m2:\n",
    "            if x >= m1:\n",
    "                m1, m2 = x, m1            \n",
    "            else:\n",
    "                m2 = x\n",
    "    return m2 if count >= 2 else None\n",
    "\n",
    "midpt = (second_largest(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1.05 else (-1 if r.item() < midpt * 0.95 else 0)\n",
    "  if r.item() > midpt * 1.05:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.95:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id QAId\n",
       "0       223  MCD\n",
       "1       224  MCD\n",
       "2       225  MCD\n",
       "3       227  MCD\n",
       "4       228  MCD"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
