{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44724,
     "status": "ok",
     "timestamp": 1525754636414,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "QziQMFUQ4ZtS",
    "outputId": "e1e35eb2-3ce4-44a5-b3a9-c0a8df807e12"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cE1kSExBZtrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_month_id(year, month):\n",
    "  return (year - 1996) * 12 + month - 6\n",
    "\n",
    "n_features = 12\n",
    "lookback = 3\n",
    "chosen_stocks = [\"QCOM\"] # \"AMZN\", \"MSFT\", \"IBM\", \"INTC\", \"QCOM\", \"NVDA\", \"IBM\", \"ADBE\", \"EBAY\", \"CSCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1525763876411,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "6vUqDR0MYQP1",
    "outputId": "ddc259d0-e2b6-4b12-e849-c602f12d1a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFeature = pd.read_csv(\"./lstm_2004_12.csv\")\n",
    "# dfFeature.loc[dfFeature[\"return\"] == 0, \"return\"] = 1\n",
    "dfFeature = dfFeature[dfFeature.QAId.isin(chosen_stocks)]\n",
    "features = dfFeature.drop(columns=['month_id', 'QAId']).as_matrix()\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1525763878070,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "DwavdGT5wkIz",
    "outputId": "37dc165a-26f5-4bf4-c283-d635448bd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizedFeatures = MinMaxScaler().fit_transform(features) \\\n",
    "                                   .reshape(157, len(chosen_stocks), n_features) \\\n",
    "                                   .reshape(157, len(chosen_stocks) * n_features)\n",
    "print(normalizedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1525763881161,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "ECiEkdPQ410b",
    "outputId": "7cada92e-95ac-400d-987d-cd9c6101549c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTarget = pd.read_csv(\"./return_2004_40.csv\")\n",
    "dfTarget[\"return\"] = np.sign(dfTarget[\"return\"])\n",
    "# dfTarget.loc[dfTarget[\"return\"] == 0, \"return\"] = 1\n",
    "dfTarget = dfTarget[dfTarget.QAId.isin(chosen_stocks)]\n",
    "dfTarget = dfTarget[dfTarget.month_id >= (to_month_id(2004, 1) + lookback)]\n",
    "targets = MinMaxScaler().fit_transform(dfTarget.drop(columns=['month_id', 'QAId']).as_matrix())\n",
    "y = targets.reshape(157 - lookback + 1, len(chosen_stocks))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1525763882966,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "Vo9QHxamwmbL",
    "outputId": "9ef70b36-2a3c-44be-a6ed-22930b63500a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 12)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "splittedFeature = normalizedFeatures\n",
    "print(splittedFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pHmaWhfZ4gm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "x = np.zeros((157 - lookback + 1, lookback, n_features * len(chosen_stocks)))\n",
    "y_mock = np.zeros((157, len(chosen_stocks)))\n",
    "\n",
    "i = 0\n",
    "for train, test in TimeseriesGenerator(splittedFeature, y_mock, length=lookback, batch_size=1):\n",
    "  if i > 157 - lookback:\n",
    "    break\n",
    "  x[i] = train[0]\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1525763885182,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "SkuyoR1bZ699",
    "outputId": "d82f1d27-ee9e-4198-f364-67e97179fdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 3, 12)\n",
      "(81, 1)\n",
      "(36, 3, 12)\n",
      "(36, 1)\n",
      "(26, 3, 12)\n",
      "(26, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "test_months = 26\n",
    "end_point = 157 - lookback + 1\n",
    "split_point = 157 - lookback + 1 - test_months\n",
    "\n",
    "x_train = x[0:split_point - 48].reshape(split_point - 48, lookback, n_features * len(chosen_stocks))\n",
    "y_train = y[0:split_point - 48].reshape(split_point - 48, len(chosen_stocks))\n",
    "x_validate = x[split_point - 36:split_point].reshape(36, lookback, n_features * len(chosen_stocks))\n",
    "y_validate = y[split_point - 36:split_point].reshape(36, len(chosen_stocks))\n",
    "x_test = x[split_point:end_point].reshape(test_months, lookback, n_features * len(chosen_stocks))\n",
    "y_test = y[split_point:end_point].reshape(test_months, len(chosen_stocks))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# ps = PredefinedSplit(np.append(np.negative(np.ones(60 * 465)), np.zeros(24 * 465))).split(x_train)\n",
    "\n",
    "# for train_ids, test_ids in ps:\n",
    "#   print(str(train_ids) + \", \" + str(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Co9Gsz7aZ_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Flatten, CuDNNLSTM\n",
    "from keras.regularizers import l1_l2, l2\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "np.random.seed(4103)\n",
    "\n",
    "def create_model(*param):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=512, input_shape=(lookback, n_features * len(chosen_stocks)), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=256, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(len(chosen_stocks), activation=\"relu\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=0.0), metrics=['accuracy'], *param)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13823,
     "status": "error",
     "timestamp": 1525764743477,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "0l18zd8xaQqR",
    "outputId": "47960b89-37a1-460d-aa9c-a58bbdff370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 9.0940 - acc: 0.3827 - val_loss: 4.3047 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 0s 749us/step - loss: 6.0322 - acc: 0.3827 - val_loss: 3.4703 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 0s 797us/step - loss: 3.2799 - acc: 0.3827 - val_loss: 3.2115 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 0s 815us/step - loss: 2.9892 - acc: 0.3827 - val_loss: 3.0829 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 0s 733us/step - loss: 2.8535 - acc: 0.3827 - val_loss: 3.0026 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 0s 703us/step - loss: 2.7582 - acc: 0.3827 - val_loss: 2.9462 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 0s 681us/step - loss: 2.7118 - acc: 0.3827 - val_loss: 2.9030 - val_acc: 0.3333\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 0s 681us/step - loss: 2.6628 - acc: 0.3827 - val_loss: 2.8685 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 0s 680us/step - loss: 2.6427 - acc: 0.3827 - val_loss: 2.8397 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 0s 684us/step - loss: 2.6049 - acc: 0.3827 - val_loss: 2.8146 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 0s 696us/step - loss: 2.5833 - acc: 0.3827 - val_loss: 2.7922 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 0s 731us/step - loss: 2.5596 - acc: 0.3827 - val_loss: 2.7715 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 0s 694us/step - loss: 2.5438 - acc: 0.3827 - val_loss: 2.7514 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 0s 686us/step - loss: 2.5188 - acc: 0.3827 - val_loss: 2.7316 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 0s 680us/step - loss: 2.5233 - acc: 0.3827 - val_loss: 2.7119 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 0s 693us/step - loss: 2.4914 - acc: 0.3827 - val_loss: 2.6927 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 0s 745us/step - loss: 2.4887 - acc: 0.3827 - val_loss: 2.6742 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 0s 711us/step - loss: 2.4929 - acc: 0.3827 - val_loss: 2.6563 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 0s 687us/step - loss: 2.4543 - acc: 0.3827 - val_loss: 2.6390 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 0s 682us/step - loss: 2.4542 - acc: 0.3827 - val_loss: 2.6217 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 0s 690us/step - loss: 2.4132 - acc: 0.3827 - val_loss: 2.6047 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 0s 700us/step - loss: 2.4065 - acc: 0.3827 - val_loss: 2.5869 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 0s 686us/step - loss: 2.3941 - acc: 0.3827 - val_loss: 2.5686 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 0s 691us/step - loss: 2.3910 - acc: 0.3827 - val_loss: 2.5505 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 0s 689us/step - loss: 2.3649 - acc: 0.3827 - val_loss: 2.5324 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 0s 698us/step - loss: 2.3498 - acc: 0.3827 - val_loss: 2.5144 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 0s 681us/step - loss: 2.3371 - acc: 0.3827 - val_loss: 2.4968 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 0s 702us/step - loss: 2.3136 - acc: 0.3827 - val_loss: 2.4793 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 0s 702us/step - loss: 2.3048 - acc: 0.3827 - val_loss: 2.4621 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 0s 723us/step - loss: 2.2749 - acc: 0.3827 - val_loss: 2.4449 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 0s 699us/step - loss: 2.2604 - acc: 0.3827 - val_loss: 2.4278 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 0s 684us/step - loss: 2.2454 - acc: 0.3827 - val_loss: 2.4109 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 0s 782us/step - loss: 2.2335 - acc: 0.3827 - val_loss: 2.3941 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 0s 720us/step - loss: 2.2238 - acc: 0.3827 - val_loss: 2.3776 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 2.1888 - acc: 0.3827 - val_loss: 2.3614 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 0s 724us/step - loss: 2.1780 - acc: 0.3827 - val_loss: 2.3456 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 0s 721us/step - loss: 2.1658 - acc: 0.3827 - val_loss: 2.3300 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 0s 700us/step - loss: 2.1601 - acc: 0.3827 - val_loss: 2.3145 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 0s 716us/step - loss: 2.1408 - acc: 0.3827 - val_loss: 2.2990 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 0s 736us/step - loss: 2.1260 - acc: 0.3827 - val_loss: 2.2837 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 0s 732us/step - loss: 2.1139 - acc: 0.3827 - val_loss: 2.2688 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 0s 714us/step - loss: 2.1018 - acc: 0.3827 - val_loss: 2.2539 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 0s 697us/step - loss: 2.0666 - acc: 0.3827 - val_loss: 2.2392 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 0s 858us/step - loss: 2.0682 - acc: 0.3827 - val_loss: 2.2247 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 0s 986us/step - loss: 2.0468 - acc: 0.3827 - val_loss: 2.2101 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 0s 887us/step - loss: 2.0398 - acc: 0.3827 - val_loss: 2.1956 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 0s 851us/step - loss: 2.0179 - acc: 0.3827 - val_loss: 2.1814 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 2.0101 - acc: 0.3827 - val_loss: 2.1675 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 1.9961 - acc: 0.3827 - val_loss: 2.1536 - val_acc: 0.3333\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 1.9872 - acc: 0.3827 - val_loss: 2.1398 - val_acc: 0.3333\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 0s 775us/step - loss: 1.9741 - acc: 0.3827 - val_loss: 2.1262 - val_acc: 0.3333\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 1.9495 - acc: 0.3827 - val_loss: 2.1128 - val_acc: 0.3333\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 0s 828us/step - loss: 1.9422 - acc: 0.3827 - val_loss: 2.0996 - val_acc: 0.3333\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 0s 899us/step - loss: 1.9349 - acc: 0.3827 - val_loss: 2.0866 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 1.9196 - acc: 0.3827 - val_loss: 2.0736 - val_acc: 0.3333\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 1.9080 - acc: 0.3827 - val_loss: 2.0607 - val_acc: 0.3333\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 0s 839us/step - loss: 1.8951 - acc: 0.3827 - val_loss: 2.0479 - val_acc: 0.3333\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 0s 850us/step - loss: 1.8831 - acc: 0.3827 - val_loss: 2.0352 - val_acc: 0.3333\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 0s 866us/step - loss: 1.8730 - acc: 0.3827 - val_loss: 2.0227 - val_acc: 0.3333\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 1.8632 - acc: 0.3827 - val_loss: 2.0103 - val_acc: 0.3333\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 1.8467 - acc: 0.3827 - val_loss: 1.9979 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 1.8381 - acc: 0.3827 - val_loss: 1.9857 - val_acc: 0.3333\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 0s 854us/step - loss: 1.8348 - acc: 0.3827 - val_loss: 1.9735 - val_acc: 0.3333\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 1.8190 - acc: 0.3827 - val_loss: 1.9617 - val_acc: 0.3333\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 1.7967 - acc: 0.3827 - val_loss: 1.9500 - val_acc: 0.3333\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 0s 745us/step - loss: 1.7935 - acc: 0.3827 - val_loss: 1.9381 - val_acc: 0.3333\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 0s 734us/step - loss: 1.7888 - acc: 0.3827 - val_loss: 1.9265 - val_acc: 0.3333\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 0s 721us/step - loss: 1.7662 - acc: 0.3827 - val_loss: 1.9149 - val_acc: 0.3333\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 1.7617 - acc: 0.3827 - val_loss: 1.9033 - val_acc: 0.3333\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 0s 735us/step - loss: 1.7561 - acc: 0.3827 - val_loss: 1.8919 - val_acc: 0.3333\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 1.7299 - acc: 0.3827 - val_loss: 1.8805 - val_acc: 0.3333\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 0s 776us/step - loss: 1.7219 - acc: 0.3827 - val_loss: 1.8689 - val_acc: 0.3333\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 0s 909us/step - loss: 1.7117 - acc: 0.3827 - val_loss: 1.8564 - val_acc: 0.3333\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 1.7037 - acc: 0.3827 - val_loss: 1.8412 - val_acc: 0.3333\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 0s 814us/step - loss: 1.6889 - acc: 0.3827 - val_loss: 1.8248 - val_acc: 0.3333\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 0s 810us/step - loss: 1.6687 - acc: 0.3827 - val_loss: 1.8087 - val_acc: 0.3333\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 1.6693 - acc: 0.3827 - val_loss: 1.7927 - val_acc: 0.3333\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 1.6471 - acc: 0.3827 - val_loss: 1.7773 - val_acc: 0.3333\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 0s 754us/step - loss: 1.6403 - acc: 0.3827 - val_loss: 1.7626 - val_acc: 0.3333\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 1.6213 - acc: 0.3827 - val_loss: 1.7487 - val_acc: 0.3333\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 0s 786us/step - loss: 1.6023 - acc: 0.3827 - val_loss: 1.7350 - val_acc: 0.3333\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 1.5927 - acc: 0.3827 - val_loss: 1.7215 - val_acc: 0.3333\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 0s 829us/step - loss: 1.5838 - acc: 0.3827 - val_loss: 1.7082 - val_acc: 0.3333\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 0s 880us/step - loss: 1.5693 - acc: 0.3827 - val_loss: 1.6949 - val_acc: 0.3333\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 0s 900us/step - loss: 1.5583 - acc: 0.3827 - val_loss: 1.6818 - val_acc: 0.3333\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 1.5504 - acc: 0.3827 - val_loss: 1.6690 - val_acc: 0.3333\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 0s 748us/step - loss: 1.5194 - acc: 0.3827 - val_loss: 1.6562 - val_acc: 0.3333\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 0s 825us/step - loss: 1.5332 - acc: 0.3827 - val_loss: 1.6435 - val_acc: 0.3333\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 0s 844us/step - loss: 1.5028 - acc: 0.3827 - val_loss: 1.6312 - val_acc: 0.3333\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 1.4894 - acc: 0.3827 - val_loss: 1.6190 - val_acc: 0.3333\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 1.4846 - acc: 0.3827 - val_loss: 1.6068 - val_acc: 0.3333\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 1.4621 - acc: 0.3827 - val_loss: 1.5947 - val_acc: 0.3333\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 1.4648 - acc: 0.3827 - val_loss: 1.5826 - val_acc: 0.3333\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 0s 766us/step - loss: 1.4485 - acc: 0.3827 - val_loss: 1.5707 - val_acc: 0.3333\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 0s 747us/step - loss: 1.4420 - acc: 0.3827 - val_loss: 1.5588 - val_acc: 0.3333\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 0s 713us/step - loss: 1.4274 - acc: 0.3827 - val_loss: 1.5471 - val_acc: 0.3333\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 0s 702us/step - loss: 1.4144 - acc: 0.3827 - val_loss: 1.5355 - val_acc: 0.3333\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 0s 729us/step - loss: 1.4127 - acc: 0.3827 - val_loss: 1.5239 - val_acc: 0.3333\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 0s 802us/step - loss: 1.3957 - acc: 0.3827 - val_loss: 1.5124 - val_acc: 0.3333\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 0s 875us/step - loss: 1.3829 - acc: 0.3827 - val_loss: 1.5010 - val_acc: 0.3333\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 1.3844 - acc: 0.3827 - val_loss: 1.4898 - val_acc: 0.3333\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 1.3749 - acc: 0.3827 - val_loss: 1.4787 - val_acc: 0.3333\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 0s 763us/step - loss: 1.3476 - acc: 0.3827 - val_loss: 1.4675 - val_acc: 0.3333\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 1.3517 - acc: 0.3827 - val_loss: 1.4565 - val_acc: 0.3333\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 0s 803us/step - loss: 1.3416 - acc: 0.3827 - val_loss: 1.4457 - val_acc: 0.3333\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 0s 809us/step - loss: 1.3235 - acc: 0.3827 - val_loss: 1.4350 - val_acc: 0.3333\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 1.3176 - acc: 0.3827 - val_loss: 1.4243 - val_acc: 0.3333\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 0s 788us/step - loss: 1.3055 - acc: 0.3827 - val_loss: 1.4138 - val_acc: 0.3333\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 0s 791us/step - loss: 1.2898 - acc: 0.3827 - val_loss: 1.4033 - val_acc: 0.3333\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 1.2775 - acc: 0.3827 - val_loss: 1.3927 - val_acc: 0.3333\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 0s 808us/step - loss: 1.2685 - acc: 0.3827 - val_loss: 1.3821 - val_acc: 0.3333\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 0s 823us/step - loss: 1.2520 - acc: 0.3827 - val_loss: 1.3716 - val_acc: 0.3333\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 1.2441 - acc: 0.3827 - val_loss: 1.3614 - val_acc: 0.3333\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 1.2407 - acc: 0.3827 - val_loss: 1.3511 - val_acc: 0.3333\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 0s 816us/step - loss: 1.2351 - acc: 0.3827 - val_loss: 1.3409 - val_acc: 0.3333\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 0s 804us/step - loss: 1.2340 - acc: 0.3827 - val_loss: 1.3306 - val_acc: 0.3333\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 0s 789us/step - loss: 1.2156 - acc: 0.3827 - val_loss: 1.3203 - val_acc: 0.3333\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 1.2132 - acc: 0.3827 - val_loss: 1.3103 - val_acc: 0.3333\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 0s 785us/step - loss: 1.2024 - acc: 0.3827 - val_loss: 1.3002 - val_acc: 0.3333\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 0s 847us/step - loss: 1.1869 - acc: 0.3827 - val_loss: 1.2900 - val_acc: 0.3333\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 1.1765 - acc: 0.3827 - val_loss: 1.2800 - val_acc: 0.3333\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 0s 795us/step - loss: 1.1665 - acc: 0.3827 - val_loss: 1.2702 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 1.1645 - acc: 0.3827 - val_loss: 1.2603 - val_acc: 0.3333\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 1.1513 - acc: 0.3827 - val_loss: 1.2502 - val_acc: 0.3333\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 0s 772us/step - loss: 1.1568 - acc: 0.3827 - val_loss: 1.2402 - val_acc: 0.3333\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 0s 762us/step - loss: 1.1374 - acc: 0.3827 - val_loss: 1.2303 - val_acc: 0.3333\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 1.1166 - acc: 0.3827 - val_loss: 1.2204 - val_acc: 0.3333\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 0s 768us/step - loss: 1.1061 - acc: 0.3827 - val_loss: 1.2106 - val_acc: 0.3333\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 0s 752us/step - loss: 1.0963 - acc: 0.3827 - val_loss: 1.2006 - val_acc: 0.3333\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 1.0940 - acc: 0.3827 - val_loss: 1.1909 - val_acc: 0.3333\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 0s 790us/step - loss: 1.0927 - acc: 0.3827 - val_loss: 1.1811 - val_acc: 0.3333\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 0s 781us/step - loss: 1.0767 - acc: 0.3827 - val_loss: 1.1713 - val_acc: 0.3333\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 1.0654 - acc: 0.3827 - val_loss: 1.1616 - val_acc: 0.3333\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 0s 768us/step - loss: 1.0624 - acc: 0.3827 - val_loss: 1.1520 - val_acc: 0.3333\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 0s 853us/step - loss: 1.0476 - acc: 0.3827 - val_loss: 1.1422 - val_acc: 0.3333\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 0s 778us/step - loss: 1.0354 - acc: 0.3827 - val_loss: 1.1323 - val_acc: 0.3333\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 0s 787us/step - loss: 1.0366 - acc: 0.3827 - val_loss: 1.1226 - val_acc: 0.3333\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 0s 798us/step - loss: 1.0138 - acc: 0.3827 - val_loss: 1.1128 - val_acc: 0.3333\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 0s 801us/step - loss: 1.0045 - acc: 0.3827 - val_loss: 1.1031 - val_acc: 0.3333\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 1.0067 - acc: 0.3827 - val_loss: 1.0934 - val_acc: 0.3333\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 0s 789us/step - loss: 1.0026 - acc: 0.3827 - val_loss: 1.0838 - val_acc: 0.3333\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 0s 774us/step - loss: 0.9891 - acc: 0.3827 - val_loss: 1.0741 - val_acc: 0.3333\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 0s 817us/step - loss: 0.9736 - acc: 0.3827 - val_loss: 1.0644 - val_acc: 0.3333\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 0s 793us/step - loss: 0.9714 - acc: 0.3827 - val_loss: 1.0548 - val_acc: 0.3333\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.9709 - acc: 0.3827 - val_loss: 1.0454 - val_acc: 0.3333\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 0s 822us/step - loss: 0.9539 - acc: 0.3827 - val_loss: 1.0357 - val_acc: 0.3333\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 0s 794us/step - loss: 0.9518 - acc: 0.3827 - val_loss: 1.0265 - val_acc: 0.3333\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 0s 807us/step - loss: 0.9338 - acc: 0.3827 - val_loss: 1.0173 - val_acc: 0.3333\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 0s 842us/step - loss: 0.9277 - acc: 0.3827 - val_loss: 1.0081 - val_acc: 0.3333\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 0s 767us/step - loss: 0.9155 - acc: 0.3827 - val_loss: 0.9989 - val_acc: 0.3333\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 0s 799us/step - loss: 0.9024 - acc: 0.3827 - val_loss: 0.9898 - val_acc: 0.3333\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 0s 820us/step - loss: 0.9088 - acc: 0.3827 - val_loss: 0.9806 - val_acc: 0.3333\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 0s 824us/step - loss: 0.8950 - acc: 0.3827 - val_loss: 0.9715 - val_acc: 0.3333\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 0s 796us/step - loss: 0.8967 - acc: 0.3827 - val_loss: 0.9623 - val_acc: 0.3333\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 0s 792us/step - loss: 0.8771 - acc: 0.3827 - val_loss: 0.9530 - val_acc: 0.3333\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 0s 784us/step - loss: 0.8649 - acc: 0.3827 - val_loss: 0.9440 - val_acc: 0.3333\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.8672 - acc: 0.3827 - val_loss: 0.9349 - val_acc: 0.3333\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 0s 827us/step - loss: 0.8620 - acc: 0.3827 - val_loss: 0.9260 - val_acc: 0.3333\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 0s 877us/step - loss: 0.8624 - acc: 0.3827 - val_loss: 0.9173 - val_acc: 0.3333\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 0s 892us/step - loss: 0.8361 - acc: 0.3827 - val_loss: 0.9086 - val_acc: 0.3333\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 0.8367 - acc: 0.3827 - val_loss: 0.8999 - val_acc: 0.3333\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 0s 835us/step - loss: 0.8309 - acc: 0.3827 - val_loss: 0.8911 - val_acc: 0.3333\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 0s 812us/step - loss: 0.8134 - acc: 0.3827 - val_loss: 0.8826 - val_acc: 0.3333\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 0s 847us/step - loss: 0.8031 - acc: 0.3827 - val_loss: 0.8741 - val_acc: 0.3333\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.8104 - acc: 0.3827 - val_loss: 0.8660 - val_acc: 0.3333\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.7911 - acc: 0.3827 - val_loss: 0.8577 - val_acc: 0.3333\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.7897 - acc: 0.3827 - val_loss: 0.8497 - val_acc: 0.3333\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 0s 861us/step - loss: 0.7771 - acc: 0.3951 - val_loss: 0.8413 - val_acc: 0.3333\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 0s 837us/step - loss: 0.7820 - acc: 0.3951 - val_loss: 0.8337 - val_acc: 0.3333\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 0s 821us/step - loss: 0.7611 - acc: 0.4198 - val_loss: 0.8259 - val_acc: 0.3333\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 0s 831us/step - loss: 0.7580 - acc: 0.4074 - val_loss: 0.8182 - val_acc: 0.3333\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 0s 826us/step - loss: 0.7454 - acc: 0.4321 - val_loss: 0.8103 - val_acc: 0.3333\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 0s 838us/step - loss: 0.7330 - acc: 0.4074 - val_loss: 0.8028 - val_acc: 0.3333\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.7491 - acc: 0.4074 - val_loss: 0.7957 - val_acc: 0.3333\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.7417 - acc: 0.4568 - val_loss: 0.7884 - val_acc: 0.3333\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 0s 818us/step - loss: 0.7295 - acc: 0.4691 - val_loss: 0.7813 - val_acc: 0.3333\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 0s 813us/step - loss: 0.7190 - acc: 0.4568 - val_loss: 0.7750 - val_acc: 0.3333\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 0s 867us/step - loss: 0.7355 - acc: 0.3951 - val_loss: 0.7682 - val_acc: 0.3333\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 0s 916us/step - loss: 0.7275 - acc: 0.4815 - val_loss: 0.7622 - val_acc: 0.3333\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 0s 876us/step - loss: 0.7174 - acc: 0.4568 - val_loss: 0.7559 - val_acc: 0.3333\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 0s 852us/step - loss: 0.7113 - acc: 0.5432 - val_loss: 0.7499 - val_acc: 0.3333\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 0s 941us/step - loss: 0.6987 - acc: 0.4815 - val_loss: 0.7446 - val_acc: 0.3056\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 0s 933us/step - loss: 0.7065 - acc: 0.4444 - val_loss: 0.7391 - val_acc: 0.3056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "81/81 [==============================] - 0s 944us/step - loss: 0.6953 - acc: 0.4321 - val_loss: 0.7338 - val_acc: 0.3333\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 0s 874us/step - loss: 0.6897 - acc: 0.5679 - val_loss: 0.7286 - val_acc: 0.3333\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 0s 860us/step - loss: 0.7094 - acc: 0.5062 - val_loss: 0.7238 - val_acc: 0.3611\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 0s 884us/step - loss: 0.6914 - acc: 0.5062 - val_loss: 0.7195 - val_acc: 0.3889\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 0.6769 - acc: 0.5679 - val_loss: 0.7152 - val_acc: 0.4444\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 0s 877us/step - loss: 0.6841 - acc: 0.5309 - val_loss: 0.7113 - val_acc: 0.5000\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 0s 895us/step - loss: 0.6815 - acc: 0.5926 - val_loss: 0.7076 - val_acc: 0.5556\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 0s 878us/step - loss: 0.6852 - acc: 0.5185 - val_loss: 0.7042 - val_acc: 0.5278\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 0s 883us/step - loss: 0.6773 - acc: 0.5309 - val_loss: 0.7010 - val_acc: 0.5278\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 0s 881us/step - loss: 0.6794 - acc: 0.4938 - val_loss: 0.6976 - val_acc: 0.5278\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 0s 811us/step - loss: 0.6721 - acc: 0.5556 - val_loss: 0.6946 - val_acc: 0.5278\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 0s 864us/step - loss: 0.6842 - acc: 0.5309 - val_loss: 0.6918 - val_acc: 0.5278\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 0s 849us/step - loss: 0.6875 - acc: 0.5432 - val_loss: 0.6892 - val_acc: 0.5278\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 0s 832us/step - loss: 0.6793 - acc: 0.5062 - val_loss: 0.6868 - val_acc: 0.5556\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 0s 806us/step - loss: 0.6768 - acc: 0.5432 - val_loss: 0.6847 - val_acc: 0.6111\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 0s 805us/step - loss: 0.6710 - acc: 0.6049 - val_loss: 0.6827 - val_acc: 0.6111\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 0s 886us/step - loss: 0.6844 - acc: 0.5679 - val_loss: 0.6812 - val_acc: 0.6389\n",
      "<keras.callbacks.History object at 0x1a52928208>\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "model = create_model()\n",
    "train_score = model.fit(x_train, y_train, validation_data=(x_validate, y_validate), batch_size=batch_size, epochs=200)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "error",
     "timestamp": 1525763095237,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "yycG9fQgaTWR",
    "outputId": "6bc04992-aa67-445c-a5dc-4034a301660a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 450us/step\n",
      "loss: 0.7542654275894165\n",
      "acc: 0.3076923191547394\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a52924a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "for i, mn in enumerate(model.metrics_names):\n",
    "  print(mn + \": \" + str(test_score[i]))\n",
    "\n",
    "plt.plot(train_score.history[\"loss\"])\n",
    "plt.plot(train_score.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYwRfk9VfdKR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def threshold_tester(result, target, a, b):\n",
    "  for t in np.arange(a, b + 0.05, 0.05):\n",
    "    print(\"thresholder: \" + str(t))\n",
    "    print(classification_report(target, (result >= t).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1525762991314,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "zQ-ZbuKz3MVJ",
    "outputId": "12722ed0-2978-4350-8022-880def161a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47545043]\n",
      " [0.45908096]\n",
      " [0.45292947]\n",
      " [0.4566467 ]\n",
      " [0.447901  ]\n",
      " [0.42793685]\n",
      " [0.44476682]\n",
      " [0.41636083]\n",
      " [0.41865188]\n",
      " [0.42434302]\n",
      " [0.44968888]\n",
      " [0.42938682]\n",
      " [0.4447795 ]\n",
      " [0.41344836]\n",
      " [0.37630275]\n",
      " [0.40860257]\n",
      " [0.4713237 ]\n",
      " [0.49298254]\n",
      " [0.48300874]\n",
      " [0.45564923]\n",
      " [0.49379525]\n",
      " [0.47574976]\n",
      " [0.46022555]\n",
      " [0.42126128]\n",
      " [0.42008337]\n",
      " [0.6469332 ]]\n",
      "thresholder: 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.15000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.20000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.25000000000000006\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.3500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.73      1.00      0.84        19\n",
      "\n",
      "avg / total       0.53      0.73      0.62        26\n",
      "\n",
      "thresholder: 0.40000000000000013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         7\n",
      "        1.0       0.72      0.95      0.82        19\n",
      "\n",
      "avg / total       0.53      0.69      0.60        26\n",
      "\n",
      "thresholder: 0.45000000000000007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.21      0.43      0.29         7\n",
      "        1.0       0.67      0.42      0.52        19\n",
      "\n",
      "avg / total       0.54      0.42      0.45        26\n",
      "\n",
      "thresholder: 0.5000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.5500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.6000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.28      1.00      0.44         7\n",
      "        1.0       1.00      0.05      0.10        19\n",
      "\n",
      "avg / total       0.81      0.31      0.19        26\n",
      "\n",
      "thresholder: 0.6500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.7000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.7500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.8000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.8500000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n",
      "thresholder: 0.9000000000000002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.27      1.00      0.42         7\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.07      0.27      0.11        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billykwok/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test, batch_size=batch_size)\n",
    "print(result)\n",
    "threshold_tester(result, y_test, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1525762727684,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "qcA2GSqdINA-",
    "outputId": "b09b9962-ff00-4a8f-c628-e0e0f9877b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 1\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "0.0: 0\n",
      "0.0: 0\n",
      "1.0: 0\n",
      "1.0: -1\n",
      "Hey\n",
      "1.0: -1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "0.0: 1\n",
      "Hey\n",
      "0.0: 1\n",
      "Hey\n",
      "1.0: 1\n",
      "1.0: 0\n",
      "1.0: 0\n",
      "1.0: 1\n",
      "[{'month_id': 223, 'QAId': 'ADBE'}, {'month_id': 224, 'QAId': 'ADBE'}, {'month_id': 239, 'QAId': 'ADBE'}, {'month_id': 240, 'QAId': 'ADBE'}, {'month_id': 241, 'QAId': 'ADBE'}, {'month_id': 243, 'QAId': 'ADBE'}, {'month_id': 244, 'QAId': 'ADBE'}, {'month_id': 245, 'QAId': 'ADBE'}, {'month_id': 248, 'QAId': 'ADBE'}]\n",
      "[{'month_id': 237, 'QAId': 'ADBE'}, {'month_id': 238, 'QAId': 'ADBE'}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "buy_list = []\n",
    "sell_list = []\n",
    "def second_largest(numbers):\n",
    "    count = 0\n",
    "    m1 = m2 = float('-inf')\n",
    "    for x in numbers:\n",
    "        count += 1\n",
    "        if x > m2:\n",
    "            if x >= m1:\n",
    "                m1, m2 = x, m1            \n",
    "            else:\n",
    "                m2 = x\n",
    "    return m2 if count >= 2 else None\n",
    "\n",
    "midpt = (second_largest(map(lambda x: x[0], result)) + min(map(lambda x: x[0], result))) / 2\n",
    "\n",
    "for i, r in enumerate(result):\n",
    "  buy_or_sell = 1 if r.item() > midpt * 1.05 else (-1 if r.item() < midpt * 0.95 else 0)\n",
    "  if r.item() > midpt * 1.05:\n",
    "    buy_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  if r.item() < midpt * 0.95:\n",
    "    sell_list.append({'month_id': i + 223, 'QAId': chosen_stocks[0]})\n",
    "  print(str(y_test[i].item()) + \": \" + str(buy_or_sell))\n",
    "  if (math.fabs(buy_or_sell - y_test[i].item()) == 2) or (buy_or_sell - y_test[i].item() == 1):\n",
    "    print(\"Hey\")\n",
    "print(buy_list)\n",
    "print(sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1525762773847,
     "user": {
      "displayName": "Billy Kwok",
      "photoUrl": "//lh6.googleusercontent.com/-hjLXUpOC6dQ/AAAAAAAAAAI/AAAAAAAACok/e_QRGsCrNhg/s50-c-k-no/photo.jpg",
      "userId": "105012465118603790454"
     },
     "user_tz": -480
    },
    "id": "tTp8yfv_ZSQv",
    "outputId": "0ee9cf79-1947-460b-d0cd-95a36f3d0f9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>QAId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  QAId\n",
       "0       237  ADBE\n",
       "1       238  ADBE"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBuy = pd.DataFrame(buy_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfSell = pd.DataFrame(sell_list, columns=[\"month_id\", \"QAId\"])\n",
    "dfBuy.head(5)\n",
    "dfSell.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t2lSM7yu3dY7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "filename_base = \"_\".join([stock.lower() for stock in chosen_stocks])\n",
    "# filename_model = \"./\" + filename_base + \"_model.h5\"\n",
    "# filename_weights = \"./\" + filename_base + \"_weights.h5\"\n",
    "filename_output_buy = \"./\" + filename_base + \"_output_buy.h5\"\n",
    "filename_output_sell = \"./\" + filename_base + \"_output_sell.h5\"\n",
    "\n",
    "# model.save(filename_model)\n",
    "# model.save_weights(filename_weights)\n",
    "dfBuy.to_csv(filename_output_buy, index=False)\n",
    "dfSell.to_csv(filename_output_sell, index=False)\n",
    "\n",
    "# files.download(filename_model)\n",
    "# files.download(filename_weights)\n",
    "# files.download(filename_output_buy)\n",
    "# files.download(filename_output_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "er00PkDpHjZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MSFT",
   "provenance": [
    {
     "file_id": "1DNgXa_HOyZehXtWnJ_rmfuch2xQ-gRCg",
     "timestamp": 1525762850051
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
